# 2024年12月记录

## 2024.12.01 周日

昨日喝酒今日上午赖床没能起来......

中午饭后去基法实验室整理前日晚上处死解剖老鼠得到的肿瘤组织和肺组织（甲醛固定已经2天）进行拍照，

然后今日其余时间继续学习计算机操作系统，笔记见2024.11.30。

------




## 2024.12.02 周一

今日上午去锦城实验室参与学术报告：浙江大学许大千教授——细胞信号通路的空间调控和翻译后修饰对代谢稳态及肿瘤发生的影响，华东理工大学杨弋教授——合成生物学与光遗传学前沿技术发展与应用的研究。

然后今日剩余时间继续学习计算机操作系统，笔记见2024.11.30。

今日回家早点休息，调整个人生物作息。

------





## 2024.12.03 周二

中午去国重实验室参加实验室文献报告，下午继续学习计算机操作系统。

​	第三章 内存管理

​	3.1 内存管理概念

​	3.1.1_1 内存的基础知识

内存可存放数据。程序执行前需要先放到内存中才能被CPU处理——缓和CPU与硬盘之间的速度矛盾。

内存地址从0开始，每个地址对应一个存储单元。内存中也有一个一个的“小房间”，每个小房间就是一个”存储单元“。如果计算机按字节编址，则每个存储单元大小为1字节即1B、8个二进制位；如果计算机按字编址，则每个存储单元大小为1个字，每个字的大小为16个二进制位。

逻辑地址：程序经过编译、链接后生成的指令中指明的是逻辑地址即相对于进程其实地址而言的地址。

物理地址：实际存放数据、指令的地址即物理地址。

问题：如果将逻辑地址映射为物理地址？装入。

装入的三种方式：

​	A.绝对装入

​	在编译时，如果知道程序将放到内存的哪个位置，编译程序将产生绝对地址的目的代码。装入程序按照装入模块中的地址，将程序和数据装入内存。绝对装入只适用于单道程序环境。

​	B.可重定位装入

​	又称为静态重定位。编译、链接后的装入模块地址都是从0开始的。指令中使用的地址、数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块装入到内存的适当位置，装入时对地址进行“重定位”，将逻辑地址变换为物理地址（地址变换是在装入时一次完成的）。

特点：在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。作业一旦进入内存后，在运行期间就不能移动，也不能再申请内存空间。

​	C.动态运行时装入

​	又称为动态重定位。编译、链接后的装入模块地址都是从0开始的。装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是把地址转换推迟到程序真正要执行时才进行。因此装入内存后所有的地址依然是逻辑地址。这种方式需要一个重定位寄存器的支持。

特点：采用动态重定位时允许程序在内存中发生移动。并且可将程序分配到不连续的存储区中；在程序运行前只需装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可向用户提供一个比存储空间大得多的地址空间。

<img src="./assets/ProgramProcess.png" alt="ProgramProcess" style="zoom:25%;" />

链接的三种方式：

​	A.静态链接：在程序运行之前，先将各目标模块及它们所需的库函数连接成一个完整的可执行文件（装入模块），之后不再拆开。

​	B.装入时动态链接：将各目标模块装入内存时，边装入变链接的链接方式。

​	C.运行时动态链接：在程序执行中需要该目标模块时，才对它进行链接。其优点是便于修改和更新，便于实现对目标模块的共享。

​	3.1.1_2 内存的概念

操作系统作为系统资源的管理者，当然也需要对内存需要管理：

​	a.操作系统负责内存空间的分配和回收；

​	b.操作系统需要提供某种技术从逻辑上对内存空间进行扩充；

​	c.操作系统需要提供地址转换功能，负责程序的逻辑地址和物理地址的转换；（装入：绝对装入——编译时产生物理地址【单道程序阶段，无操作系统】；可重定位装入——装入时将逻辑地址转换为物理地址【早起的多道批处理阶段】；动态运行时装入——运行时将逻辑地址转换为物理地址，需设置重定位寄存器【现代操作系统】）

​	d.操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰。（内存保护可采取两种方法：方法一——在CPU中设置一对上、下限寄存器，存放进程的上、下限地址。进程的指令要访问某个地址时，CPU检查是否越界；方法二——采用重定位寄存器即基址寄存器和界地址寄存器即限长寄存器进行越界检查。重定位寄存器中存放的是进程的起始物理地址，界地址寄存器中存放的是进程的最大逻辑地址）

​	3.1.1_2 进程的内存映像

<img src="./assets/ProcessImage.png" alt="ProcessImage" style="zoom:25%;" />

​	3.1.2 覆盖与交换

背景：早起的计算机内存很小，比如IBM推出的第一台PC机最大只支持1MB大小的内存。因此经常会出现内存大小不够的情况。后来人们引入了“覆盖技术”，以解决“程序大小超过物理内存总和”的问题。

​	覆盖技术：

覆盖技术的思想：将程序分为多个段（模块），常用的段常驻内存，不常用的段在需要时调入内存。

<img src="./assets/RecoveryMethod.png" alt="RecoveryMethod" style="zoom:25%;" />

必须由程序员声明覆盖结构，操作系统完成自动覆盖。缺点：对用户不透明，增加了用户编程负担。

覆盖技术只用于早期的操作系统中，现在已经成为历史。

​	交换技术：

交换技术的思想：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存（进程在内存与磁盘间动态调度）

暂时换出外存等待的进程状态为挂起状态，挂起态又可以进一步细分为就绪挂起、阻塞挂起两种状态（之前提到的七状态模型）

应该在外存（磁盘）的什么位置保存被换出的进程？——具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式；对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出的速度，因此通常对换区采用连续分配方式。总之，对换区的I/O速度比文件区更快。

什么时候应该交换？——交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如：在发现许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程；如果缺页率明显下降，就可以暂停喊出。

应该换出哪些进程？——可优先换出阻塞进程；可换出优先级低的进程；为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间...（注意PCB还是需要放在内存中，不会被换出外存）

注：覆盖与交换的区别——覆盖是在同一个程序或进程中的，交换是在不同进程（或作业）之间的。

​	3.1.3_1 连续分配管理方式

连续分配：指为用户进程分配的必须是一个连续的内存空间

​	A.单一连续分配

在单一连续分配方式中，内存被分为系统区和用户区。系统区通常位于内存的低地址部分，用于存放操作系统相关数据；用户区用于存放用户进程相关数据。**内存中只能有一道用户程序，用户程序独占整个用户区空间**。

优点：实现简单；无外部碎片；可以采用覆盖技术扩充内存；不一定需要采取内存保护

缺点：只能用于单用户、单任务的操作系统中；有内部碎片；存储器利用率低

<img src="./assets/SingleContinuousAllocation.png" alt="SingleContinuousAllocation" style="zoom:25%;" />

​	B.固定分区分配

20世纪60年代出现了支持多道程序的系统，为了能在内存中装入多道程序，且这些程序之间又不会互相干扰，于是将整个用户空间划分为若干个固定大小的分区，在每个分区中只装入一道作业，这样就形成最早的、最简单的一种可运行多道程序的内存管理方式。

固定区分配可以分为：分区大小相等/分区大小不等：

<img src="./assets/FixedPartitionAllocation.png" alt="FixedPartitionAllocation" style="zoom:25%;" />

分区大小相等——缺乏灵活性，但是很适合用于一台计算机控制多个相同对象的场合。

分区大小不等——增加灵活性，可以满足不同大小的进程需求。根据常在系统中运行的作业大小情况划分。

操作系统需要建立一个数据结构——分区说明表，来实现各个分区的分配与回收。每个表项对应一个分区，通常按分区大小排列。每个表项包括对应分区的大小、起始地址、状态（是否已分配）。当用户程序要装入内存时，由操作系统内核程序根据用户大小检索该表，从中找到一个能满足大小、未分配的分区，将之分配给该程序，然后修改状态为“已分配”。优点：实现简单，无外部碎片。缺点：用户程序太大，可能所有的分区都不满足要求，此时不得不采用覆盖技术来解决，但又会降低性能；会产生内部碎片，内存利用率低。

​	C.动态分区分配

又称为可变分区分配。这种分配不会预先划分内存分区，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区大小正好适合进程的需要。因此系统分区的大小和数目是可变的。

<img src="./assets/DynamicPartitionAllocation.png" alt="DynamicPartitionAllocation" style="zoom:25%;" />

系统要用什么样的数据结构记录内存的使用情况？两种常用的数据结构——空闲分区表（每个空闲分区对应一个表项，表项中包含分区号、分区大小、分区起始地址等信息）/空闲分区链（每个分区的起始部分和末尾部分分别设置前向指针和后向指针，起始部分处还可记录分区大小等信息）。

当很多个空闲分区都能满足需求时，应该选择哪个分区进行分配——动态分区分配算法。

如何进行分区的分配和回收操作？

<img src="./assets/PartitionRecycle1.png" alt="PartitionRecycle1" style="zoom:25%;" />

<img src="./assets/PartitionRecycle2.png" alt="PartitionRecycle2" style="zoom:25%;" />

<img src="./assets/PartitionRecycle3.png" alt="PartitionRecycle3" style="zoom:25%;" />

<img src="./assets/PartitionRecycle4.png" alt="PartitionRecycle4" style="zoom:25%;" />

动态分区分配没有内部碎片，但是有外部碎片。内部碎片是分配给某进程的内存区域中，如果有些部分没有用上；外部碎片是指内存中的某些空闲分区由于太小而难以利用。如果内存中空闲空间的总和本来可以满足某进程的要求，但由于进程需要的是一整块连续的内存空间，因此这些“碎片”不能满足进程的需求。可以采用紧凑（拼凑，Compaction）技术来解决外部碎片。

​	3.1.3_2 动态分区分配算法

​	a.首次适应算法(First Fit)

算法思想：每次都从低地址开始查找，找到第一个能满足大小的空闲分区。

如何实现：空闲分区**按地址递增的次序链接**。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

​	b.最佳适应算法(Best Fit)

算法思想：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此威力保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区，即优先使用更小的空闲区。

如何实现：空闲分区**按容量递增的次序链接**。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

缺点：每次都选最小的分区进行分配，会留下越来越多、越来越小的、难以利用的内存块，因此这种方法会产生很多的外部碎片。

​	c.最坏适应算法(Worst Fit)

又称为最大适应算法(Largest Fit)

算法思想：为解决最佳适应算法的问题——即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会大小，更方便利用。

如何实现：空闲分区**按容量递减的次序链接**。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

缺点：每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大、更可用，但是这种方式会导致较大的连续空闲区被迅速用完，如果之后有“大进程”到达，就没有内存分区可用。

​	d.邻近适应算法(Next Fit)

算法思想：首次适应算法每次都从链头开始查找。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。

如何实现：空闲分区**以地址递增的次序链接**（可排成一个循环链表）。每次分配内存时从上次查找结束的位置开始查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

缺点：可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，最后导致无大分区可用。

总结：

|   算法   |                       算法思想                       | 分区排列顺序 |                             优点                             |                             缺点                             |
| :------: | :--------------------------------------------------: | :----------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 首次适应 |                 从头到尾找合适的分区                 |   地址递增   | 综合看性能最好。算法开销小，回收分区后一般不需要对空闲分区队列重新排列 |                                                              |
| 最佳适应 |         优先使用更小的分区，以保留更多大分区         |   容量递增   |       会有更多的大分区被保留下来，更能满足大进程的要求       | 会产生太小的、那以利用的碎片；算法开销大，回收分区后可能需要对空闲分区队列进行重现排序 |
| 最坏适应 |   优先使用更大的分区，以防止产生太小的不可用的碎片   |   容量递减   |                   可以减少难以利用的小碎片                   |         大分区容易被用完，不利于大进程；算法开销大。         |
| 邻近适应 | 由首次适应演变而来，每次从上次查找结束的位置开始查找 |   地址递增   |       不用每次都从低地址的小分区开始检索。算法开销小。       |                  会使高地址的大分区也被用完                  |

晚上阅读Nature Methods的issue：

[1] 

------


## 2024.12.04 周三

今日上午休息。

中午及下午去基法实验室学习计算机操作系统，并完成笔记：

​	3.1.4_1 基本分页存储管理的基本概念

将内存空间分为一个个大小相等的分区（如果每个分区4kb），每个分区就是一个“页框“（页框=页帧=内存块=物理块=物理页面）。每个页框有一个编号，即“页框号”（页框号=页帧号=内存块号=物理块号=物理页号），页框号从0开始。

将进程的逻辑地址空间也分为与页框大小相等的一个个部分，每个部分称为一个“页”或“页面”。每个页面也有一个编号，即“页号”，页号也是从0开始。

<img src="./assets/PageStore.png" alt="PageStore" style="zoom:25%;" />

操作系统以页框为单位为各个进程分配内存空间。进程的每个页面分别放入一个页框中。也就是说，进程的页面与内存的页框有一一对应的关系。

各个页面不必连续存放，可以放到不相邻的各个页框中。

重要的数据结构——页表

<img src="./assets/PageTable.png" alt="PageTable" style="zoom:25%;" />

问题一：每个页表项占多少字节？Eg.假设某系统物理内存大小为4GB，页面大小为4KB，则每个页表项至少应为多少字节？——内存块大小=页面大小=4KB=$2^{12}$B，4GB的内存总共会被分为$2^{32}/2^{12}=2^{20}$个内存块，所以内存块号的范围应该是$0 \sim 2^{20}-1$，因此内存块号至少要用20bit即3B来表示块号

注：页号可以是隐含的、不占用空间（页表项连续存放）。【假设各页表项从内存地址为X的地方开始连续存法规，如何找到页号为i的页表项？——i号页表项的存放地址=X+3\*i】；页表记录的只是内存块号，而不是内存块的起始地址！**j号内存块的起始地址=j\*内存块大小**。

问题二：如何实现地址的转换？

<img src="./assets/PageTable1.png" alt="PageTable1" style="zoom:25%;" />

特点：虽然进程的各个页面是离散存放的，但是页面内部是连续存放的。

如果要访问逻辑地址A，则需要：确定逻辑地址A对应的页号“P”，找到P号页面在内存中的起始地址（需要查页表），然后确定逻辑地址A的“页内偏移量”W，最后逻辑地址A对应的物理地址=P号页面在内存中的起始地址+页内偏移量W。

<img src="./assets/PageTable2.png" alt="PageTable2" style="zoom:25%;" />

<img src="./assets/PageTable3.png" alt="PageTable3" style="zoom:25%;" />

<img src="./assets/PageTable4.png" alt="PageTable4" style="zoom:25%;" />

总结：页面大小刚好是2的整数幂有什么好处？逻辑地址的拆分更加迅速——如果每个页面大小为$2^k$B，用二进制表示逻辑地址，则末尾K位即为页内偏移量，其余部分就是页号。因此，如果让每个页面的大小为2的整数幂，计算机硬件可以很方便地得出一个逻辑地址对应的页号和页内偏移量，而无需进行除法运算，从而提升了运行速度；物理地址的计算更加迅速——根据逻辑地址得到页号，根据页号查询页表从而找到页面存放的内存块号，将二进制表示的内存块号和页内偏移量拼接起来，就可以得到最终的物理地址。

<img src="./assets/LogicAddressStructure.png" alt="LogicAddressStructure" style="zoom:25%;" />

​	3.1.4_2 基本地址变换机构

基本地址变换机构可以解除进程的页表将逻辑地址转换为物理地址。

通常会在系统中设置一个页表寄存器（PTR），存放页表在内存中的起始地址F和页表长度M。进程未执行时，页表的始址和页表长度放在进程控制块（PCB）中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。

设页面大小为L，逻辑地址A到物理地址E的变换过程如下：

<img src="./assets/AddressMapping.png" alt="AddressMapping" style="zoom:25%;" />

​	a.计算页号P和页内偏移量W（如果用十进制数手算，则P=A/L，W=A%L；但是在计算机实际运行时，逻辑地址结构是固定不变的，因此计算机硬件可以更快地得到二进制表示的页号、页内偏移量）；

​	b.比较页号P和页面长度M，若P$\ge$M，则产生越界中断，否则继续执行。（注意：页号是从0开始的，而页表长度至少是1，因此P=M时也会越界）；

​	c.页表中页号P对应的页表项地址=页表起始地址F+页号P*页表项长度，取出该页表项内容b，即为内存块号。（注意区分页表项长度、页表长度、页面大小的区别：页表长度——这个页表中总共有几个页表项，即总共有几个页；页表项长度——每个页表项占多大的存储空间；页面大小——一个页面占多大的存储空间）

​	d.计算E=b*L+W，用得到的物理地址E去访存。（如果内存块号、页面偏移量是用二进制表示的，那么把二者拼接起来就是最终的物理地址了）

<img src="./assets/AddressMappingExample.png" alt="AddressMappingExample" style="zoom:25%;" />

<img src="./assets/AddressMappingExtension.png" alt="AddressMappingExtension" style="zoom:25%;" />

注：页内偏移量位数与页面大小之间的关系；**页式管理中的地址是一维的**；实际应用中，通常使一个页框恰好能让入整数个页表项；为了方便找到页表项，页表一般是放在连续的内存块中的。

​	3.1.4_3 具有快表的地址变换机构

快表，又称为联想寄存器（TLB，Translation Lookaside Buffer），是一种访问速度比内存快很多的高速缓存（TLB不是内存），用来存放最近访问的页表项的副本，可以加速地址变换的速度。与此对应，内存中的页表常称为慢表。

<img src="./assets/TLB.png" alt="TLB" style="zoom:25%;" />

引入快表后，地址的变换过程：

​	a.CPU给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较；

​	b.如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若快表命中，则访问某个逻辑地址仅需一次访存即可。

​	c.如果没有找到匹配的页号，则需要访问内存中的页表，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后访问该物理地址对应的内存单元。因此，若快表未命中，则访问某个逻辑地址需要两次访存（注意：在找到页表项后，应同时将其存入快表，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换）

由于查询快表的速度比查询页表的速度快很多，因此只要快表命中，就可以节省很多时间。因为局部性原理，一般来说快表的命中率可以达到90%以上。

<img src="./assets/TLBExample.png" alt="TLBExample" style="zoom:25%;" />

局部性原理：

​	时间局部性原理：如果执行了程序的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久后这个数据很有可能再次被访问（因为程序中存在大量的循环）。

​	空间局部性原理：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元很有可能被访问（很多数据在内存中都是连续存放的）

基本地址变换机构vs具有快表的地址变换机构：

|                        | 地址变换过程                                                 | 访问一个逻辑地址的访存次数                         |
| ---------------------- | ------------------------------------------------------------ | -------------------------------------------------- |
| 基本地址变换机构       | 1、算页号、页内偏移量<br />2、检查页号合法性<br />3、查页表，找到页面存放的内存块号<br />4、根据内存块号与页内偏移量得到物理地址<br />5、访问目标内存单元 | 两次访存                                           |
| 具有快表的地址变换机构 | 1、算页号、页内偏移量<br />2、检查页号合法性<br />3、查快表。若命中，即可知道页面存放的内存块号，可直接进行5；若未命中则按照4；<br />4、查页表，找到页面存放的内存块号，并且将页表项复制到快表中<br />5、根据内存块号与页内偏移量得到物理地址<br />6、访问目标内存单元 | 快表命中，只需一次访存<br />快表未命中，需两次访存 |

TLB和普通Cache的区别——TLB中只有页表项的副本，而普通Cache中可能会有其他各种数据的副本。

​	3.1.4_4 两级页表

单级页表存在的问题：

​	1.页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框；

​	2.没有必要让整个页表常驻内存，因为进程在一段时间内可能只需访问某几个特定的页面；

针对问题1：采用俄罗斯套娃策略——可将页表继续进行分组，使每个内存块刚好可以放入一个分组（例如页面大小4KB，每个页表项4B，每个页面可存放1K个页表项，因此每1K个连续的页表项为一组，每组刚好占一个内存块，再将各组离散地放到各个内存块中）

另外，要为离散分配的页表再建立一张页表，称为页目录表或外层页表、顶层页表。

<img src="./assets/TwoPageStructure.png" alt="TwoPageStructure" style="zoom:25%;" />

<img src="./assets/TwoPageStructure1.png" alt="TwoPageStructure1" style="zoom:25%;" />

如何实现地址变换：

<img src="./assets/TwoPageStructureExample.png" alt="TwoPageStructureExample" style="zoom:25%;" />

针对问题2：可以再需要访问页面时才把页面调入内存（虚拟存储技术）。可以再页表项中增加一个标志位，用于表示该页面是否已经调入内存。若想访问的页面不在内存中，则产生缺页中断（内中断），然后将目标页面从外存调入内存。

<img src="./assets/TwoPageStructure2.png" alt="TwoPageStructure2" style="zoom:25%;" />

注：

​	1.若采用多级页表机制，则各级页表的大小不能超过一个页面。若两级页表不够，可以分更多级

<img src="./assets/TwoPageStructureExample1.png" alt="TwoPageStructureExample1" style="zoom:25%;" />

​	2.两级页表的访存次数分析（假设没有快表机构）——第一次访存访问内存中页目录表，第二次访存访问内存中的二级页表，第三次访存访问目标内存单元。【N级页表访问一个逻辑地址需要N+1次访存】

​	3.1.5 基本分段存储管理方式

与“分页”最大的区别就是：**离散分配时所分配的地址空间的基本单位不同**。

分段：进程的地址空间按照程序自身的逻辑关系划分为若干个段，每个段都有一个段名（在低级语言中，程序猿使用段名来编程），每段从0开始编址。

内存分配规则：以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以不相邻。

<img src="./assets/Segment.png" alt="Segment" style="zoom:25%;" />

<img src="./assets/Segment1.png" alt="Segment1" style="zoom:25%;" />

程序分为多个段，各段离散地装入内存，为了保证程序能正常运行，就必须能从物理内存中找到各个逻辑段的存放位置。为此，需要每个进程建立一张段映射表，简称“段表”。

<img src="./assets/SegmentTable.png" alt="SegmentTable" style="zoom:25%;" />

注：每个段对应一个段表项，其中记录了该段在内存中的起始位置（“基址”）和段的长度。各个段表项的长度是相同的。例如：某系统按字节寻址，采用分段存储管理，逻辑地址结构为（段号16位，段内地址16位），因此用16位即可表示最大段长。物理内存大小为4GB（可用32位表示整个物理内存地址）。因此，可以让每个段表项占16+32=48位，即6GB。由于段表项长度相同，因此段号可以是隐含的，不占存储空间。若段表存放的起始地址为M，则K号段对应的段表项存放的地址位M+K*6。

地址变换：

<img src="./assets/AddressMapping1.png" alt="AddressMapping1" style="zoom:25%;" />

<img src="./assets/AddressMapping2.png" alt="AddressMapping2" style="zoom:25%;" />

分页vs分段：

​	页是信息的物理单位。分页的目的主要是为了实现离散分配，提高内存利用率。分页仅仅是系统管理上的需要，完全是系统行为，对用户是不可见的。

​	段是信息的逻辑单位。分段的目的是更好地满足用户需求。一个段通常包含着一组属于一个逻辑模块的信息。分段对用户是可见的，用户编程时需要显式地给出段名。

​	页的大小固定且由系统决定。段的长度不固定，决定于用户编写的程序。

​	分页的用户进程地址空间是一维的，程序员只需要给出一个记忆符即可表示一个地址。

​	分段的用户进程地址空间是二维的，程序员在标识一个地址时，既要给出段名，也要给出段内地址。

<img src="./assets/PageVsSegment.png" alt="PageVsSegment" style="zoom:25%;" />

​	分段比分页更容易实现信息的共享和保护。

<img src="./assets/PageVsSegment1.png" alt="PageVsSegment1" style="zoom:25%;" />

<img src="./assets/PageVsSegment2.png" alt="PageVsSegment2" style="zoom:25%;" />

​	访问一个逻辑地址需要几次访存？分页：第一次访存——查内存中的页表，第二次访存——访问目标内存单元。总共两次访存。分段：第一次访存——查内存中的段表，第二次访存——访问目标内存单元。总共两次访存。与分页系统类似，分段系统中也可以引入快表机构，将近期访问过的段表项放到快表中，这样可以少访问一次，加快地址变换速度。

|          |                         优点                         |                             缺点                             |
| :------: | :--------------------------------------------------: | :----------------------------------------------------------: |
| 分页管理 | 内存利用率高，不会产生外部碎片，只会有少量的页内碎片 |            不方便按照逻辑模块实现信息的共享和保护            |
| 分段管理 |        很方便按照逻辑模块实现信息的共享和保护        | 如果段长过大，为其分配很大的连续空间会很不方便。另外，段式管理会产生外部碎片 |

​	3.1.6 段页式管理方式

分段+分页的结合即为段页式管理方式。

<img src="./assets/SegmentPlusPage.png" alt="SegmentPlusPage" style="zoom:25%;" />

将进程按照逻辑分段，再将各段分页。最后将内存空间分为大小相同的内存块/页框/页帧/物理块，系统以块为单位为进程分配内存。进程前将各页面分别装入各内存块中。

段页式管理方式的逻辑地址结构：段号+页号+页内偏移量

<img src="./assets/SegmentPlusPage1.png" alt="SegmentPlusPage1" style="zoom:25%;" />

段页式管理的地址结构是二维的。

段表、页表：每个段对应一个段表项，各段表项长度相同，由段号（隐含）、页表长度、页表存放地址组成；每个页对应一个页表项，各页表项长度相同，由页号（隐含）、页面存放的内存块号组成。

<img src="./assets/SegmentPlusPage2.png" alt="SegmentPlusPage2" style="zoom:25%;" />

逻辑地址转换为物理地址的过程：

<img src="./assets/SegmentPlusPage3.png" alt="SegmentPlusPage3" style="zoom:25%;" />

晚上抽空复苏CT26-WT和CT26-luc细胞，明日下一批小鼠即将到来，准备开始接种肿瘤进行双边瘤模型构建，然后超速低温离心14h的血清去除外泌体，用于后续的外泌体提取。

------





## 2024.12.05 周四

今日上午收到老鼠后进行安顿，然后收集过夜离心的血清。

​	3.2 虚拟内存管理

​	3.2.1 虚拟内存的概念

传统存储管理方式：（很多暂时用不到的数据也会长期占用内存，导致内存利用率不高）

​	连续分配：单一连续分配、固定分区分配、动态分区分配

​	非连续分配：基本分页存储管理、基本分段存储管理、基本段页式存储管理

特征：a.一次性：作业必须一次性全部装入内存后才能开始运行。这会造成两个问题：作业很大时不能全部装入内存，导致大作业无法运行，此外当大量作业要求运行时，由于内存无法容量所有作业，因此只有少量作业能运行，导致多道程序并发度下降。b.驻留性：一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据，浪费了宝贵的内存资源。

为解决上述问题，需要进行新的内存管理——虚拟内存管理（基于局部性原理）

基于局部性原理，在程序装入时，可以将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存，就可以让程序开始执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。在操作系统的管理下，在用户看来似乎有一个比实际大得多的内存，这就是虚拟内存。【操作系统虚拟性的一个体现，实际的物理内存大小没有变，只是在逻辑上进行了扩充】

虚拟内存有以下三个主要特征：

​	多次性：无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存。

​	对换性：在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入换出。

​	虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量远大于实际的容量。

如何实现虚拟内存技术？

虚拟内存技术允许一个作业多次调入内存，如果采用连续分配方式，会不方便实现。因此虚拟内存的实现需要建立在离散分配的内存管理方式基础上——请求分页存储管理/请求分段存储管理/请求段页式存储管理。

与传统的非连续分配存储管理的区别：在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序【<u>操作系统要提供请求调页（或请求调段）功能</u>】；若内存不够，由操作系统负责将内存中暂时用不到的信息换出到外存【<u>操作系统要提供页面置换（或段置换）功能</u>】。

​	3.2.2 请求分页管理方式

页表机制：

与基本分页管理相比，请求分页管理中为了实现“请求调页”，操作系统需要知道每个页面是否已经调入内存，如果还没调入，那么也需要知道该页面在外存中存放的位置。当内存空间不够时，要实现“页面置换”，操作系统需要通过某些指标来决定到底换出哪个页面：有的页面没有被修改过，就不用在浪费时间写回外存；有的页面修改过，就需要将外存中的旧数据覆盖，因此操作系统也需要记录各个页面是否被修改的信息。

<img src="./assets/RequestPageStructure.png" alt="RequestPageStructure" style="zoom:25%;" />

缺页中断机构：

<img src="./assets/PageInterruption.png" alt="PageInterruption" style="zoom:25%;" />

缺页中断是因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此属于内中断。

地址变换机构

<img src="./assets/AddressMapping3.png" alt="AddressMapping3" style="zoom:25%;" />

新增步骤：请求调页（查到页表项时进行判断），页面置换（需要调入页面，但没有空闲内存块时进行），休要修改请求页表中新增的表项。

<img src="./assets/AddressMapping4.png" alt="AddressMapping4" style="zoom:25%;" />

​	3.2.3 页面置换算法

页面的换入、换出需要磁盘I/O，会有较大的开销，因此好的页面置换算法应该追求更少的缺页率。

​	a.最佳置换算法（OPT）

算法思想：每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。

<img src="./assets/OPT.png" alt="OPT" style="zoom:25%;" />

实现方法：最佳置换算法可以保证最低的缺页率，但实际上只有在进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面访问序列。因此，最佳置换算法是无法实现的。

​	b.先进先出置换算法（FIFO ）

算法思想：每次选择淘汰的页面是最早进入内存的页面。

实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面即可。队列的最大长度取决于系统为进程分配了多少个内存块。

<img src="./assets/FIFO1.png" alt="FIFO1" style="zoom:25%;" />

只有FIFO算法会产生Belady异常。另外，FIFO算法虽然实现简单，但是该算法与进程实际运行时的规律不适应，因为先进入的页面也有可能最经常被访问。因此，算法性能差。

​	c.最近最久未使用置换算法（LRU）

算法思想：每次淘汰的页面是最近最久未使用的页面。

实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t。每当淘汰一个页面时，选择现有页面t值最大的，即最近最久未使用的页面。

<img src="./assets/LRU1.png" alt="LRU1" style="zoom:25%;" />

该算法的实现需要专门的硬件支持，虽然算法性能好，但是实现困难、开销大。

​	d.时钟置换算法（CLOCK）

算法思想：是一种性能和开销比较均衡的算法，又称为CLOCK算或最近未使用算法（NRU，Not Recenetly Used）

简单型实现方法：为每个页面设置一个访问位，再将内存中的页面都通过链接指针**链接成一个循环队列**。当某页被访问时，其访问位置为1。当需要淘汰一个页面时，只需检查页的访问位。如果是0，就选择该页换出；如果是1，则将它置为0，暂不换出，继续检查下一个页面，若第一轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描（第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK算法选择一个淘汰页面最多会经过两轮扫描）

<img src="./assets/CLOCK.png" alt="CLOCK" style="zoom:25%;" />

但是简单的CLOCK算法仅考虑到一个页面最近是否被访问过。事实上，如果被淘汰的页面没有被修改过，就不需要执行 I/O操作写回外存。只有被淘汰的页面被修改过时，才需要写会外存。

​	e.改进型的时钟置换算法

改进型实现方法：除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。在其他条件都想同时，应优先淘汰没有修改过的页面，避免I/O操作。修改位=0表示页面没有被修改过；修改位=1表示页面被修改过。

<img src="./assets/CLOCK1.png" alt="CLOCK1" style="zoom:25%;" />

优先级排序：

​	第一级优先：最近没访问，且没修改的页面

​	第二级优先：最近没访问，但修改过的页面

​	第三级优先：最近访问过，但没修改的页面

​	第四级优先：最近访问过，且修改过的页面

|                          |                           算法规则                           |                     优缺点                     |
| :----------------------: | :----------------------------------------------------------: | :--------------------------------------------: |
|           OPT            |              优先淘汰最长时间内不会被访问的页面              |        缺页率最小，性能最好；但无法实现        |
|           FIFO           |                  优先淘汰最先进入内存的页面                  |    实现简单；但性能很差，可能出现Belady异常    |
|           LRU            |                 优先淘汰最近最久没访问的页面                 |      性能很好；但需要硬件支持，算法开销大      |
|       CLOCK（NRU）       | 循环扫描各页面<br />第一轮淘汰访问位=0的，并且将扫描过的页面访问位改为1。若第一轮未选中，则进行第二轮扫描 | 实现简单，算法开销小；但为考虑页面是否被修改过 |
| 改进型CLOCK（改进型NRU） | 若用（访问位、修改位）的形式表示，则<br />第一轮：淘汰（0，0）<br />第二轮：淘汰（0，1），并将扫描过的页面访问位都置为0<br />第三轮：淘汰（0，0）<br />第四轮：淘汰（0，1） |            算法开销较小，性能也不错            |

​	3.2.4 页面分配策略

驻留集：指请求分页存储管理中给进程分配的物理块的集合。

在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小。

若驻留集太小，会导致缺页频繁，系统要花大量时间来处理缺页，实际用于进程推进的时间很少；驻留集太大，又会导致多道程序并发度下降，资源利用率降低。所以应该选择一个合适的驻留集大小。

针对驻留集大小是否可变：

​	固定分配：操作系统为每个进程分配一组固定数目的物理块，在进程运行期间不再改变。即驻留集大小不变。

​	可变分配：先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少，即驻留集大小可变。

针对驻留集的置换方法：

​	局部置换：发生缺页时只能选进程自己的物理块进行置换。

​	全局置换：可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，再分配给缺页进程。

固定分配局部置换：系统为每个进程分配一定数量的物理块，在整个运行期间都不变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。这种策略的缺点是：很难在刚开始就确定应为每个进程分配多少个物理块才算合理。（采用这种策略的系统可以根据进程大小、优先级、或是根据程员猿给出的参数来确定为一个进程分配的内存块数）

可变分配全局置换：刚开始会为每个进程分配一定数量的物理块。操作系统会保持一个空闲物理块队列。当某进程发生缺页时，从空闲物理块中取出一块分配给该进程。若已无空闲物理块，则可以选择一个未锁定的页面换出外存，再将该物理块分配给缺页的过程。采用这种策略时，只要某进程发生缺页，都将获得新的物理块，仅当空闲物理块用完时，系统才选择一个未锁定的页面调出。被选择调出的页可能是系统中任何一个进程的页，因此这个被选中的进程拥有的物理块会减少，缺页率会增加。

可变分配局部置换：刚开始会为每个进程分配一定数量的物理块。当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存。如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度；反之，如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。

何时调入页面？

​	a.预调用页面：根据局部性原理，一次调入若干个相邻的页面可能比一次调入一个页面更高效。但如果提前调入的页面大多数都没被访问过，则又是低效的。因此可以预测不久之后可能访问到的页面，将它们预先调入内存，但目前预测成功率只有50%左右。这种策略主要用于进程的首次调入，由程序员指出应该先调入哪些部分。

​	b.请求调页策略：进程在运行期间发现缺页时才将所缺页面调入内存。由这种策略调入的页面一定会被访问到，但由于每次只能调入一页，而每次调页都要磁盘I/O操作，因此I/O 开销较大。

从何处调入页面？

​	a.系统拥有足够的对换空间：页面的调入、调出都是在内存与对换区之间进行，这样可以保证页面的调入、调出速度很快。在进程运行前，需将进程相关的数据从文件区复制到对换区。

<img src="./assets/PageChange.png" alt="PageChange" style="zoom:25%;" />

​	b.系统缺少足够的对换空间：凡是不会被修改的数据都直接从文件区调入，由于这些页面不会被修改，因此换出时不必写回磁盘，下次需要时再从文件区调入即可。对于可能被修改的部分，换出时需写回磁盘对换区，下次需要时再从对换区调入。

<img src="./assets/PageChange1.png" alt="PageChange1" style="zoom:25%;" />

​	c.UNIX方式：运行之前进程有关的数据全部放在文件区，故未使用过的页面，都可从文件区调入。若被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入。

<img src="./assets/UNIXPage.png" alt="UNIXPage" style="zoom:25%;" />

抖动（颠簸）现象：

​	刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸【为进程分配的物理块太少，会使进程发生抖动现象；为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率】。产生抖动的主要原因：进程频繁访问的页面数目高于可用的物理块数。为了研究应该为每个进程分配多少个物理块，Denning提出了“工作集”的概念。

工作集：指在某段时间间隔里，进程实际访问页面的集合。

<img src="./assets/WorkSet.png" alt="WorkSet" style="zoom:25%;" />

拓展：基于局部性原理可知，进程在一段时间内访问的页面与不久之后会访问的页面是有相关性的。因此，可以根据进程近期访问的页面集合（工作集）来设计一种页面置换算法——选择一个不在工作集中的页面进行淘汰。

​	3.2.5 内存映射文件

传统的文件访问方式：

​	open系统调用——打开文件；

​	seek系统调用——将读写指针移到某个位置；

​	read系统调用——从读写指针所指位置读入若干数据（从磁盘读入内存）；

​	write系统调用——将内存中的指定数据，写回磁盘（根据读写指针确定要写回什么位置）

内存映射文件（Memory-Mapped Files）访问方式：

​	open系统调用——打开文件；

​	mmap系统调用——将文件映射到进程的虚拟地址空间

​	然后以访问内存的方式访问文件数据，文件数据的读入、写出由操作系统自动完成，进程关闭文件时，操作系统自动将文件被修改的数据写回磁盘。

特点：多个进程可以映射同一个文件，实现共享；进程关闭文件时，操作系统负责将文件数据写回磁盘，并解除内存映射；以访问内存的方式读写文件；进程可使用系统调用，请求操作系统将文件映射到进程的虚拟地址空间。

优点：程序员编程更简单，已建立映射的文件，只需按访问内存的方式读写即可；文件数据的读入/写出完全由操作系统负责，I/O效率可以由操作系统优化。

然后继续阅读Nature Methods issue：Volume 21 Issue 8, August 2024——《Focus on advanced AI in biology》：https://www.nature.com/nmeth/volumes/21/issues/8

------



## 2024.12.06 周五

今日上午休息。

中午及下午看Attention、Self-Attention机制，然后在基法实验室学习计算机操作系统，笔记如下：

​	第四章 文件管理

​	4.1.1 初始文件管理

文件：一组有意义的信息/数据集合

文件的属性：

|      属性      |                             描述                             |
| :------------: | :----------------------------------------------------------: |
|     文件名     | 由创建文件的用户决定文件名，主要是为了方便用户找到文件，同一目录下不允许有重名文件 |
|     标识符     | 一个系统内的各文件标识符唯一，对用户来说毫无可读性，因此标识符只是操作系统用于区分哥哥文件的一种内部名称 |
|      类型      |                        指明文件的类型                        |
|      位置      | 文件存放的路径（让用户使用）、在外存中的地址（操作系统使用，对用户不可见） |
|      大小      |                        指明文件的大小                        |
|    创建时间    |                    指明文件首次创建的时间                    |
|  上次修改时间  |                  指明文件最近一次修改的时间                  |
| 文件所有者信息 |                      指明文件所有者信息                      |
|    保护信息    |                 对文件进行保护的访问控制信息                 |

文件内部的数据结构：

​	无结构文件（如文本文件）：由一些二进制或字符流组成，又称“流式文件”。

​	有结构文件（如数据库表）：由一组相似的记录组成，又称“记录式文件”。

<img src="./assets/FileStructure.png" alt="FileStructure" style="zoom:25%;" />

文件之间的组织方式：

<img src="./assets/FileOrganization.png" alt="FileOrganization" style="zoom:25%;" />

操作系统应该向上提供的功能：创建文件（create系统调用）、读文件（read系统调用）、写文件（write系统调用）、删除文件（delete系统调用）、打开文件（open系统调用）【读写文件之前需要打开文件】、关闭文件（close系统调用）【读写文件结束之后需要关闭文件】。

从用户到裸机的视角，文件应如何存放在外存？——与内存一样，外存也是由一个个存储单元组成的，每个存储单元可以存储一定量的数据（如1B）。每个存储单元对应一个物理地址。类似于内存分为一个个“内存块”，外存会分为一个个“块/磁盘块/物理块”。每个磁盘块的大小是相等的，每块一般包含2的整数幂个地址（如$2^{10}$个地址即1KB）。同样类似的是，文件的逻辑地址也可以分为（逻辑块号，块内地址），操作系统同样需要将逻辑地址转换为外存的物理地址（物理块号，块内地址）的形式。块内地址的位数取决于磁盘块的大小。操作系统以“块”为单位为文件分配存储空间，因此即使一个文件大小只有10B，但它依然要占用1KB的磁盘块，外存中的数据读入内存的时候同样以“块”为单位。

其他需要由操作系统实现的文件管理功能：文件共享——多个用户可以共享使用一个文件；文件保护——如何保证不同的用户对文件有不同的操作权限。

​	4.1.2 文件的逻辑结构

按文件是否有结构分类，可以分为无结构文件、有结构文件两种。

​	无结构文件：文件内部的数据就是一系列二进制流或字符流组成，又称为“流式文件”。如Windows操作系统中的.txt文件。

​	有结构文件：由一组相似的记录组成，又称“记录式文件”。每条记录有若干个数据项组成。一般来说每条记录有一个数据项可作为关键字。根据各条记录的长度（占用的存储空间）是否相等，又可分为定长记录和可变长记录两种。

有结构文件的逻辑结构——顺序文件/索引文件/索引顺序文件

​	a.顺序文件：文件中的记录一个接一个地顺序排列（逻辑上），记录可以是定长的或可变长的。各个记录在物理上可以顺序存储（逻辑上相邻的记录物理上也相邻）或链式存储（逻辑上相邻的记录物理上不一定相邻）。

<img src="./assets/FixedVsVariableFileStore.png" alt="FixedVsVariableFileStore" style="zoom:25%;" />

顺序文件可以分为串结构和顺序结构。串结构记录之间的顺序与关键字无关（通常按照记录存入时间决定记录的顺序）；顺序结构记录之间的顺序按关键字顺序排列。

顺序文件若是通过链式存储，无论是定长/可变长记录，都无法实现随机存取，每次只能从第一个记录开始依次往后寻找；顺序文件若是顺序存储——若是可变长记录，则无法实现随机存取，每次只能从第一个记录开始依次往后查找；若是定长记录，可实现随机存取，记录长度为L，则第i个记录存放的相对位置是i*L，若采用串结构则无法快速找到某关键字对应的记录，若采用顺序结构，可以快速找到某关键字对应的记录（折半查找）。即**定长记录的顺序文件，若物理上采用顺序存储，则可实现随机存取；若能再保证记录的顺序接哦股，则可以实现快速检索（即根据关键字快速找到对应记录）。**

​	b.索引文件：

<img src="./assets/IndexFile.png" alt="IndexFile" style="zoom:25%;" />

索引表本身是定长记录的顺序文件。因此可以快速找到第i个记录对应的索引项。

可将关键字作为索引号内容，若按关键字顺序排列，则还可以支持按照关键字折半查找。

每当要增加/删除一个记录时，需要对索引表进行修改。由于索引文件具有很快的检索速度，因此主要用于对信息处理的及时性要求比较高的场合。

另外，可以用不同的数据项建立多个索引表。如：学生信息表中可以用“学号”建立一张索引表，也可以用“姓名”建立一张索引表。（SQL就支持根据某个数据项建立索引的功能）

缺点：每个记录对应一个索引表项，因此索引表可能会很大。

​	c.索引顺序文件：索引顺序文件就是索引文件和顺序文件的结合

<img src="./assets/IndexSequentialFile.png" alt="IndexSequentialFile" style="zoom:25%;" />

索引顺序文件中，同样会为文件建立一张索引表，但不同的是：并不是每个记录对应一个索引表项，而是**一组记录对应一个索引表项**。

<img src="./assets/IndexSequentialFile1.png" alt="IndexSequentialFile1" style="zoom:25%;" />

为进一步提高检索效率，可以为顺序文件建立多级索引表。

<img src="./assets/IndexSequentialFile2.png" alt="IndexSequentialFile2" style="zoom:25%;" />

​	4.1.3 文件目录

引入文件目录结构使得文件之间的组织结构清晰易于查找，编程时也可以很方便的用文件路径找到一个文件。

文件控制块（FCB）：

<img src="./assets/FCB.png" alt="FCB" style="zoom:25%;" />

目录本身也是一种特殊的文件结构。FCB的有序集合称为“文件目录”，一个FCB就是一个文件目录项。FCB中包含了文件的基本信息（文件名、物理地址、逻辑结构、物理结构等）、存取控制信息（是否可读/可写、禁止访问的用户名单等）、使用信息（如文件的建立时间、修改时间等）

FCB的操作：

​	搜索：当用户要使用一个文件时，系统要根据文件名搜索目录，找到该文件对应的目录项。

​	创建文件：创建一个文件时，需要在其所属的目录中增加一个目录项。

​	删除文件：当删除一个文件时，需要在目录中删除相应的目录项。

​	显示目录：用户可以请求现实目录的内容，如显示该目录中的所有文件及相应属性。

​	修改目录：某些文件属性保存在目录中，因此这些属性变化时需要修改相应的目录项（如：文件重命名）。

目录结构：

​	a.单级目录结构

早期操作系统不支持多级目录，整个系统中只建立一张目录表，每个文件占一个目录项。

<img src="./assets/SingleDirectory.png" alt="SingleDirectory" style="zoom:25%;" />

单极目录实现了“按名存取”，但是不允许文件重名。在创建一个文件时，需要先检查目录表中有没有重名文件，确定不重名后才能允许建立文件，并将新文件对应的目录项插入目录表中。

​	b.两级目录结构

早期的多用户操作系统，采用两级目录结构，分为主文件目录（MFD，Master File Directory）和用户文件目录（UFD，User File Directory）。

<img src="./assets/DoubleDirectory.png" alt="DoubleDirectory" style="zoom:25%;" />

​	c.多级目录结构（树形目录结构）

<img src="./assets/MultiDirectory.png" alt="MultiDirectory" style="zoom:25%;" />

<img src="./assets/MultiDirectory1.png" alt="MultiDirectory1" style="zoom:25%;" />

注意区分绝对路径和相对路径。在引入了“当前目录”和“相对路径”之后，磁盘I/O的次数减少了，这就提升了访问文件的效率。

树形目录结构可以很方便地对文件进行分类，层次结构清晰，也能够更有效地进行文件的管理和保护。但是，树形结构不便于实现文件的共享。为此，提出了“无环图目录结构”。

​	d.无环图目录结构：

<img src="./assets/NoCircleDirectory.png" alt="NoCircleDirectory" style="zoom:25%;" />

索引结点：

<img src="./assets/IndexNode.png" alt="IndexNode" style="zoom:25%;" />

当找到文件名对应的目录项时，才需要将索引结点调入内存，索引结点中记录了文件的各种信息，包括文件在外存中的存放位置，根据存放位置即可找到文件。

存放在外存中的索引结点称为“磁盘索引结点”，当索引结点放入内存后称为“内存索引结点”。内存索引结点还需要增加一些信息，比如：文件是否被修改、此时有几个进程正在访问该文件等。

​	4.1.4 文件的物理结构（文件分配方式）

<img src="./assets/FileBlock.png" alt="FileBlock" style="zoom:25%;" />

​	a.连续分配

连续分配方式要求每个文件在磁盘上占有一组连续的块。

逻辑块号转变为物理块号只需要转换块号即可，块内地址保持不变。

<img src="./assets/FileContinuousBlock.png" alt="FileContinuousBlock" style="zoom:25%;" />

用户给出要访问的逻辑块号，操作系统找到该文件对应的目录项（FCB）：物理块号=起始块号+逻辑块号。当然，还需要检查用户提供的逻辑块号是否合法（逻辑块号$\ge$长度就不合法）。

可以直接算出逻辑块号对应的物理块号，因此连续分配支持顺序访问和直接访问（即随机访问）。

优点：连续分配的文件在顺序读/写时速度最快。

缺点：但是物理上采用连续分配的文件不方便拓展；物理上采用的连续分配存储空间利用率低，会产生难以利用的磁盘碎片【可以用紧凑来处理碎片，但是需要耗费很大的时间代价】。

​	b.链接分配

链接分配采取离散分配的方式，可以为文件分配离散的磁盘块。分为隐式链接和显式链接两种。

隐式链接：

<img src="./assets/FileHiddenLinkBlock.png" alt="FileHiddenLinkBlock" style="zoom:25%;" />

用户给出要访问的逻辑块号i，操作系统需要i+1次磁盘I/O操作。故采用链式分配（隐式链接）方式的文件，只支持顺序访问，不支持随机访问，查找效率低。另外，指向下一个盘块的指针也需要耗费少量的存储空间。

优点：很方便文件拓展，不会有碎片问题，外存利用率高。

缺点：只支持顺序访问，不支持随机访问，查找效率低，指向下一个盘块的指针也需要耗费少量的存储空间。

显式链接：

<img src="./assets/FileTransparentLinkBlock.png" alt="FileTransparentLinkBlock" style="zoom:25%;" />

把用于连接文件各物理块的指针显式地存放在一张表中。即文件分配表（FAT，File Allocation Table）。

注意：一个磁盘仅设置一张FAT。开机时，将FAT读入内存，并常驻内存。FAT的各个表项在物理上连续存储，且每一个表项长度相同，因此<u>“物理块号”字段可以是隐含的</u>。开机时文件分配表放入内存，并常驻内存。

用户给出要访问的逻辑块号i，通过查询FAT，往后找到i号逻辑块对应的物理块号，往后找到i号逻辑块对应的物理块号即可【逻辑块号转换为物理块号的过程不需要读磁盘操作】。故采用链式分配（显式链接）方式的文件，支持顺序访问，也支持随机访问（想访问i号逻辑块时，并不需要依次访问之前的0～i-1号逻辑块），由于块号转换的过程不需要访问磁盘，因此相比于隐式链接来说，访问速度快很多。

优点：很方便文件拓展，不会有碎片问题，外存利用率高，并且支持随机访问。相比于隐式链接来说，地址转换时不需要访问磁盘，因此文件的访问效率更高。

缺点：文件分配表需要占用一定的存储空间。

​	c.索引分配

索引分配允许文件离散地分配在各个磁盘块中，系统会为每个文件建立一张索引表，索引表中记录了文件的各个逻辑块对应的物理块（索引表的功能类似于内存管理中的页表——建立逻辑页面到物理页面之间的映射关系）。索引表存放的磁盘块称为索引块。文件数据存放的磁盘块称为数据块。

<img src="./assets/FileIndexBlock.png" alt="FileIndexBlock" style="zoom:25%;" />

用户给出要访问的逻辑块号i，从目录项中可知索引表存放位置，将索引表从外存读入内存，并查找索引表即可知i号逻辑块再外存中的存放位置。

可见索引分配方式可以支持随机访问，文件拓展也很容易实现（只需要给文件分配一个空闲块，并增加一个索引表项即可）。

如果索引表太大，一个索引块装不下，应该怎么解决？

​	1.链接方案：将多个索引块链接起来存放。

<img src="./assets/FileIndexBlock1.png" alt="FileIndexBlock1" style="zoom:25%;" />

缺点：若文件很大，索引表很长，就需要将很多个索引块链接起来。想要找到i号索引块就必须依次读入0~i-1号索引块，这就导致磁盘I/O次数过多，查找效率低下。

​	2.多层索引：建立多层索引。使第一层索引块指向第二层索引块。还可根据文件大小要求再建立第三层、第四层索引块。

<img src="./assets/FileIndexBlock2.png" alt="FileIndexBlock2" style="zoom:25%;" />

特别注意：若采用多层索引，则各层索引表大小不能超过一个磁盘块。

可根据逻辑块号算出应该查找索引表的那个表项。如果采用K层索引的方式，且顶级索引表未调入内存，访问目标数据块K+1次磁盘I/O。

缺点：即使是小文件，访问一个数据块依然需要K+1次读磁盘。

​	3.混合索引：多种索引分配方式的结合。例如：一个文件的顶级索引表中，既包含直接地址索引（直接指向数据块）、又包含一级简介索引（指向单层索引表）、还包含两级简介索引表（指向两层索引表）。

<img src="./assets/FileIndexBlock3.png" alt="FileIndexBlock3" style="zoom:25%;" />

优点：对于小文件来说，访问一个数据块所需的读磁盘次数更少。

|                   |                             How?                             |                          目录项内容                          |                             优点                             |                             缺点                             |
| :---------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|     顺序分配      |                为文件分配的必须是连续的磁盘块                |                      起始块号、文件长度                      |                 顺序存取速度快，支持随机访问                 |                  会产生碎片，不利于文件拓展                  |
| 链接分配-隐式分配 | 除文件的最后一个盘块之外，每个盘块中都存有指向下一个盘块的指针 |                      起始块号、结束块号                      |         可解决碎片问题，外存利用高，文件拓展实现方便         |                  只能顺序访问，不能随机访问                  |
| 链接分配-显式分配 | 建立一张文件分配表（FAT）显示记录盘块的先后顺序（开机后FAT常驻内存） |                           起始块号                           | 除了拥有隐式链接的优点之外，还可以通过查询内存的FAT实现随机访问 |                  FAT需要占用一定的存储空间                   |
|     索引分配      | 为文件数据块建立索引表。<br />若文件太大，可采用链接方案、多层索引、混合索引 | 链接方案记录的是第一个索引块的块号，多层/混合索引记录的是顶级索引块的块号 |               支持随机访问，易于实现文件的拓展               | 索引表需占用一定的存储空间。访问数据块前需要先读入索引块。若采用链接方案，查找索引块时可能需要很多次读磁盘操作 |

​	4.1.5 逻辑结构vs物理结构

逻辑结构：

​	用户（文件创建者）的视角看到的样子；在用户看来，整个文件占用连续的逻辑地址空间；文件内部的信息完全由用户自己决定，操作系统并不关心。

物理结构：

​	由操作系统决定文件采用什么物理结构存储；操作系统负责将逻辑地址转变为（逻辑块号，块内偏移量）的形式，并负责实现逻辑块号到物理块号的映射

​	4.1.6 文件存储空间管理

存储空间的划分和初始化：

磁盘空间一个必经的步骤是——进行存储空间的划分：为磁盘分区，即将物理磁盘划分为一个个文件卷（逻辑卷、逻辑盘）。文件卷也会进一步划分为目录区（存放文件目录信息FCB、用于磁盘存储空间管理的信息）、文件区（存放文件数据）。

<img src="./assets/FileDivision.png" alt="FileDivision" style="zoom:25%;" />

存储空间管理：

​	a.空闲表法

<img src="./assets/IdleTable.png" alt="IdleTable" style="zoom:25%;" />

适用于“连续分配方式”。

如何分配磁盘块：与内存管理中的动态分区分配很类似，为一个文件分配连续的存储空间。同样可以采用首次适应、最佳适应、最坏适应等算法来决定要为文件分配哪个区间。

如何回收磁盘块：与内存管理中的动态分区分配很类似，当回收某个存储区时需要有四种情况——回收区的前后都没有相邻空闲区；回收区的前后都是空闲区；回收区前面是空闲区；回收区后面是空闲区。总之，回收时需要注意表项的合并问题。

​	b.空闲链表法

<img src="./assets/IdleLink.png" alt="IdleLink" style="zoom:25%;" />

分为空闲盘块链（以**盘块为单位**组成一条空闲链）和空闲盘区链（以**盘区为单位**组成一条空闲链）

空闲盘块链：

​	如何分配磁盘块：若某文件申请K个盘块，则从链头开始依次摘下K个盘块分配，并修改空闲链的链头指针。

​	如何回收磁盘块：回收的盘块依次挂到链尾，并修改空闲链的链尾指针。

​	适用于离散分配的物理结构，为文件分配多个盘块可能要重复多次操作。

空闲盘区链：

​	如何分配磁盘块：若某文件申请K个盘块，则可以采用首次适应、最佳适应等算法，从链头开始检索，按照算法规则找到一个大小符合要求的空闲盘块，分配给文件。若没有合适的连续空闲块，也可以将不同盘区的盘块同时分配给一个文件，注意分配后可能要修改相应的链指针、盘区大小等数据。

​	如何回收磁盘块：若回收区和某个空闲盘区相邻，则需要将回收区合并到空闲盘区。若回收区没有和任何空闲区相邻，将回收区作为单独的一个空闲盘区挂到链尾。

​	离散分配、连续分配都适用，为一个文件分配多个盘块时效率更高。

​	c.位示图法

<img src="./assets/PositionalDiagram.png" alt="PositionalDiagram" style="zoom:25%;" />

位示图法：每个二进制位对应一个盘块。以上图例中0表示盘块空闲，1表示盘块已分配。位示图一般用连续的“字”表示，如本例中一个字的字长是16位，字中的每一位对应一个盘块。因此可以用（字号，位号）【列号，行号】对应一个盘块号。

本例中盘块号、字号、位号从0开始，若n表示字长，则（字号，位号）=（i，j）的二进制对应盘块号b=ni+j。相反，b号盘块对应的字号i=[b/n]，位号j=b%n。

如何分配磁盘块：若文件需要K个块，顺序扫描位示图找到K个相邻或不相邻的0，然后根据字号、位号算出对应的盘块号将相应盘块分配给文件，最后将相应位设置为1。

如何回收磁盘块：根据回收的盘块号计算出对应的字号、位号，然后将相应二进制设为0。

​	d.成组链接法

空闲表法、空闲链表法不适用于大型文件系统，因为空闲表或空闲链表可能过大。UNIX系统中采用了成组链接法对磁盘空闲块进行管理。

文件卷的目录区中专门用一个磁盘块作为“超级块”，当系统启动时需要将超级块读入内存。并且要保证内存与外存中的“超级块”数据一致。

<img src="./assets/GroupLink.png" alt="GroupLink" style="zoom:25%;" />

如何分配磁盘块：Eg：需要1个空闲块——检查第一个分组的块数是否足够。1<100因此是足够的；分配第一个分组中的1个空闲块，并修改相应数据。Eg：需要100个空闲块——检查第一个分组是否足够。100=100，是足够的。分配第一个分组中的100个空闲块，但是由于300号块内存放了再下一组的信息，因此300号块的数据需要复制到超级块中。

如何回收磁盘块：Eg：假设每个分组最多100个空闲块，此时第一个分组已有99个块，还要再回收一块，此时直接插到第一个分组当中；。Eg：假设每个分组最多为100个空闲块，此时第一个分组已有100个块。需要将超级块中的数据复制到新回收的块中，并修改超级块的内容，让新回收的块成为第一个分组。

​	4.1.7 文件的基本操作

​	**a.创建文件（Create系统调用）**

进行create系统调用时，需要提供的几个主要参数：

​	1.所需的外存空间大小（如：一个磁盘块，即1KB）；

​	2.文件存放路径（"/A/B/C"）

​	3.文件名

操作系统在处理create系统调用时，主要做了两件事：

​	1.在外存中找到文件所需的空间（上小节的算法）；

​	2.根据文件存放路径的信息找到该目录对应的目录文件，在目录中创建该文件对应的目录项。目录项中包含了文件名、文件在外存中的存放位置等信息。

​	**b.删除文件（Delete系统调用）**

进行delete系统调用时，需要提供的几个主要参数：

​	1.文件存放路径（"/A/B/C"）。

​	2.文件名。

操作系统在处理delete系统调用时，做了以下几件事：

​	1.根据文件存放路径找到相应的目录文件，从目录中找到文件名对应的目录项。

​	2.根据该目录项纪录的文件在外存的存放位置、文件大小等信息，回收文件占用的磁盘块（上小节的算法）。

​	3.从目录表中删除文件对应的目录项。

​	**c.打开文件（Open系统调用）**

在很多操作系统中，在对文件进行操作之前，要求用户先使用open系统调用“打开文件”，需要提供的几个主要参数：

​	1.文件存放路径。

​	2.文件名。

​	3.要对文件的操作类型（如r只读、rw读写等）

操作系统在处理open系统调用时，做了以下几件事：

​	1.根据文件存放路径找到相应的目录文件，从目录中找到文件名对应的目录项，并检查该用户是否有指定的操作权限。

​	2.将目录项复制到内存中的“打开文件表”中【里面有打开计数器，每个用户打开相同的文件时，打开计数器+1】。并将对应表目的编号返回给用户。之后用户使用打开文件表的编号来指明要操作的文件。

<img src="./assets/OpenFile.png" alt="OpenFile" style="zoom:25%;" />

注意：打开文件时并不会把文件数据直接读入内存。“索引号”也称“文件描述符”。

​	**d.关闭文件（Close系统调用）**

操作系统在处理close系统调用时，做了以下几件事：

​	1.将进程的打开文件表相应表项删除。

​	2.回收分配给该文件的内存空间等资源。

​	3.系统打开文件表的打开计数器count减1，若count=0，则删除对应表项。

​	**e.读文件（Read系统调用）**

进程使用read系统调用完成写操作。需要指明是哪个文件（在支持“打开文件”操作的系统中，只需要提供文件在打开文件中的索引号即可），还需要指明要读入多少数据（如读入1KB）、指明读入的数据要放在内存中的什么位置。

操作系统在处理read系统调用时，会从读指针指向的外存中，将用户指定大小的数据读入用户指定的内存区域中。

​	**f.写文件（Write系统调用）**

进程使用write系统调用完成写操作，需要指明是哪个文件（在支持“打开文件”操作的系统中，只需要提供文件在打开文件表中的索引号即可），还需要指明要写出多少数据（如写入1KB）、写回外存的数据放在内存中的什么位置。

操作系统在处理write系统调用时，会从用户指定的内存区域中，将指定大小的数据写回写指针指向的外存。

注：读/写文件用文件描述符即可指明文件，不再需要用到文件名。

​	4.1.8 文件共享

共享vs复制：多个用户共享同一个文件，意味着系统中只有“一份”文件数据。并且只要某个用户修改了文件的数据，其他用户也可以看到文件数据的变化。如果多个用户“复制”了同一个文件，那么系统中会有“好几份”文件数据。其中一个用户修改了自己的那份文件数据，对其他用户的文件数据并没有影响。

基于索引结点的共享方式（硬链接）：

<img src="./assets/HardLink.png" alt="HardLink" style="zoom:25%;" />

各个用户的目录项都指向同一个索引结点，索引结点中需要有链接计数count，当某个用户想要删除文件时，只是删除该用户的目录项，且count--，count=0时才能真正删除文件数据和索引结点，否则会导致指针悬空。

基于索引结点的共享方式（软链接、符号链接）：

<img src="./assets/SoftLink.png" alt="SoftLink" style="zoom:25%;" />

在一个Link型的文件中记录共享文件的存放路径（类似于Windows快捷方式），操作系统根据路径一层层查找目录，最终找到共享文件，即使软连接指向的共享文件已删除，Link型文件依然存在，只是通过Link型文件中的路径区查找共享文件会失败（找不到对应目录项）。由于软连接的方式访问共享文件时要查询多级目录，会有多次磁盘I/O，因此用软链接访问。

​	4.1.9 文件保护

​	a.口令保护

为文件设置一个“口令”，用户请求访问该文件时必须提供“口令”。

口令一般存放在文件对应的FCB或索引结点中。用户访问文件前需要先输入“口令”，操作系统会将用户提供的口令与FCB中存储的口令进行对比，如果正确，则允许该用户访问文件。

优点：保存口令的空间开销不多，验证口令的时间开销也很小。

缺点：正确的“口令”存放在系统内部，不够安全。

​	b.加密保护

使用某个“密码”对文件进行加密，在访问文件时需要提供正确的“密码”才能对文件进行正确的解密。

优点：保密性强，不需要再系统中存储“密码”。

缺点：编码/译码，或者说加密/解密要花费一定的时间。

​	c.访问控制

在每个文件的FCB（或索引结点）中增加一个访问控制列表（Access-Control List，ACL），该表记录了各个用户可以对文件执行那些操作。

<img src="./assets/AccessControlType.png" alt="AccessControlType" style="zoom:25%;" />

精简的访问列表：以“组”为单位，标记各“组”用户可以对文件执行哪些操作。如分为系统管理员、文件主、文件主的伙伴、其他用户几个分组。当某用户想要访问文件时，系统会坚持该用户所属的分组是否有相应的访问权限。

特点：实现灵活，可以实现复杂的文件保护功能。

​	4.2.1 文件系统的层次结构

自顶向下：用户接口——文件目录系统——存取控制模块——逻辑文件系统与文件信息缓冲区——物理文件系统——辅助分配模块/设备管理模块

<img src="./assets/FileSystemStructure.png" alt="FileSystemStructure" style="zoom:25%;" />

假设某用户请求删除文件：

​	用户需要通过操作系统提供的接口发出上述请求——用户接口；

​	用于用户提供的是文件的存放路径，因此需要操作系统一层一层地查找目录，找到对应的目录项——文件目录系统；

​	不同的用户对文件有不同的操作全选，因此为了保证安全，需要检查用户是否有访问权限——存取控制模块（存取控制验证层）；

​	验证了用户的访问权限之后，需要把用户提供的“记录号”转变为对应的逻辑地址——逻辑文件系统与文件信息缓冲区；

​	要删除这条记录，必定要对磁盘设备发出请求——设备管理程序模块；

​	删除这些记录后，会有一些盘块空闲，因此要将这些空闲盘块进行回收——辅助分配模块。

​	4.2.2 文件系统布局

文件系统在外存中的结构：

​	物理格式化：即低级格式化——划分扇区，检测坏扇区，并用备用扇区替换坏扇区。

<img src="./assets/FileSystemInExternalMemory.png" alt="FileSystemInExternalMemory" style="zoom:25%;" />

​	逻辑格式化：磁盘分区（分卷Volume），完成个分区的文件系统初始化。注：逻辑格式化后灰色部分就有实际数据了，白色部分还没有数据。

<img src="./assets/FileSystemInExternalMemory1.png" alt="FileSystemInExternalMemory1" style="zoom:25%;" />

文件系统在内存中的结构：

<img src="./assets/FileSystemInInternalMemory.png" alt="FileSystemInInternalMemory" style="zoom:25%;" />

注：近期访问过的目录文件会换存在内存中，不用每次都从磁盘读入，这样可以加快目录检索速度。

​	4.2.3 虚拟文件系统

普通文件系统：

<img src="./assets/CommonFileSystem.png" alt="CommonFileSystem" style="zoom:25%;" />

虚拟文件系统：

<img src="./assets/VirtualFileSystem.png" alt="VirtualFileSystem" style="zoom:25%;" />

特点：

​	1.向上层用户进程提供统一标准的系统调用接口，屏蔽底层具体文件系统的实现差异；

​	2.VFS要求下层的文件系统必须实现某些规定的函数功能，如open/read/write等。一个新的文件系统想要在某操作系统上被使用，就必须满足该操作系统VFS的要求；

存在的问题：不同的文件系统，表示文件数据结构各不相同。打开文件后，其在内存中的表示就不同。解决方法：不同文件被打开之后，VFS会生成一个vnode（v结点）表，把文件相关信息复制到vnode中，这样就能用统一的格式来表示文件信息。

​	3.每打开一个文件，VFS就在主存中新建一个vnode，用统一的数据结构表示文件，无论该文件存储在哪个文件系统中【vnode只会存在于主存】；

<img src="./assets/vnode.png" alt="vnode" style="zoom:25%;" />

此外，打开文件创建vnode之后，将文件信息复制到vnode，vnode的功能指针指向具体文件系统的函数功能。

文件系统挂载（Mounting）：即文件系统安装/装载——如何将一个文件系统挂载到操作系统中？

文件系统挂载要做的事：

​	a.在VFS中注册新挂载的文件系统。内存中的挂载表（mount table）包含每个文件系统的相关信息，包括文件系统类型、容量大小等。

​	b.新挂载的文件系统，要向VFS提供一个函数地址列表。

​	c.将新文件系统加到挂载点（mount point），也就是将新文件系统挂载在某个父目录下面。

晚上抽空给CT26-luc传代（CT26-WT已经被污染），准备后续开始进行皮下双边瘤实验。

------





## 2024.12.07 周六

今日一天学习计算机操作系统，并完成相应的笔记至2024.12.06位置。

------





## 2024.12.08 周日

今日上午进行WB实验，进行电泳、转膜。

中午饭后继续学习计算机操作系统，完成相应的笔记：

​	第五章 输入输出（I/O）管理

​	5.1.1 I/O设备的分类和管理

"I/O"设备就是“输入/输出”（Input/Output），就是可以将数据输入到计算机，或者可以接收计算机输出数据的外部设备，属于计算机中的硬件部件。

UNIX系统将外部设备抽象为一种特殊的文件，用户可以使用与文件操作相同的方式对外部设备进行操作。

I/O设备分类

​	a.按使用特性

人机交互外部设备：鼠标、键盘、打印机等，用于人机交互，数据传输速度慢。

存储设备：移动硬盘、光盘等，用于数据存储，数据传输速度快。

网络通信设备：调制解调器等，用于网络通信，属于介于上述两种之间。

​	b.按传输速率

低速设备：鼠标、键盘等，传输速率为每秒几个到几百字节。

中速设备：激光打印器等，传输速率为每秒数千至上万个字节。

高速设备：如磁盘等，传输速率为每秒数千字节至千兆字节。

​	c.按信息交换的单位

块设备：如磁盘等，数据传输的基本单位是“块”，传输速率较高，可寻址，即可随机地读/写任意块。

字符设备：如鼠标、键盘等，数据传输的基本单位是“字符”，传输速率较慢，不可寻址，在输入/输出时常采用中断驱动方式。

​	5.1.2 I/O控制器

I/O设备由机械部件和电子部件组成，机械部件主要用来举行具体的I/O操作、电子部件主通常是一块插入主板扩充槽的印刷电路板。CPU无法直接控制I/O设备的机械部件，因此I/O设备还要有一个电子部件作为CPU和I/O设备机械部件之间的“中介”，用于实现CPU对设备的控制。

这个电子部件即为I/O控制器，又称为设备控制器。CPU可控制I/O控制器，I/O控制器来控制设备的机械部件。

I/O控制器的功能：

​	接受和识别CPU发出的命令：如CPU发来的read/write命令，I/O控制器中会有相应的控制寄存器来存放命令和参数。

​	向CPU报告设备的状态；I/O控制器中会有相应的状态寄存器，用于记录I/O设备的当前状态，如1表示空闲、0表示忙碌。

​	数据交换：I/O控制器中会设置相应的数据寄存器。输出时，数据寄存器用于暂存CPU发来的数据，之后再由控制器传送设备。输入时，数据寄存器用于暂存设备发来的数据，之后CPU从数据寄存器中取走数据。

​	地址识别：类似于内存的地址，为了区分设备控制器中的各个寄存器，也需要给各个寄存器设置一个特定的“地址”。I/O控制器通过CPU提供的“地址”来判断CPU要读/写的是哪个寄存器。

I/O控制器的组成：

<img src="./assets/IOControllerComposition.png" alt="IOControllerComposition" style="zoom:25%;" />

注：一个I/O控制器可能会对应多个设备；数据寄存器、控制寄存器、状态寄存器可能有多个（如：每个控制/状态寄存器对应一个具体的设备），且这些寄存器都要有相应的地址，才能方便CPU操作。有的计算机会让这些寄存器占用内存地址的一部分，称为**内存映像I/O**【可以采用对内存进行操作的指令来对控制器进行操作】，另一些计算机则采用I/O专用地址，即**寄存器独立编址**【需要专门设置的指令来操作控制器】。

<img src="./assets/MemoryIOvsRegisterIO.png" alt="MemoryIOvsRegisterIO" style="zoom:25%;" />

​	5.1.3 I/O控制方式

​	a.程序直接控制方式

<img src="./assets/IODirectAccess.png" alt="QQ_1733645567206" style="zoom:25%;" />

CPU干预的频率：很频繁，I/O操作开始之前、完成之后需要CPU介入，并且在等待I/O完成的过程中CPU需要不断地轮询检查。

数据传输的单位：每次读/写一个字。

数据的流向：读操作（数据输入）——I/O设备->CPU->内存；写操作（数据输出）——内存->CPU->I/O设备。每个字的读/写都需要CPU的帮助。

优点：实现简单。在读/写指令之后，加上实现循环检查的一系列指令即可。

缺点：CPU和I/O设备只能串行工作，CPU需要一直轮询检查，长期处于“忙等”状态，CPU利用率低。

​	b.中断驱动方式

引入中断机制。由于I/O设备速度很慢，因此CPU发出读/写命令后，可将等待I/O的进程阻塞，先切换到别的进程执行。当I/O完成后，控制器会向CPU发出一个中断信号，CPU监测到中断信号后会保存当前进程的运行环境信息，转去执行中断处理程序处理该中断。处理中断的过程中，CPU从I/O控制器读一个字的数据传送到CPU寄存器，再写入主存。接着，CPU恢复等待I/O的进程（或其他进程）的运行环境，然后继续执行。



注：CPU会在每个指令周期的末尾检查中断；中断处理过程中需要保存、恢复进程的运行环境，这个过程需要一定的时间开销。如果中断频率太高，也会降低系统的性能。

<img src="./assets/IOInterruptionDrive.png" alt="IOInterruptionDrive" style="zoom:25%;" />

CPU的干预频率：每次I/O操作开始之前、完成之后需要CPU介入。等待I/O完成的过程中CPU可以切换到别的进程执行。

数据传送的单位：每次读/写一个字。

数据的流向：读操作（数据输入）——I/O设备->CPU->内存；写操作（数据输出）——内存->CPU->I/O设备。

优点：与程序直接控制方式相比，I/O控制器会通过中断信号主动报告I/O已完成，CPU不再需要不停地轮询。CPU和I/O设备可并行工作，CPU利用率得到明显提升。

缺点：每个字在I/O设备与内存之间的传输，都需要经过CPU。而频繁的中断处理会消耗较多的CPU时间。

​	c.DMA方式

DMA方式中文名为直接存储器存取。主要用于“块设备”的I/O控制。改进：数据的传送单位是“块”；数据的流向是从设备直接放入内存，或者内存直接到设备，不需要经过CPU；仅在传输一个或多个数据块的开始或结束时，才需要CPU干预。

<img src="./assets/IODMA.png" alt="IODMA" style="zoom:25%;" />

<img src="./assets/IODMARegister.png" alt="IODMARegister" style="zoom:25%;" />

CPU干预的频率：仅在传送一个或多个数据块的开始和结束时，才需要CPU干预。

数据传送的单位：每次读/写一个或多个块（注：每次读写的只能是连续的多个块，且这些块读入内存后在内存中也必须是连续的）

数据的流向：读操作（数据输入）——I/O设备->内存；写操作（数据输出）——内存->I/O设备【不需要经过CPU】。

优点：数据传输以“块”为单位，CPU介入频率进一步降低。数据的传输不再需要先经过CPU再写入内存，数据传输效率进一步增加。CPU和I/O设备的并行性得到提升。

缺点：CPU每发出一条I/O指令，只能读/写一个或多个连续的数据块。

​	d.通道控制方式

通道：可以识别并执行一系列的通道指令。与CPU相比，通道可以执行的指令很单一，并且通道程序是放在主机内存中，也就是说通道与CPU共享内存

<img src="./assets/IOTube.png" alt="IOTube" style="zoom:25%;" />

<img src="./assets/IOTubeControl.png" alt="IOTubeControl" style="zoom:25%;" />

CPU干预的频率：极低。通道会根据CPU的指示执行相应的通道程序，只有完成一组数据块的读/写后才需要发出中断信号，请求CPU干预。

数据传送的单位：每次读/写一组数据块。

数据的流向：读操作（数据输入）——I/O设备->内存；写操作（数据输出）——内存->I/O设备【在管道的控制下进行】。

优点：实现复杂，需要专门的通道硬件支持。

缺点：CPU、通道、I/O设备可并行工作，资源利用率很高。

总结：

|                  |                     完成一次读/写的过程                      | CPU干预频率 | 数据传输单位 |               数据流向               | 优缺点 |
| :--------------: | :----------------------------------------------------------: | :---------: | :----------: | :----------------------------------: | :----: |
| 程序直接控制方式 |                 CPU发出I/O命令后需要不断轮询                 |    极高     |      字      | 设备->CPU->内存<br />内存->CPU->设备 |  见上  |
|   中断驱动方式   | CPU发出I/O命令后可以做其他事，本次I/O完成后设备控制器发出中断信号 |     高      |      字      | 设备->CPU->内存<br />内存->CPU->设备 |  见上  |
|     DMA方式      | CPU发出I/O命令后可以做其他事，本次I/O完成后DMA控制器发出中断信号 |     中      |      块      |      设备->内存<br />内存->设备      |  见上  |
|   通道控制方式   | CPU发出I/O命令后可以做其他事。通道会执行通道程序以完成I/O，完成后通道向CPU发出中断信号 |     低      |    一组块    |      设备->内存<br />内存->设备      |  见上  |

​	5.1.4 I/O软件层次结构

<img src="./assets/IOSoftwareLayer.png" alt="IOSoftwareLayer" style="zoom:25%;" />

用户层软件：实现了与用户交互的接口，用户可直接使用该层提供的、与I/O操作相关的库函数设备进行操作。

设备独立性软件：用户层软件将用户请求翻译成格式化的I/O请求，并通过“系统调用”请求操作系统内核的服务。

设备驱动程序：设备独立性软件又称设备无关性软件。与设备的硬件特性无关的功能几乎都在这一层实现。主要实现的功能：**向上层提供调用接口**；**设备的保护**（设备是一种特殊的文件，不同用户对文件的权限也不同）；**差错处理**；**设备的分配与回收**；**数据缓冲区管理**；建立逻辑设备名到物理设备名的映射关系，根据设备类型选择调用相应的驱动设备【设备独立性软件需要通过逻辑设备表LUT来确定逻辑设备对应的物理设备，并找到该设备对应的设备驱动程序】。主要负责对硬件设备的具体控制，将上层发出的一系列命令转化成特定设备能识别的一系列操作。

中断处理程序：当I/O任务完成时，I/O控制器会发送一个中断信号，系统会根据中断信号类型找到相应的中断处理程序并执行。

硬件：执行I/O操作，有机械部件、电子部件组成。

​	5.1.5 输入/输出应用程序接口和驱动程序接口

输入/输出应用程序接口：

<img src="./assets/IOApplicationInterface.png" alt="IOApplicationInterface" style="zoom:25%;" />

阻塞I/O：应用程序发出I/O系统调用，进程需转为阻塞态；eg：字符设备接口——从键盘读一个字符get。

非阻塞I/O：应用程序发出I/O系统调用，系统调用可迅速返回，进程无需阻塞等待。eg：块设备接口——往磁盘写数据write。

设备驱动程序接口：

<img src="./assets/DeviceDrivenInterface.png" alt="DeviceDrivenInterface" style="zoom:25%;" />

核心：接口=统一标准。

​	5.2.1 I/O核心子系统

<img src="./assets/IOKeySubsystem.png" alt="IOKeySubsystem" style="zoom:25%;" />

用户层软件——假脱机技术（SPOOLing技术）；

设备独立性软件——I/O调度、设备保护、设备分配与回收、缓冲区管理（即缓冲与高速缓存）；

I/O调度：用某种算法确定一个好的顺序来处理各个I/O请求。如磁盘调度（先来先服务算法、最短寻道优先算法、SCAN算法、C-SCAN算法、LOOK算法、C-LOOK算法），当多个磁盘I/O请求到来时，用某种调度算法确定满足I/O请求的顺序。

设备保护：操作系统需要实现文件保护功能，不同的用户对各个文件有不同的访问权限。在UNIX系统中，设备被看作是一种特殊的文件，每个设备也会有对应的FCB。当用户请求访问某个设备时，系统根据FCB中记录的信息来判断该用户是否有相应的访问权限，以此实现“设备保护”的功能。

​	5.2.2 假脱机技术（SPOOLing技术）

“脱机”——脱离主机的控制进行的输入/输出操作。引入脱机技术后，缓解了CPU与慢速I/O设备的速度矛盾。另一方面，即使CPU在忙碌，也可以提前将数据输入到磁带，即使慢速的输出设备正在忙碌，也可以提前将数据输出到磁带【预输入、缓输出】。

<img src="./assets/Offline.png" alt="Offline" style="zoom:25%;" />

假脱机技术，又称为SPOOLing技术，是用软件的方式模拟脱机技术，SPOOLing系统的组成如下：

<img src="./assets/PseudoOffline.png" alt="PseudoOffline" style="zoom:25%;" />

输入井和输出井——模拟输入输出时的磁带，输入进程和输出进程——模拟脱机输入/输出时的外围控制机，输入缓冲区和输出缓冲区——内存中的缓冲区，输入、输出时的“中转站”。

共享打印机就是用SPOOLing技术将独占式打印机“虚拟”成共享打印机。

核心：脱机/假脱机=缓冲区

​	5.2.3 设备的分配与回收

​	A.设备分配时应该考虑的因素

​	设备的固有属性：独占设备、共享设备、虚拟设备

​	设备分配算法：先来先服务算法、短任务优先算法、......

​	设备分配中的安全性：安全分配方式（为进程分配一个设备后就将进程阻塞，本次I/O完成后才将进程唤醒）【一个时段内每个进程只能使用一个设备，优点：破坏了“请求和保持”条件，不会死锁；缺点：对于一个进程来说，CPU和I/O设备只能串行工作】、不安全分配方式（进程发出I/O请求后，系统为其分配I/O设备，进程可继续执行，之后还可以发出新的I/O请求。只有某个I/O请求得不到满足时才将进程阻塞）【一个进程可以同时使用多个设备，优点：进程的计算任务和I/O任务可以并行处理，使进程迅速推进；缺点：有可能发生死锁（死锁避免，死锁的检测和解除）】。

回顾：

静态分配：进程运行前为其分配全部所需的资源，运行结束后归还资源。

动态分配：进程运行过程中动态申请设备资源。

​	B.设备分配管理中的数据结构

<img src="./assets/DeviceDistributionDataStructure.png" alt="DeviceDistributionDataStructure" style="zoom:25%;" />

一个通道可控制多个设备控制器，每个设备控制器可控制多个设备。

设备控制表（DCT）：系统为每个设备配置一张DCT，用于记录设备情况：

<img src="./assets/DCT.png" alt="DCT" style="zoom:25%;" />

控制器控制表（COCT）：每个设备控制器都会对应一张COCT。操作系统根据COCT的信息对控制器进行管理和操作。

<img src="./assets/COCT.png" alt="COCT" style="zoom:25%;" />

通道控制表（CHCT）：每个通道都会对应一张CHCT。操作系统根据CHCT的信息对通道进行操作和管理。

<img src="./assets/CHCT.png" alt="CHCT" style="zoom:25%;" />

系统设备表（SDT）：记录系统中全部设备的情况，每个设备对应一个表目。

<img src="./assets/SDT.png" alt="SDT" style="zoom:25%;" />

​	C.设备分配的步骤

​	根据进程请求的**物理设备名**查找SDT->根据SDT找到DCT，若设备忙碌则将进程PCB挂到设备等待队列，不忙碌则将设备分配给进程->根据DCT找到COCT，若控制器忙碌则将进程PCB挂到控制器等待队列，不忙碌则将控制器分配给进程->根据COCT找到CHCT，若通道忙碌则将进程PCB挂到通道等待队列，不忙碌则将通道分配给进程。

只有设备、控制器、通道三者都分配成功时，这次设备才算成功，之后便可启动I/O设备进行数据传送。

缺点：用户编程必须使用“物理设备名”，底层细节对用户不透明，不方便编程；若换了一个物理设备，则程序无法运行；若进程请求的物理设备正在忙碌，即使系统还有同类型的设备，进程也必须阻塞等待。

改进方法：建立逻辑设备名与物理设备名的映射机制，用户编程时只需提供逻辑设备名。

​	根据进程请求的**逻辑设备名**查找SDT->查找SDT，找到用户进程指定类型的、并且空闲的设备，将其分配给该进程。操作系统在逻辑设备表（LUT）中新增一个表项->根据DCT找到COCT，若控制器忙碌则将进程挂到控制器等待队列中，不忙碌则将控制器分配给进程->根据COCT找到CHCT，若通道忙碌则将进程PCB挂到通道等待列队中，不忙碌则将通道分配给进程。

<img src="./assets/LUT.png" alt="LUT" style="zoom:25%;" />

​	5.2.4 缓冲区管理

缓冲区是一个存储区域，可以由专门的硬件寄存器组成，也可以利用内存作为缓冲区。

使用硬件作为缓冲区的成本较高，容量较小，一般仅用在对速度要求非常高的场合，如联想寄存器（快表）。

一般情况，更多的是利用内存作为缓冲区，“设备独立性软件”的缓冲区管理就是要组织管理好这些缓冲区。

缓冲区的作用：

​	缓和CPU与I/O设备速度不匹配的矛盾；

​	减少对CPU的中断频率，放宽对CPU中断相应时间的限制；

​	解决数据粒度不匹配的问题；

​	提高CPU与I/O设备之间的并行性

<img src="./assets/BufferRegion.png" alt="BufferRegion" style="zoom:25%;" />

缓冲区分为两种类型的缓冲：单缓冲和多缓冲。

单缓冲：假设某用户进程请求某种块设备读入若干块的数据。若采用单缓冲的策略，操作系统会在主存中为其分配一个缓冲区。注意：当缓冲区数据非空时，不能往缓冲区冲入数据，只能从缓冲区把数据传出；当缓冲区为空时，可以往缓冲区冲入数据，但必须把缓冲区充满后，才能从缓冲区把数据传出。

<img src="./assets/SingleBuffer.png" alt="SingleBuffer" style="zoom:25%;" />

<img src="./assets/SingleBuffer1.png" alt="SingleBuffer1" style="zoom:25%;" />

双缓冲：假设某用户进程请求某种块设备读入若干块的数据。若采用单缓冲的策略，操作系统会在主存中为其分配两个缓冲区。

<img src="./assets/DoubleBuffer.png" alt="DoubleBuffer" style="zoom:25%;" />

<img src="./assets/DoubleBuffer2.png" alt="DoubleBuffer2" style="zoom:25%;" />

结论：采用双缓冲策略，处理一个数据块的平均耗时为Max（T，C+M）。

<img src="./assets/SingleBuffervsDoubleBuffer.png" alt="SingleBuffervsDoubleBuffer" style="zoom:25%;" />

<img src="./assets/SingleBuffervsDoubleBuffer1.png" alt="SingleBuffervsDoubleBuffer1" style="zoom:25%;" />

循环缓冲：将多个大小相等的缓冲区链接成一个循环队列。

<img src="./assets/CircleBuffer.png" alt="CircleBuffer" style="zoom:25%;" />

缓冲池：由系统中共用的缓冲区组成。这些缓冲区按使用状态可以分为——空缓冲队列、装满输入数据的缓冲队列（输入队列）、装满输出数据的缓冲队列（输出队列）。

另外，根据一个缓冲区在实际运算中扮演的功能不同，又设置了工作缓冲区：用于收容输入数据的工作缓冲区（hin）、用于提取输入数据的工作缓冲区（sin）、用于收容输出数据的工作缓冲区（hout）、用于提取输出数据的工作缓冲区（sout）。

<img src="./assets/BufferPool.png" alt="BufferPool" style="zoom:25%;" />

​	5.3.1 磁盘的结构

磁盘：磁盘的表面由一些磁性物质组成，可以用这些磁性物质来记录二进制数据。

磁道：磁盘的盘面会被划分成一个个磁道，这样的一个“圈”就是一个磁道。

扇区：一个磁道又被划分成一个个扇区，每个扇区就是一个“磁盘块”。每个扇区存放的数据量相同。

<img src="./assets/DiskNotation.png" alt="DiskNotation" style="zoom:25%;" />

盘面与柱面：

<img src="./assets/DiskNotation1.png" alt="DiskNotation1" style="zoom:25%;" />

可用**（柱面号，盘面号，扇区号）**来定位任意一个“磁盘块”，在“文件的物理结构”小节中，我们经常提到文件数据存放在外存中的几号块，这个块号就可以转换成（柱面号，盘面号，扇区号）的地址形式。

可根据该地址读取一个“块”：根据“柱面号”移动磁臂，让磁头指向指定柱面->激活指定盘面对应的磁头->磁盘旋转过程中，指定的扇区会从磁头下面划过，完成对指定扇区的读/写。

磁盘的分类：活动头磁盘/固定头磁盘；可换盘磁盘（盘片可以更换）/固定盘磁盘（盘片不可以更换）：

<img src="./assets/DiskType.png" alt="DiskType" style="zoom:25%;" />

​	5.3.2 磁盘的调度算法

一次磁盘读/写操作需要的时间：寻找时间$T_s$+延迟时间$T_R$+传输时间$T_t$。

​	寻找时间（寻道时间）：在读/写数据前，将磁头移动到指定磁道所花的时间。启动磁头臂是需要时间的，假设耗时为s，移动磁头也是需要时间的，假设磁头匀速移动，每跨越一个磁道耗时为m，总共需要跨越n条磁道，则寻道时间$T_s=s+m*n$。

​	延迟时间：通过旋转磁盘，使磁头定位到目标扇区所需要的时间。假设磁盘转速为r（单位：转/秒，或转/分），则平均所需的延迟时间$T_R=\frac{1}{2} * \frac{1}{r}=\frac{1}{2r}$。其中$\frac{1}{r}$就是转一圈需要的时间，找到目标扇区平均需要转半圈，因此乘以系数$\frac{1}{2}$。

​	传输时间：从磁盘读出或向磁盘写入数据所经历的时间/假设磁盘转速为r，此次读/写的字节数为b，每个磁道上的字节数为N，则平均传输时间$T_t=\frac{1}{r}*\frac{b}{N}=\frac{b}{rN}$。其中每个磁道要可存N字节的数据，因此b字节的数据需要$\frac{b}{N}$个磁道才能存储。而读/写一个磁道所需的时间刚好又是转一圈所需要的时间$\frac{1}{r}$。

​	总的平均存取时间$T_a=T_s+\frac{1}{2r}+\frac{b}{rN}$。

因此延迟时间和传输时间都与磁盘转速相关，且为线性相关。而转速是硬件的固有属性，因此操作系统也无法优化延迟时间和传输时间，但是操作系统的磁盘调度算法会直接影响寻道时间。

​	a.先来先服务算法（FCFS）

算法思想：根据进程请求访问磁盘的先后顺序进行调度。

<img src="./assets/DiskFCFS.png" alt="DiskFCFS" style="zoom:25%;" />

优点：公平；如果请求访问的磁盘比较集中的话，性能一般。

缺点：如果有大量进程竞争使用磁盘，请求访问的磁道很分散，则FCFS在性能上很差，寻道时间长。

​	b.最短寻找时间优先（SSTF）

算法思想：优先处理的磁道是与当前磁道最近的磁道，可以保证每次的寻道时间最短，但是并不能保证总的寻道时间最短（类似于贪心算法）。

<img src="./assets/DiskSSTF.png" alt="DiskSSTF" style="zoom:25%;" />



优点：性能较好，平均寻道时间短。

缺点：可能产生“饥饿”现象。

​	c.扫描算法（SCAN）

算法思想：磁头移动到最外侧磁道的时候才能往内移动，移动道最内磁磁道的时候才能往外移动。由于磁头移动的方式很像电梯，也称为电梯算法。

<img src="./assets/DiskScan.png" alt="DiskScan" style="zoom:25%;" />

优点：性能较好，平均寻道时间较短，不会产生饥饿现象。

缺点：只有到达最边上的磁道才能改变磁头的方向；对于各个位置的响应频率不平均。

​	d.LOOK调度算法

算法思想：针对SCAN算法缺点1的优化——如果在磁头移动方向上已经没有别的请求，就可以立即调转磁头移动方向。

<img src="./assets/DiskLook.png" alt="DiskLook" style="zoom:25%;" />

优点：比起SCAN算法来看，不需要每次都移动到最外侧或最内侧才改变磁头方向，使寻道时间进一步缩短。

​	e.循环扫描算法（C-SCAN）

算法思想：针对SCAN算法缺点2的优化——规定只有磁头朝某个特定方向移动时才处理磁道访问请求，而返回时直接快速移动至起始端而不处理任何请求。

<img src="./assets/DiskCSCAN.png" alt="DiskCSCAN" style="zoom:25%;" />

优点：比起SCAN算法来看，对于各个位置磁道的响应频率很平均。

缺点：只有到达最边上的磁道才能改变磁头的方向；比起SCAN算法，平均寻道时间更长。

​	f.C-LOOK算法

算法思想：针对C- SCAN算法的改良——如果在磁头移动方向上已经没有别的请求，就可以立即调转磁头移动方向，且只有磁头朝某个特定方向移动时才处理磁道访问请求。

<img src="./assets/DiskCLOOK.png" alt="DiskCLOOK" style="zoom:25%;" />

优点：比起C-SCAN算法来看，寻道时间进一步缩短。

​	5.2.3 减少磁盘延迟的方法

<img src="./assets/DiskDelayTime.png" alt="DiskDelayTime" style="zoom:25%;" />

方法1：交替编号法——让逻辑上相邻的扇区在物理上有一定的间隔，可以使读区连续的逻辑扇区需要的延迟时间更小。原理——读取完一个扇区后需要一段时间处理才可以继续读入下一个扇区。

磁盘地址结构的设计：

<img src="./assets/DiskAddressStructureDesign.png" alt="DiskAddressStructureDesign" style="zoom:25%;" />

<img src="./assets/DiskAddressStructureDesign1.png" alt="DiskAddressStructureDesign1" style="zoom:25%;" />

物理地址上，柱面号在盘面号之前时为了读取地址连续的磁盘块时，可以减少磁头移动消耗的时间。

<img src="./assets/DiskDelayTime1.png" alt="DiskDelayTime1" style="zoom:25%;" />



方法2：错位命名法——让相邻盘面的扇区编号“错位”。原理：同错位命名。

<img src="./assets/DiskDelayTime2.png" alt="DiskDelayTime2" style="zoom:25%;" />

​	5.3.4 磁盘的管理

磁盘初始化：物理格式化—>分区—>逻辑格式化

<img src="./assets/DiskInitiation.png" alt="DiskInitiation" style="zoom:25%;" />

引导块：计算机开机时需要进行一系列初始化的工作，这些初始化工作是通过执行初始化程序（自举程序）玩橙的。

​	初始化程序可以放在ROM中，ROM中的数据在出厂时就写入了，并且以后不能修改。问题：万一自举程序需要更改，将会很不方便。所以，现代计算机中ROM中只存放很小的“自举装入程序”，而完整的自举程序放在磁盘的启动块（即引导块/启动分区）上，启动块位于磁盘的固定位置，当计算机开机时，先运行“自举装入程序”，通过执行该程序就可以找到引导块，将完整的“自举程序”读入内存并完成初始化。【拥有启动分区的磁盘称为启动磁盘或系统磁盘】

坏块的管理：坏了、无法使用的扇区就是坏块。这属于硬件故障，操作系统无法修复。应将坏块标记出来，以免错误地使用到它。

​	对于简单的磁盘，可以在逻辑格式化时（建立文件系统时）对整个磁盘进行坏块检查，标明哪些扇区是坏扇区，比如：在FAT表上标明（在这种方式中，坏块对操作系统不透明）。

​	对于复杂的磁盘，磁盘控制器（磁盘设备内部的一个硬件部件）会维护一个坏块链表。

​	在磁盘出厂前进行低级格式化（物理格式化）时就将坏块链进行初始化。

​	保留一些“备用扇区”，用于替换坏块。这种方式称为扇区备用。这种处理方式的坏块对于操作系统透明。

​	5.3.5 SSD固态硬盘

原理：基于闪存技术Flash Memory，属于电可擦除ROM，即EEPROM。

组成：闪存翻译层——负责翻译逻辑块号，找到对应页（Page）。存储介质：多个闪存芯片（Flash Chip），每个芯片内部包含多个块（Block），而每个块包含多个页（Page）

读写性能特性：

​	以页为单位读/写：相当于磁盘的“扇区”；

​	以块为单位“擦除”，擦干净的块，其中的每页都可以写一次，读无限次；

​	支持随机访问，系统给定一个逻辑地址，闪存翻译层可通过电路迅速定位到对应的物理地址。

​	读快、写慢。要写的页如果有数据，则不能写入，需要将块内其他页全部复制到一个新的（擦除过的）块中，在写入新的页。

与机械硬盘相比的特点：

​	SSD读写速度快，随机访问性能高，用电路控制访问；机械硬盘通过移动磁臂旋转磁盘控制访问位置，有寻道时间和旋转延迟；

​	SSD安静无噪音、耐摔抗震、能耗低、造价更贵；

​	SSD的一个”块“被擦除次数过多（重复写同一块）可能会坏掉，而机械硬盘的扇区不会因为写的次数太多而坏掉。

磨损均衡技术：

​	思想：将”擦除“平均分布在各个块上，以提升使用寿命；

​	动态磨损均衡——写入数据时，优先累计擦除次数少的新闪存块；

​	静态磨损均衡——SSD监测并自动进行数据分配、迁移，让老旧的闪存块承担以读为主的存储任务，让较新的闪存块承担更多的写任务。

------







## 2024.12.09 周一

今日上午睡过头，无工作。

今日剩余时间去基法实验室继续学习计算机操作系统，完成相应的笔记至2024.12.08，所有关于计算机操作系统的知识课程已学完。

中间抽空去国重实验室进行洗膜、孵二抗、洗膜、曝光等操作，所有条带曝光出来效果均不好，故未保存实验数据，分析其原因可能是：WB胶放置时间过久、抗体失效、样品放置时间太久，故后续需要重新制备样品、配置新鲜的WB分离胶及浓缩胶再进行。

------





## 2024.12.10 周二

今日一天均在寻找





## 2024.12.11 周三

今日上午学习CS



下午选修CS50x 2024-Lecture1-C，复习C语言的语法，参考视频：https://www.youtube.com/watch?v=cwtpLIWylAw&list=PLhQjrBD2T381WAHyx1pq-sBfykqMBI7V4，傍晚完成该Lecutre的作业：

1.https://cs50.harvard.edu/x/2024/psets/1/mario/less/，代码如下：

```c
#include <cs50.h>
#include <stdio.h>

int main(void)
{
    int n;
    do
    {
        n = get_int("Please input your number: ");
    }
    while (n < 1 || n > 8);
    for (int i = 0; i < n; i++)
    {
        for (int j = 0; j < n; j++)
        {
            if (i + j > n - 1)
            {
                printf("#");
            }
            else
            {
                printf(" ");
            }
        }
        printf("\n");
    }
}
```

2.https://cs50.harvard.edu/x/2024/psets/1/mario/more/，代码如下：

```c
#include <cs50.h>
#include <stdio.h>

int main(void)
{
    int n;
    do
    {
        n = get_int("Please input your number: ");
    }
    while (n < 1 || n > 8);

    for (int i = 0; i < n; i++)
    {
        for (int j = 0; j < n; j++)
        {
            if (i + j + 2 > n)
            {
                printf("#");
            }
            else
            {
                printf(" ");
            }
        }
        printf("  ");
        for (int k = 0; k <= i; k++)
        {
            printf("#");
        }
        printf("\n");
    }
}
```

3.https://cs50.harvard.edu/x/2024/psets/1/cash/

```C
#include <cs50.h>
#include <stdio.h>

int main(void)
{
    int charge;
    int count = 0;

    // Promot user for a non-negative input
    do
    {
        charge = get_int("Please input your charge: ");
    }
    while (charge < 0);

    // Array of coin values in cents
    int coins[] = {25, 10, 5, 1};

    // Calculate the minimum number of coins
    for (int i = 0; i < 4; i++)
    {
        while (charge >= coins[i])
        {
            charge -= coins[i];
            count++;
        }
    }

    // Output the result
    printf("%i\n", count);
    return 0;
}
```

4.https://cs50.harvard.edu/x/2024/psets/1/credit/

```C
#include <cs50.h>
#include <stdio.h>

// Function prototypes
bool luhn_algorithm(long number);
int get_length(long number);
void classify_card(long number);

int main(void)
{
    // Prompt user for credit card number
    long number = get_long("Number: ");

    // Validate car number
    if (luhn_algorithm(number))
    {
        classify_card(number);
    }
    else
    {
        printf("INVALID\n");
    }
    return 0;
}

// Function to Luhn algorithm
bool luhn_algorithm(long number)
{
    int sum = 0;
    int flag = false;

    while (number > 0)
    {
        int digit = number % 10;

        // Double every other digit starting from the second-to-last
        if (flag)
        {
            digit *= 2;
            if (digit > 9)
            {
                digit -= 9;
            }
        }

        sum += digit;
        flag = !flag;
        number /= 10;
    }

    return (sum % 10 == 0); // Card is valid if sum dodulo 10 is 0
}

// Function to get length of a card
int get_length(long number)
{
    int length = 0;
    while (number > 0)
    {
        length++;
        number /= 10;
    }
    return length;
}

// Function to classify the card
void classify_card(long number)
{
    int length = get_length(number);

    // Extract the first two digits and the first digit
    long first_two = number;
    while (first_two >= 100)
    {
        first_two /= 10;
    }
    int first_digit = first_two / 10;

    // Determine card type
    if (length == 15 && (first_two == 34 || first_two == 37))
    {
        printf("AMEX\n");
    }
    else if (length == 16 && (first_two >= 51 && first_two <= 55))
    {
        printf("MASTERCARD\n");
    }
    else if ((length == 13 || length == 16) && first_digit == 4)
    {
        printf("VISA\n");
    }
    else
    {
        printf("INVALID\n");
    }
}
```

这几天一直在学习国外的计算机课程，发现国外的课程赶国内的课程完全是碾压式，果然学习先进的知识还是得向国外靠齐，这一点在目前看来还是没有什么问题。

------





## 2024.12.12 周四

今日上午在家学习托福听力，开始准备进行精听训练。

下午学习C语言复习指针，指针变量实际也是一种特殊的数据结构，指针变量的值是具有实际值的变量的地址。指针也可以作为函数的参数，*是一个单目运算符，用来访问指针的值所表示的地址上的变量，既可以做右值（int k = \*p），也可以做左值（\*p = k + 1）。：

```C
#include <stdio.h>

void f(int *p);
void g(int k);

int main(void)
{
  int i = 6;
  printf("&i=%p\n", &i); // &i=0xbfff17d70
  f(&i); // p=0xbfff17d70, *p=6
  g(i); // k=26
  
  
  return 0;
}


void f(int *p)
{
  printf("p=%p\n", p);
  printf("*p=%d\n", *p);
  *p = 26;
}


void g(int k)
{
  printf("k=%d\n", k);
}
```

指针的应用场景：

- 交换两个变量的值。

```C
#include <stdio.h>

void swap(int *pa, int *pb);

int main(void)
{
  int a = 5;
  int b = 6;
  swap(&a, &b);
  printf("a=%d, b=%d", a, b);
  
  return 0;
}

void swap(int *pa, int *pb)
{
  int t = *pa;
  *pa = *pb;
  *pb = t;
}
```

- 函数需要返回多个值，某些值就只能通过指针返回，传入的参数实际上是需要保存带回的结果的变量。

```c
#include <stdio.h>

void minman(int a[], int len, int *min, int *max);

int main(void)
{
  int a[] = {1,2,3,4,5,6,7,8,9,10,12,25,24,,44,61,55};
  int min, max;
  minmax(a, sizeof(a)/sizeof(a[0]), &min, &max);
  printf()
  
  return 0;
}

void minman(int a[], int len, int *min, int *max)
{
  *min = *max = a[0];
  for (int i = 1; i < len; i++)
  {
    if (a[i] < *min)
    {
      *min = a[i]; //更新最小指针所指的值
    }
    if (a[i] > *max)
    {
      *max = a[i]; //更新最大指针所指的值
    }
  }
}
```

- 函数返回运算的状态，结果通过指针返回。【常用的思路是让函数返回特殊的不属于有效范围内的值来表示出错，例如-1或0，但是当任何数值都是有效的可能结果时，就得分开返回了，后续的语言如C++和Java采用了异常机制来解决这个问题】

```C
#include <stdio.h>

int divide(int a, int b, int *result);

int main(void)
{
  int a = 5;
  int b = 2;
  int c;
  if (divide(a, b, &c))
  {
    printf("%d/%d=%d", a, b, c)
  }
  return 0;
}

int divide(int a, int b, int *result)
{
  int ret = 1;
  if {b == 0} ret = 0;
  else
  {
    *result = a / b;
  }
  return ret;
}
```

注：&用来取地址，\*中用来取值或定义指针。函数的参数为数组的时候，数组其实就是指针（数组变量本身表达地址，无需用&取地址，但是数组的单元表达的是变量，需要用&取地址）【sizeof(a)==sizeof(int\*)，\*p=p[0]】，但是可以用数组的运算符[]进行运算；同样\*也可以对数组进行操作；数组变量const指针，不能进行互相进行赋值（int a[] \<\=\=\> int\* const a，所以不能进行int a[] = b，但是可以int *p = b，其中b为数组，因为a,b为const指针，所以并不能相互赋值）。

注：针对C99，注意\*和const的相对位置：

​	当const位于\*的前面时（const int* p = &i; int const* p = &i），表示指针指向的数据是常量，不能通过指针修改数据；

​	当const位于\*的后面时（int* const p = &i），表示指针本身（指针指向的地址）是常量，不能修改指针指向的地址。

例如：const数组例如const int a[] = {1,2,3,4,5,6};，这里的数组变量a[]已经是const指针，表明数组指向的地址不能被修改，再在前面加上一个const对const指针进行修饰，这就表明数组的每个元素都是const int无法被修改，所以必须通过初始化进行赋值。

指针的运算——可以对指针进行加减整数：

```C
#include <stdio.h>

int main(void)
{
  char ac[] = {0,1,2,3,4,5,6,7,8,9};
  char *p = ac;
  char *p1 = &ac[5];
  printf("p = %p\n", p); //0xbffbad5a
  printf("p+1 = %p\n", p+1); //0xbffbad5b
  printf("*(p+1) = %d\n", *(p+1)); //1
  pinrtf("p1-p=%d\n", p1 - p); //5 两个地址的差/sizeof
  /*
   *p -> a[0]
   *(p+1) -> a[1]
   *(p+n) -> a[n]
  */
  int ai[] = {0,1,2,3,4,5,6,7,8,9};
  int *q = ai;
  int *q1 = &ai[6];
  printf("q = %p\n", q); //0xbffbad2c
  printf("q+1 = %p\n", q+1); //0xbffbad30
  printf("*(q+1) = %d\n", *(q+1)); //1  
  pinrtf("q1-q=%d\n", q1 - q); //6 两个地址的差/sizeof
}
```

指针的类型转换：void\*表示不知道指向什么东西的指针，计算时与char\*相同（但不想通）；指针也可以转换类型:int \*p=&i; void \*q = (void\*)p

注：针对\*p++\：*的优先级虽然高，但是没有++高，在某些CPU上，这可以直接被翻译成一条汇编指令；指针的运算一般用于数组类等具有连续内存空间的操作；

注：0地址问题——内存中有0地址，但是通常是不能随便碰的地址；所以指针不能指向0地址；0地址一般用来表示特殊的事情：返回的指针是无效的、指针没有被真正初始化（先初始化为0）；NULL是一个预定定义的符号，表示0地址：有的编译器不能用0来表示0地址。

注：指针的类型——无论指向什么类型，所有的指针大小都是相同的，因为都是地址。但是只想不同类型的指针不能直接互相赋值，这是为了避免用错指针。

指针的用途：需要传入较大的数据时用作参数；传入数组后对数组进行操作；函数返回不止一个结果：需要用函数来修改不止一个变量；动态申请内存。

动态内存分配：

```C
#include <stdio.h>
#include <stdlib.h>

int main(void)
{
  int number;
  int* a;
  printf("Input number: ")；
  scanf("%d", &number);
  // int a[number]; //C99
  // C99 before
  // memory allocation requery
  a = (int*)malloc(number*sizeof(int));
  for (i = 0; i < number; i++)
  {
    scanf("%d", &a[i]);
  }
  for (i = number - 1; i >= 0; i--)
  {
    printf("%d", a[i]);
  }
  // release memory
  free(a);
  return 0;
}
```

malloc函数：使用前需要引用\<stdlib.h\>头文件，语法：void\* malloc(size_t)，注意向malloc申请的空间的大小是以字节为单位的，返回的结果是void\*，需要类型转换为自己需要的类型。

free函数：把申请得来的空间还给操作系统；申请过的空间，都需要换，且只能还申请来的空间地址。

常见问题：a.使用了malloc函数，但是没有进行free操作，长时间运行内存逐渐下降；c.free函数使用后再次进行free操作；c.malloc函数申请的地址被修改后直接去free操作。

傍晚给小鼠进行脱毛以及给CT26-luc细胞系换液，明天准备进行皮下瘤接种。

然后完成课题组标书任务。

------





## 2024.12.13 周五

今日上午睡觉休息，无其他事项。

中午消化CT26-luc细胞系，制备成细胞悬液，给小鼠进行皮下瘤注射，每只小鼠两个接种点，每个接种点接种细胞数量$1.0*10^6/50ul$。

下午继续学习C语言指针部分，完成笔记至2023.12.14部分，然后继续学习字符串：

在C语言中字符串是以0结尾的一串字符（0或‘\0’是一样的，但是和‘0’不同），0标志着字符串的结束，但它不是字符串的一部分（计算字符串长度的时候不包含这个0）。字符串是以数组的形式存在，以数组或指针的形式访问（更多的是以指针的形式；不能用运算符对字符串做运算；通过数组的方式可以遍历字符串）。string.h里有很多处理字符串的函数。

```c
#include <stdio.h>

int main(void)
{
  char* s = "Hello, World!"; //s是一个指针，初始化为指向一个字符串向量；实际上s是const char* s，由于历史原因，编译器接受不带const的写法。
  char* s2 = "Hello, World!";
  s[0] = 'B'; //试图对s所指的字符串做写入会导致严重的后果。
  
  //如果需要修改字符串，应该用数组的形式
  char string[] = "Hello, World!";
  string[0] = "B";  
    
  printf("s = %p\n", s);
  printf("s2 = %p\n", s2); 
  printf("Here!s[0] = %c\n",s[0]); // 编译报错；
  printf("Here!string[0] = %c\n", string[0]); //编译通过，运行成功
}
```

需要定义字符串的时候，是用指针还是数组？——数组：这个字符串在这里，作为本地变量空间自动被回收；指针：这个字符串不知道在哪里，多用于处理参数和动态分配空间；

字符串的输入输出：

```C
#include <stdio.h>

int main(void)
{
  char word[8];
  char word2[8];  
  scanf("%s", word); //Hello World!
  scanf("%s", word2);
  
  // 安全的方式
  scanf("%7s", word)
  printf("%s##%s##\n", word, word2); //Hello##World!
  
  return 0;
}
```

scanf读入一个单词（到空格、tab或回车为止），这种方式是不安全的：因为不知道要读入的内容的长度。如果需要安全的输入，需要在%和s之间插入一个数字，这个数字表示最多允许读入的字符的数量，这个数字应该比数组的大小小一（字符串以0为结尾）。

字符串数组：

字符串数组的定义：

```c
#include <stdio.h>

int main(void)
{
  a[0] --> char*
  
  char *a[] = {
    "Hello",
    "World",
    "!"
  }
  
  return 0;
}
```

字符串数组可以作为（主）程序参数

```c
#include <stdio.h>

int main(int argc, char const *argv[])
{
  int i;
  for (i = 0; i < argc; i++)
  {
    printf("%d:%s\n", i, argv[i]);
  }
  
  return 0;
}  
```

argv[0]是命令本身，当使用Unix的符号链接时，反应符号链接的名字。

单字符的输入输出：

int putchar(int c);向标准输出写一个字符，返回写了几个字符，EOF(-1)表示写失败。

int getchar(void);从标准输入读入一个字符，返回类型是int是为了返回EOF(-1)。

```c
#include <stdio.h>

int main(int argc, char const *argv[])
{
  int ch;
  
  while ((ch = getchar())!= EOF)
  {
    putchar(ch)
  }
  
  printf("EOF\n");
  
  return 0;
}
```

字符串函数(使用需先引入string.h)：

strlen：size_t strlen(const char \*s);返回s的字符串长度，不包括结尾的0；

```c
#include <stdio.h>
#include <string.h>

int mylen(const char* s)
{
  int idx = 0;
  while (s[idx] != '\0')
  {
    idx++;
  }
  
  return idx;
}

int main(int argc, char const *argv[])
{
  char line[] = "Hello";
  printf("strlen=%lu\n", mylen(line)); //5
  printf("sizeof=%lu\n", sizeof(line)); //6
}
```

strcmp：int strcmp(const char\* s1, const char\* s2 );用于避哦啊叫两个字符串，返回值：

- 0:s1==s2
- 1:s1>s2
- -1:s1<s2

```c
#include <stdio.h>
#include <string.h>

int mycmp(const char *s1, const char *s2)
{
  // int idx = 0;
  // while( s1[idx] == s2[idx] && s1[idx] != '\0' )
  // {
  //   idx++;
  // }
  // return s1[idx]-s2[idx];
  while (*s1 == *s2 && *s1 != '\0')
  {
    s1++;
    s2++;
  }
  return *s1 - *s2;
}


int main(int argc, char const *argv[])
{
  char s1[] == "abc";
  char s2[] == "abc";  
 	printf("%d\n", strcmp(s1, s2)); //0
  
  char s3[] == "abc";
  char s4[] == "Abc";  
  printf("%d\n", strcmp(s1, s2)); //32
  printf("%d\n", 'a'-'A'); //32  
  printf("%d\n", mycmp(s1, s2)); //32
   
  return 0;
}
```

strcpy：char * strcpy(char \*restrict dst, const char \*restrict src);把src的字符串拷贝到des，restrict表明src和dst不重叠（C99），返回dst。

复制一个字符串：char \*dst = (char\*)malloc(strlen(src)+1); strcpy(dst, src);

```c
#include <stdio.h>
#include <string.h>

char* mycpy(char* dst, char* src)
{
  // int idx = 0;
  // while (src[idx])
  // {
  //	 dst[idx] = src[idx];    
  //   idx++;
  // }
  // dst[idx] = '\0';
  // return dst;
  char* ret = dst;
  while (*src)
  {
    *dst++ = *src++;
  }
  *dst = '\0';
  
	return ret;
}

int main(int argc, char const *argc[])
{
  char s1[] = "abc";
  char s1[] = "abc";
  strcpy(s1, s2);
  
  return 0;
}
```

字符串中找字符：char \* strchr(const char \*s, int c)，char \* strrchr(const char \*s, int c)。返回NULL表示没有找到。

```c
#include <stdio.h>
#include <string.h>

int main(int argc, char const *argv[])
{
	// char s[] = "hello";
  // char *p = strchr(s, 'l');
  // printf("%s\n", p); //llo
  // p = strchr(p+1, 'l');
  // printf("%s\n", p); //lo
  
  char s[] = "hello";
  char *p = strchr(s, 'l');
  char c = *p;
  *p = '\0'
  char *t = (char*)malloc(strlen(p)+1);
  strcpy(t, p);
  printf("%s\n", t); // he 
  free(t);
  
  return 0;
}
```

字符串中找字符串：char \* strstr(const char \*s1, const char \* s2)，char \* strcasestr(const char \*s1, const char \* s2);

枚举：是一种用户定义的数据类型，用关键字enum定义。枚举的意义就是给常量一些名字。

```c
#include <stdio.h>

enum COLOR {RED, YELLOW, GREEN};

int main(int argc, char const *argv[])
{
  int color = -1;
  char *colorName = NULL;
  
  printf("输入你最喜欢的颜色的代码： ");
  scanf("%d", &color);
  switch ( color )
  {
    case RED: colorName = "red"; break;
    case YELLOW: colorName = "yellow"; break;
    case GREEN: colorName = "green";break;
    default: colorName = "unknown";break;
  }
  printf("你最喜欢的颜色是%s\n", colorName);
  
  return 0;
}
```

注：枚举类型名字通常并不真的使用，要用的是在打括号里的名字，因为它们就是常量符号，它们的类型是int，默认值以此从0到n，当然也可以指定值例如enum COLOR {RED=1, YELLO, GREEN = 5};。

晚上回家继续进行项目结题发表论文引用情况挖掘。

------





## 2024.12.14 周六

今日上午



下午学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture1:Algorithms and Computation（Instructor: Jason Ku）:

​	The goal of this introductions to algorithms class is to teach you to solve computation problems and communicate that your solutions are correct and efficient. Models of computation, data structures, and algorithms are introduced

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-1-algorithms-and-computation/

和Lecture2:Data Structures and Dynamic Arrays（Instructor: Erik Demaine）：

​	Data structures are ways to store data with algorithms that support operations on the data. These collection of sorted operations are interfaces. This class goes over two main interfaces: sequence and set.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-2-data-structures-and-dynamic-arrays/

key: word RAM model of computation:

- memory = array of w-bit words
- "array" = consecutive chunk of memory

So array[i] = memory[address(array) + i] and array access is $O(1)$ time when we assume that w $\ge$ lgn, where n is the length of that array.



```python
reorder_students(L):
  """
  	Input:L      | linked list with head L.head and size L.size
  	Output: None |
  	This function should modify list L to reverse its last half.
  	Your solution should NOT instantiate:
  		-any addtional linked list nodes;
  		-any other non-constant-sized data structures;
  """
  n = len(L) // 2;
  a = L.head;
  for

  return ;
```

------





## 2024.12.15 周日

今日一天都在国重会议室、校图书馆、基法实验室做PPT，主要做成的任务图（经典与代偿抗氧化体系）如下：





无其他事项。

------





## 2024.12.16 周一

今日上午休息，昨日做PPT消耗太多脑力。

中午及下午继续学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture3:



抽空去基法实验室查看之前皮下双边瘤种植状态，目前肿瘤还是成小丘形态，并没有长到实验标准。

------





## 2024.12.17 周二

今日上午继续休息。

中午出发去锦城实验室参加曝光仪的培训，然后学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture5:Linear Sorting

​	This builds on the lecture on improving find times and discusses how to achieve a faster sort. Direct access array sorts, tuple sorts, counting sorts, and radix sorts are discussed.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-5-linear-sorting/

Counting sorts的C语言实现：

```c
#include <stdlib.h>
#include <string.h>

int ctsort(int *data, int size, int k)
{
  int *counts, 
  		*temp;
  int i, j
  
  // allocate memory address to counting array
  if ((counts = (int *)malloc(k * sizeof(int))) == NULL)
    return -1;
  
  // allocate template memory address to Sorted elements
  if ((temp = (int *)malloc(size * sizeof(int))) == NULL)
    return -1;
  
  // initiate counting array
  for (i = 0; i < k; i++)
  {
    counts[i] = 0;
  }
  
  for (j = 1; j < size; j++)
  {
    counts[data[j]] = counts[data[j]] + 1;
  }
  
  // key codes: 
  for (j = size - 1; j >= 0; j--)
  {
    temp[counts[data[j]]-1] = data[j];
    counts[data[j]] = counts[data[j]] - 1;
  }
  
  // copy sorted elements into data from temp
  memcpy(data, temp, size * sizeof(int));
  
  // release memory
  free(counts);
  free(temp);
  
  return 0;
}
```





------





## 2024.12.18 周三

今日上午学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture6:Binary Trees, Part 1（Instructor: Erik Demaine）：

​	This is the first of two lectures on binary trees. This lecture discusses binary tree terminology, tree navigation, and dynamic operations. These are explored in two applications: sets and sequences.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-6-binary-trees-part-1/

补充：中序遍历（Inorder search）【**中序遍历**（Inorder Traversal）是二叉树的一种遍历方式，它按照 **左子树 → 根节点 → 右子树** 的顺序访问树中的节点。】的C语言实现：

```c
#include <stdio.h>

struct Node {
  int key;
  struct Node* left;
  struct Node* right;
};

void inorderTraversal(struct Node* root)
{
  if (root == NULL) return;
  
  // search left subtree
  inorderTraversal(root -> left);
  
  // search root node
  print("%d", root -> key);
  
  // search right subtree
  inorderTraversal(root -> right);
}
```

```c
#include <stdio.h>
#include <stdlib.h>

struct Node {
  int key;
  struct Node* left;
  struct Node* right;  
}

struct Stack {
  struct Node* data;
  struct Stack* next;
}

// push function
void push(struct Stack** top, struct Node* node)
{
  struct Stack* newNode = (struct Stack*)malloc(sizeof(struct Stack));
  newNode -> data = node;
  newNode -> next = *top;
  *top = newNode;
}

//pop function
struct Node* pop(struct Stack** top)
{
  if (*top == NULL) return NULL;
  struct Stack* temp = *top;
  struct Node* result = temp -> data;
  *top = temp -> next;
  free temp;
  return result;
}

// inorder search
void inorderTraversal(struct Node* root)
{
  struct Stack* stack = NULL; // initiate stack
  struct Node* current = root;
  
  while (current != NULL || stack != NULL)
  {
    // push left subtree into stack one by one
    while (current != NULL)
    {
      push(&stack, current);
      current = current -> left;
    }
    
    // pop stack top
    current = pop(&stack);
    printf("%d", current -> key);
    
    // search right subtree
    current = current -> right;
  }
}
```

以及BST的insert_node和delete_node方法：

```c

```

MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture 7: Binary Trees, Part 2: AVL（Instructor: Erik Demaine）：

​	This is the second lecture on binary trees. This covers subtree augmentation and sequence binary trees with subtree sizes. Rotations, rebalancing, and height augmentation are used to achieve height balance (AVL).

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-7-binary-trees-part-2-avl/

下午完善MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms的课程笔记至每处的相应位置。

晚上和家欢师姐和她爱人、蒋军师兄吃饭，饭后回来思考是否要用Latex记录一下这些年对于生物、数学、物理、计算机等融合产生的思想火花已经对于建立严密的**生物符号表示及相应运算逻辑体系**，我觉得可行，先思考第一小节的内容需要写什么。

回家碎片化学习Transformer模型的简单代码实现（Demo）【https://zhuanlan.zhihu.com/p/694373104】：

Transfomer组件的实现需要先运行位置编码（Position ）、多头注意力机制（Multi-head attention）和前馈网络的代码，然后是编码器（Encoder）、解码器和Transformer架构：

1.位置编码：

​	在Transformer出现以前，NLP任务大多是RNN、LSTM为代表的循环处理方式，即一个token一个token的输入到模型当中。模型本身是一种顺序结构，自然就包含了token的顺序信息。有以下的缺陷：

​	a.“遗忘”现象：无法支持长时间序列，虽然LSTM在一定程度上缓解了这种现象，但是这种缺陷仍然存在；

​	b.句子越靠后的token对结果的影响越大；

​	c.只能利用上文信息，不能获取下文信息；

​	d.算法时间复杂度较高$O(n)$，其中n为token数量，因为循环网络是一个个token输入，token有多少，就要循环多少

Transformer把token的顺序信号加到词向量上帮助模型学习信息，关键的问题如何对这些词向量赋予恰当的位置信息，所以涉及到位置编码（Positional Encoding）：

位置编码分为两个类型：绝对位置编码/相对位置编码

​	绝对位置编码：为序列中的每个位置分配一个唯一的编码，这种编码直接反映了元素在序列中的绝对位置。顺序编码：从1开始向后每个token的位置编码依次加1，如我爱人工智能的编码依次为123456。但是这种方式存在很大的问题，句子越长，后面的值越大，相应所占的权重也就越大，这样的方式无法凸显每个位置的真实权重。目前常用的两种方式：

a.基于正弦和余弦函数的编码：由Transformer提出，根据正余弦函数中的不同频率来为序列的每个位置生成唯一的编码。优点：支持任意长度的序列，并且模型可以从编码中推断出信息位置。

b.可学习的位置编码：一些模型选择通过训练过程中学习位置编码，而不是使用预定义的函数。这种方式允许模型自适应地优化位置编码，以最适合特定的任务。但是这种一般需要固定输入的长度，而且可解释性较差（全是高位矩阵数据，可读性较差）

​	相对位置编码：函数型位置编码通过输入token的位置信息得到编码信息。这种编码方式使模型能够关注元素之间的相对位置关系。

位置编码应有的特点：

​	a.每个时间步都有唯一的编码；

​	b.在不同长度的句子中，两个时间布之间的距离应该一致；

​	c.模型不受句子长短的影响，并且编码范围是有界的；

​	d.同一时间序列中，每个连续的编码应该是等步长的，即线性相关的；

​	e.位置编码应该能够表示token的绝对或相对位置关系；

Transformer编码公式——**使用正余弦函数表示绝对位置，通过两者乘积得到相对位置**：
$$
\text{PE}_{pos,2i}=\sin(\frac{pos}{10000^{\frac{2i}{d_model}}}) \\
\text{PE}_{pos,2i+1}=\cos(\frac{pos}{10000^{\frac{2i}{d_model}}})
$$
其中$\text{PE}$表示位置编码，$pos$表示一句话中token的位置，每个token的位置编码是一个向量（或者叫embedding），$i$表示这个向量中每个元素的index，$d_{model}$表示位置编码向量的长度，直观来看：
$$
\text{PE}_{pos}=\begin{bmatrix}
\sin(\omega_1 \cdot pos) \\
\cos(\omega_1 \cdot pos) \\
\sin(\omega_2 \cdot pos) \\
\cos(\omega_2 \cdot pos) \\
... \\
... \\
\sin(\omega_{\frac{d}{2}} \cdot pos)\\
\cos(\omega_{\frac{d}{2}} \cdot pos)	
\end{bmatrix}
$$
其中$\omega_i = \frac{1}{10000^{\frac{2i}{d_{model}}}}$，可以说每个位置编码向量都是sin和cos的交替。

问题：编码因子$\omega_i$的意义——**指数级频率变化**（指数函数允许位置编码在非常宽的频率范围内分布，从非常低的频率到非常高的频率）；**平滑频率变化**（$d_{model}$越大$\frac{2i}{d_{model}}$越小，那么$\Delta\frac{2i}{d_{model}}$就越小，那么相对于$pos$的变化即$\frac{pos}{10000^{\frac{2i}{d_{model}}}}$的变化比率更小，频率变化缓慢，有助于模型在学习过程中不会对位置的微小变化过度敏感，从而更好地泛化，特别是当处理长序列的时候平滑的频率变化意味着在序列远端，位置编码仍然能够有效区分不同的位置，提高位置编码的敏感度）；**远程衰减性**（随着两个token相对距离的增加，它们的相关性越来越弱，呈现出远程衰减性）；**10000是一个经验选择的常数**（用于调节频率的下降速度，这个数越大下降速度就越慢，选取一个足够大的数，以确保即使在模型纬度很大时，频率的变化也能覆盖一个广泛的范围）

```python
# import libraries
import math
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F


class PositionalEncoding(nn.Module):
	def __init__(self, d_model, max_len = 5000):
    """
    :param d_model: dimension of the token
    :param 
    """
    super(PositionalEncoding, self).__init__()
    
    # compute position coding
    pe = torch.zeros(max_len, d_model)
    position = torch.arrange(0, max_len, dtype=torch.float).unsqueeze(1)
    div_term = torch.exp(torch.arrange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))
		pe[:, 0::2] = torch.sin(position * div_term)
    pe[:, 1::2] = torch.cos(position * div_term)
    pe = pe.unsqueeze(0)
    self.register_buffer('pe', pe)
    
  def forward(self, x):
    x = x + x + self.pe[;, :x.size(1)]
    return x
  
# Example
d_model = 512
max_len = 100
num_heads = 8

# 位置编码
pos_encoder = PositionalEncoding(d_model, max_len)

# 示例输入序列
input_sequence = torch.randn(5, max_len, d_model)

# 
input_sequence = pos_encoder(input_sequence)
print("Position coding of input sequence:")
print(input_sequence.shape)  
```

详细参考资料：https://blog.csdn.net/xian0710830114/article/details/133377460；https://blog.csdn.net/qq_23022733/article/details/141184336

------





## 2024.12.19 周四

今日上午继续学习Transformer模型的位置编码，并完成笔记至昨日相应的部分。

中午再次加深Transformer模型的复习，参考视频：https://www.bilibili.com/video/BV1gapwegE2R/



下午进行PyTorch中的Transformer层实现，参考视频：https://www.bilibili.com/video/BV1wPp3enEtQ/：

在PyTorch中，Transformer算法是属于“构建循环神经网络的元素”，而非“成熟神经网络”，因此Transformer是位于PyTorch.nn这个基本模块下的。事实上，在PyTorch中并没有完整的Transformer架构，只有用于构建Transformer的各个层：

<img src="./assets/TransformerModelArchitecture.png" alt="TransformerModelArchitecture" style="zoom:25%;" />

在`torch.nn`模块下，存在服务于Transformer架构的各类神经网络层和模型：

| 类名称                                           | 作用                                                         |
| :----------------------------------------------- | ------------------------------------------------------------ |
| `nn.Transformer`                                 | 不带输入层与输入层的Transformer模型，同时具备编码器和解码器  |
| `nn.TransformerEncoder`                          | Transformer编码器的堆叠层，可以控制Nx的N的具体数字           |
| `nn.TransformerDecoder`                          | Transformer解码器的堆叠层，可以控制Nx的N的具体数字           |
| `nn.TransformerEncoderLayer`                     | Transformer编码器层，由自注意力和前馈网络组成                |
| `nn.TransformerDecoderLayer`                     | Transformer解码器层，由自注意力、编码器-解码器注意力和前馈网络组成 |
| `nn.MultiheadAttention`                          | 多头注意力机制                                               |
| `nn.LayerNorm`                                   | 层归一化层                                                   |
| `nn.Embedding`                                   | 嵌入层，用于将输入序列转换为嵌入表示                         |
| `nn.Transformer.generate_square_subsequent_mask` | 掩码函数。用于生成一个方形矩阵，用于Transformer模型中自注意力机制的上三角遮罩 |

重点就是`nn.TransformerEncoderLayer`和`nn.TransformerDecoderLayer`，这两个层赋予Transformer极高的灵活性。

- `torch.nn.TransformerEncoderLayer(d_mode, nhead, dim_feedforward=2048, dropout=0.1, activation=\<function relu\>, layer_norm_eps=1e-05, batch_first=False, norm_first=False, bias=True, device=None, dtype=None)`

| 参数              | 说明                                                         |
| ----------------- | ------------------------------------------------------------ |
| `d_model`         | 输入的嵌入维度（Embedding过程中规定的特征维度），数学公式中的$d_k$ |
| `nhead`           | 多头注意力机制中的头数，在代码中通常表示为num_heads          |
| `dim_feedforward` | 前馈网络的隐藏层维度，默认值为2048                           |
| `dropout`         | Dropout概率，默认值为0.1。在Transformer架构图中虽然没有展现dropout层，但是业内习惯讲Dropout层放置在每一个复杂结构之后，在Encoder中，Dropout出现在自注意力层后、残差链接之前，也出现在前馈神经网络后、残差链接之前 |
| `activation`      | 激活函数，默认值为`relu`                                     |
| `layer_norm_eps`  | 层归一化的epsilon值，默认值为1e-05                           |
| `batch_first`     | 如果为`True`，则输入和输出的张量形状为（batch_size, seq_len, feature），否则为（seq_len, batch_size, feature）。默认值为`False` |
| `norm_first`      | 如果为`True`，则执行前馈网络之前进行层归一化。默认值为`False` |
| `bias`            | 如果为`True`，则在线性层使用偏置，默认值为`True`             |
| `device`          | 指定层的设备，默认值为`None`                                 |
| `dtype`           | 指定层的数据类型，默认值为`None`                             |

```python
import torch
import torch.nn as nn
encoder_layer = nn.TransformerEncoderLayer(d_model = 512, nhead = 8, batch_first = True)
src = torch.rand(32, 10, 512)
out = encoder_layer(src)
out.shape # torch.Size([32, 10, 512])
```

`torch.nn.TransformerEncoderLayer`实例化后可以输入的内容有：

| 参数                   | 说明                                                         |
| ---------------------- | ------------------------------------------------------------ |
| `src`                  | 输入到编码器层的序列（必填）                                 |
| `src_mask`             | 输入序列的掩码矩阵（可选），默认接受形状为（seq_len, seq_len）的二维矩阵，通常该参数默认是执行前瞻掩码，在encoder中很少使用 |
| `src_key_padding_mask` | 输入序列的填充掩码矩阵（可选），默认接受形状为（batch_size, seq_len）的二维矩阵，这个参数只提供给填充掩码使用 |

```python
def create_padding_mask_1(seq, pad_token = 0):
  # seq: (batch_size, seq_len, embedding_dim)
  # 检查填充位置
  padding_mask = (seq == pad_token).all(dim = -1) # (batch_size, seq_len)
  padding_mask = padding_mask.float() * -1e9
  
  return padding_mask

def create_padding_mask_2(seq, pad_token = 0):
  # seq: (batch_size, seq_len)
  # 创建一个与输入序列形状相同的掩码
  padding_mask = (seq == pad_token).float() * -1e9 # (batch_size, seq_len)
  
  return padding_mask

def creat_look_ahead_mask(seq_len, start_seq = 1):
  mask = torch.triu(torch.ones((seq_len, seq_len)), diagnoal = start_seq)
  mask = mask.float * -1e9 #将未来的位置设置为无穷大
  
  return mask # (seq_len, seq_len)

src.shape # torch.Size([32, 10 ,512])
src_key_padding_mask = create_padding_mask_1(src, pad_token = 0)
src_mask = create_look_ahead_mask(10, start_seq = 1)
src_key_padding_mask.shape # torch.Size([32, 10])
src_mask.shape # torch.Size([10, 10])

encoder_layer(src, 
              src_mask =src_mask,
             	src_key_padding_mask = src_key_padding_mask).shape # torch.Size([32, 10 ,512])

```

傍晚及晚上开始学习C++：如何安装C++（Windows/Mac/Linux）、C++编译器是如何工作的（它将获取源文件并输出一个.obj文件，obj文件是包含机器代码的文件以及其它我们定义的常数数据，然后将这些obj文件链接成一个包含所有内容的可执行文件中，可执行文件是包含了需要允许的机器代码）、C++链接器是如何工作的。

复习前馈网络（FeedForward Neural Network）：

A FeedForward Neural Network (FFN) is designed to map input data to an output through a series of layers. Each layer consists of neurons that perform linear transformations and apply activation functions to introduce non-linearity. 

Properties:

​	**Layers**: An FFN consists of an input layer, one or more hidden layers, and an output layer.

​	**Forward Pass**: Data flows in one direction, from the input layer through the hidden layers to the output layer.

​	**No Cycles**: There are no cycles or loops in the network, meaning the connections do not form a directed cycle.

​	**Activation Functions**: Each neuron in the hidden layers typically uses an activation function like ReLU, Sigmoid, or Tanh to introduce non-linearity.

​	**Training**: FFNs are typically trained using backpropagation, a method for calculating the gradient of the loss function and adjusting the weights to minimize the error.

```python
import torch
import torch.nn as nn
import torch.optim as optim

# Define the structure of the FFN
class FFN(nn.Module):
  def __init__(self, input_size, hidden_size, output_size):
    """
    The FFN class defines a simple feedforward neural network with one hidden layer.
    """
    super(FFN, self).__init__()
    self.fc1 = nn.Linear(input_size, hidden_size) 	# First fully connected layer
    self.relu = nn.ReLU()														# Activation function
    self.fc2 = nn.Linear(hidden_size, output_size)	# Second fully connected layer
    
  def forward(self, x):
    x = self.fc1(x)
    x = self.relu(x)
    x = self.fc2(x)
    
# Example usage
input_size = 3
hidden_size = 5
output_size = 2

# Create an instance of the FFN
model = FFN(input_size, hidden_size, output_size)

# Define a loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr = 0.01)

# Example input and target output
inputs = torch.tensor([[1.0, 2.0, 3.0]])
targets = torch.tensor([[0.5, 1.5]])

# Forward pass: Compute predicted outputs by passing inputs to the model
outputs = model(inputs)
loss = criterion(outputs, targets)

# Backward pass: Compute gradients of the loss with respect to model parameters
loss.backward()

# Update model parameters
optimizer.step()

print(f"Predicted outputs: {outputs}")
```

​	

------





## 2024.12.20 周五

今日上午睡觉休息大脑，无其他事项。

中午及下午在基法实验室学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture8: Binary Heaps（Instructor: Erik Demaine）：

​	Prof. Demaine discusses priority queue interfaces and sorting algorithms. Algorithms include AVL sort for set AVL trees, selection sort for arrays, insertion sort for sorted arrays, and heap sort for binary heaps.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-8-binary-heaps/

但是发现好像少了Binary Heaps Data Structure的学习，略微有点难懂，故先复习Heaps结构：

Heaps结构的C++代码实现（https://www.geeksforgeeks.org/binary-heap/）：

```c++
// A C++ program to demonstrate Common Binary Heap Operations
#include<iostream>
#include<climits>
using namespace std;

// Prototype of a utility function to swap two integers
void swap(int *x, int *y);

// A class for Min Heap
class MinHeap
{
  int *harr; // pointer to array of elements in heap
  int capacity; // maximum possible size of min heap
  int heap_size; // current number of elements in min heap
  // Constructor
  MinHeap(int capacity);
  
  // to heapify a subtree with the root at given index
  void MinHeapify(int i);
  
  int parent(int i) {return (i - 1) / 2};
  
  // to get index of left child of node at index i
  int left(int i) {return (2*i + 1)};
  
  // to get indexo of right child of node at index i
  int right(int i ) {return (2*i + 2)};
  
  // to extract the root which is the minimum element
  int extractMin();
  
  // Decreases key value of key at index i to new_val
  void decreaseKey(int i, int new_val);
  
  // Returns the minimum key(key at root) from min heap
  int getMin(){return harr[0]};
  
  // Deletes a key stored at index i
  void deleteKey(index i);
  
  // Insert a new key 'k'
  void insertKey(int k)
}

// Constructor: Builds a heap from a given array a[] of given size
MinHeap::MinHeap(int cap)
{
  heap_size = 0;
  capacity = cap;
  harr = new int[cap];
}

//Insert a new key 'k'
void insertKey(int k)
{
  // check whether it is overflow
  if (heap_size == capacity)
  {
    count << "\nOverflow: Could not insertKey\n";
    return;
  }
  
  // Firstly, insert the new key at the end;
  heap_size++;
  int i = heap_size-1;
  harr[i] = k
  
  // Secondly, fix the min heap property if it is violated
  while (i != 0 && harr[parent(i)] > harr[i])
  {
    swap(&harr[i], &harr[parent(i)]);
    i = parent(i);
  }
}

// Decreases value of key at index 'i' to new_val. It is assumed that
// new_val is smaller than arr[i].
void Minheap::decreaseKey(int i, int new_val)
{
  harr[i] = new_val;
  while (i != 0 && harr[parent(i)] > harr[i])
  {
    swap(&harr[i], &harr[parent(i)]);
    i = parent(i);
  }
}

// Method to remove minimum element (or root) from min heap
int MinHeap::extractMin()
{
  if (heap_size <= 0)
    return INT_MAX;
  if (heap_size == 1)
  {
    heap_size--;
    return harr[0];
  }
  
  // Store the minimum value, and remove it from heap
  int root = harr[0];
  harr[0] = harr[heap_size - 1];
  heap_size--;
  MinHeapify(0);
  
  return root;
}

// This function deletes key at index i. It first reduced value to minus
// infinite, then calls extractMin()
void MinHeap::deleteKey(int i)
{
    decreaseKey(i, INT_MIN);
    extractMin();
}

// A recursive method to heapify a subtree with the root at given index
// This method assumes that the subtrees are already heapified
void MinHeap::MinHeapify(int i)
{
    int l = left(i);
    int r = right(i);
    int smallest = i;
    if (l < heap_size && harr[l] < harr[i])
        smallest = l;
    if (r < heap_size && harr[r] < harr[smallest])
        smallest = r;
    if (smallest != i)
    {
        swap(&harr[i], &harr[smallest]);
        MinHeapify(smallest);
    }
}

// A utility function to swap two elements
void swap(int *x, int *y)
{
    int temp = *x;
    *x = *y;
    *y = temp;
}

// Driver program to test above functions
int main()
{
    MinHeap h(11);
    h.insertKey(3);
    h.insertKey(2);
    h.deleteKey(1);
    h.insertKey(15);
    h.insertKey(5);
    h.insertKey(4);
    h.insertKey(45);
    cout << h.extractMin() << " ";
    cout << h.getMin() << " ";
    h.decreaseKey(2, 1);
    cout << h.getMin();
    return 0;
}
```

二叉堆的实际应用：算法题——给定一个长度为`n`的无序数组，返回数组中最大的`k`个元素（以下使用java语言实现）：

方法一：使用**排序**——对数组进行排序，然后取出最大的 `k` 个元素。时间复杂度为 `O(n log n)`

```java
import java.util.Arrays;

public class KLargestElements{
  public static int[] findKLargest(int[] nums, int k){
    Array.sort(nums); // 数组排序
    int[] result = new int[k];
    for (int i = 0; i < k; i++){
      result[i] = nums[nums.length - i - 1];
    }
    
    return nums;
  }
}
```

方法二：**遍历选择**——进行k轮遍历，分别在每轮中提取最大的元素，时间复杂度为`O(nk)`

```java
public class KLargestElements{
  public static int[] findKLargest(int[] nums, int k){
    int n = nums.length;
    int[] result = new int[k];
    
    // 找到最大的k个元素
    for (int i = 0; i < k; i++){
      int maxIndex = i;
      // 遍历剩余的元素，找到最大的元素
      for (int j = i + 1; j < n; j++){
        if (num[j] > nums[maxIndex]){
          maxIndex = j;
        }
      }
      //交换当前最大值与i位置的元素
      swap(nums, i, maxIndex);
      result[i] = nums[i]; // 记录找到的最大值
  	}
    
    return result;
	}


// swap function
	private static void swap(int[] nums, int i, int j) {
    	int temp = nums[i];
    	nums[i] = nums[j];
    	nums[j] = temp;
	}
}
```

方法三：使用**堆**——初始化一个堆，起堆顶的元素最小；先将数组的前k个元素依次入堆，然后从k+1个元素开始，若当前元素大于堆顶元素，则将堆顶元素出栈，并将当前元素入栈；遍历完成后，堆中保存的就是最大的k个元素。（堆排序，Heap Sort）

```java
import java.util.PriorityQueue;

public class KLargestElements {
	public static int[] findKLargest(int[] nums, int k) {
    // 使用一个最小堆来保存最大的k个元素
    PriorityQueue<Integer> minHeap = new PriorityQueue<>(k);
    
    for (int num : nums){
      if (minHeap.size() < k){
        minHeap.offer(nums); // 堆中元素少于k时直接插入
      } else if (num > minHeap.peek()){
        minHeap.poll(); // 如果堆已满且当前元素更大，移除最小元素
        minHeap.offer(num); // 添加当前元素至堆中
      }
    }
    
    int[] result = new int[k];
    for (int i = 0; i < k; i++){
      result[i] = minHeap.poll(); // 取出堆中的元素
    }
    
    return result;
	}
}
```

傍晚及晚上学习：MLCB2024-Lecture01-Introduction（instructor: Manolis Kellis），地址链接：https://www.youtube.com/watch?v=1zZSPeKGRzw；MLCB2024-Lecture02-Expression Analysis Clustering Classification（instructor: Manolis Kellis），地址链接：https://www.youtube.com/watch?v=Air6zIVf0M8

并复习K-means clustering算法，然后学习Python的代码：

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from numpy.random import uniform
from sklearn.datasets import make_blobs
import seaborn as sns
import random
def euclidean(point, data):
    """
    Euclidean distance between point & data.
    Point has dimensions (m,), data has dimensions (n,m), and output will be of size (n,).
    """
    return np.sqrt(np.sum((point - data)**2, axis=1))
class KMeans:
    def __init__(self, n_clusters=8, max_iter=300):
        self.n_clusters = n_clusters
        self.max_iter = max_iter
    def fit(self, X_train):
        # Initialize the centroids, using the "k-means++" method, where a random datapoint is selected as the first,
        # then the rest are initialized w/ probabilities proportional to their distances to the first
        # Pick a random point from train data for first centroid
        self.centroids = [random.choice(X_train)]
        for _ in range(self.n_clusters-1):
            # Calculate distances from points to the centroids
            dists = np.sum([euclidean(centroid, X_train) for centroid in self.centroids], axis=0)
            # Normalize the distances
            dists /= np.sum(dists)
            # Choose remaining points based on their distances
            new_centroid_idx, = np.random.choice(range(len(X_train)), size=1, p=dists)
            self.centroids += [X_train[new_centroid_idx]]
        # This initial method of randomly selecting centroid starts is less effective
        # min_, max_ = np.min(X_train, axis=0), np.max(X_train, axis=0)
        # self.centroids = [uniform(min_, max_) for _ in range(self.n_clusters)]
        # Iterate, adjusting centroids until converged or until passed max_iter
        iteration = 0
        prev_centroids = None
        while np.not_equal(self.centroids, prev_centroids).any() and iteration < self.max_iter:
            # Sort each datapoint, assigning to nearest centroid
            sorted_points = [[] for _ in range(self.n_clusters)]
            for x in X_train:
                dists = euclidean(x, self.centroids)
                centroid_idx = np.argmin(dists)
                sorted_points[centroid_idx].append(x)
            # Push current centroids to previous, reassign centroids as mean of the points belonging to them
            prev_centroids = self.centroids
            self.centroids = [np.mean(cluster, axis=0) for cluster in sorted_points]
            for i, centroid in enumerate(self.centroids):
                if np.isnan(centroid).any():  # Catch any np.nans, resulting from a centroid having no points
                    self.centroids[i] = prev_centroids[i]
            iteration += 1
    def evaluate(self, X):
        centroids = []
        centroid_idxs = []
        for x in X:
            dists = euclidean(x, self.centroids)
            centroid_idx = np.argmin(dists)
            centroids.append(self.centroids[centroid_idx])
            centroid_idxs.append(centroid_idx)
        return centroids, centroid_idxs
# Create a dataset of 2D distributions
centers = 5
X_train, true_labels = make_blobs(n_samples=100, centers=centers, random_state=42)
X_train = StandardScaler().fit_transform(X_train)
# Fit centroids to dataset
kmeans = KMeans(n_clusters=centers)
kmeans.fit(X_train)
# View results
class_centers, classification = kmeans.evaluate(X_train)
sns.scatterplot(x=[X[0] for X in X_train],
                y=[X[1] for X in X_train],
                hue=true_labels,
                style=classification,
                palette="deep",
                legend=None
                )
plt.plot([x for x, _ in kmeans.centroids],
         [y for _, y in kmeans.centroids],
         'k+',
         markersize=10,
         )
plt.show()
```

以及Hierarchical clustering算法：





------





## 2024.12.21 周六

今日上午复习GPT模型，参考链接：

中午先去基法实验室合药并给近端肿瘤给药中午及下午在图书馆学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture9: Breadth-First Search（Instructor: Justin Solomon）：

​	This class covers graph definitions, neighbor sets and adjacencies, graph representations in data structures, and paths. It also discusses shortest paths trees and breadth-first search.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-9-breadth-first-search/

Simple graph is no self-loop and every edge is distinct and satisfy the rule $E=O(|V|^2)$. 

For direct graph, we have $|E| \le 2 \binom{|V|}{2} = O(|V|^2)$ and for undirect graph we have $|E| \le \binom{|V|}{2} = O(|V|^2)$.

For neighbors, we have the following propeties:

- The **outgoing neighbor set** of $u \in V$ is $\text{Adj}^+(u) = \{u \in V | (u,v) \in E \}$
- The **incoming neighbor set** of $u \in V$ is $\text{Adj}^-(u) = \{u \in V | (u,v) \in E \}$
- The **out-degree** of vertex $u \in V$ is $\text{deg}^+(u) = |\text{Adj}^+(u)|$
- The **in-degree** of vertex $u \in V$ is $\text{deg}^-(u) = |\text{Adj}^-(u)|$
- For undirected graph, $\text{Adj}^+(u) = \text{Adj}^-(u)$ and $\text{deg}^+(u) = \text{deg}^-(u)$
- Dropping supersciprt defaults to outgoing. i.e. $\text{Adj}(u) = \text{Adj}^+(u)$ and $\text{deg}(u) = \text{deg}^+(u)$

we can infer the relationship:
$$
\sum_{u \in V} \text{deg}^+(u) = \begin{Bmatrix}
 2|E| && \text{if undirected}\\
|E| && \text{if directed}
\end{Bmatrix}
$$
Graph presentations: Edge list, adjacency list, adjacency matrix, and many others.

The definition of path in graph is $P(v_1, v_2, ...,v_k)$ where $(v_i, v_{i+1}) \in E$ for $\forall i \in \{1, 2, ..., k-1 \}$ and we denote $\ell(p) := \text{length}$ and $\delta(u,v) := \text{length of shortest path}$.

Model Graph Problems:

- SINGLE_PAIR_REACHABILITY(G, s,t)：is there a path in G from s to t.
- SINGLE_PAIR_SHORTEST_PATH(G, s, t)：return the shortest path in G from s to t.
- SINGLE_SOURCE_SHORTEST_PATH(G, s)：return the shortest distance from s to all t plus a shortest path tree.

Level sets: we define $L_k :=\{u \in V: d(s,u) = k \}$

<img src="./assets/GraphLevelSets.png" alt="QQ_1734765254423" style="zoom:25%;" />

Key: **Breadth-First Search（BFS） Algorithm**:

​	BFS is undamental **graph traversal algorithm** for searching a tree data structure for a node that satisfies a given property. It begins with a node, then first traverses all its adjacent.  It starts at the tree node and explores all nodes at the present depth prior to moving on to the nodes at the next depth level.

Algorithm step (Java implementation，reference code: https://www.geeksforgeeks.org/breadth-first-search-or-bfs-for-a-graph/):

```java
import java.util.*;

class GfG {
  
    // BFS from given source s
    static void bfs(List<List<Integer>> adj, int s) {
      
        // Create a queue for BFS
        Queue<Integer> q = new LinkedList<>();
        
        // Initially mark all the vertices as not visited
        // When we push a vertex into the q, we mark it as 
        // visited
        boolean[] visited = new boolean[adj.size()];
        
        // Mark the source node as visited and enqueue it
        visited[s] = true;
        q.add(s);
        
        // Iterate over the queue
        while (!q.isEmpty()) {
          
            // Dequeue a vertex and print it
            int curr = q.poll();
            System.out.print(curr + " ");
            
            // Get all adjacent vertices of the dequeued vertex
            // If an adjacent has not been visited, mark it 
            // visited and enqueue it
            for (int x : adj.get(curr)) {
                if (!visited[x]) {
                    visited[x] = true;
                    q.add(x);
                }
            }
        }
    }

    // Function to add an edge to the graph
    static void addEdge(List<List<Integer>> adj, int u, int v) {
        adj.get(u).add(v);
        adj.get(v).add(u); // Undirected graph
    }

    public static void main(String[] args) {
      
        // Number of vertices in the graph
        int V = 5;
        
        // Adjacency list representation of the graph
        List<List<Integer>> adj = new ArrayList<>(V);
        for (int i = 0; i < V; i++) {
            adj.add(new ArrayList<>());
        }
        
        // Add edges to the graph
        addEdge(adj, 0, 1);
        addEdge(adj, 0, 2);
        addEdge(adj, 1, 3);
        addEdge(adj, 1, 4);
        addEdge(adj, 2, 4);
        
        // Perform BFS traversal starting from vertex 0
        System.out.println("BFS starting from 0:");
        bfs(adj, 0);
    }
}
```

The **time complexity can be expressed as $O(|V| + |E|)$** because we need to search all node and related pathway in given graph in the worst-case, the **space complexity can be expressed as $O(|V|)$** because we should queue data strcuture to store the node whether it is checked. Note that $|V|$ is the number of all vertices and $|E|$ the number of all edges.

然后继续学习MLCB2024-Lecture03-Single cell Analysis（instructor: Manolis Kellis），地址链接：https://www.youtube.com/watch?v=xmLoR3ynwkw

在学习这堂课的时候又提到了单细胞分析的基因相似性分析，借此又回顾一遍WGCNA分析：

​	Weighted Gene Co-expression Network Analysis (WGCNA) is a powerful technique for analyzing high-dimensional data, such as transcriptomics, to find clusters (modules) of highly correlated genes and relate these modules to external traits or sample properties. It identifies groups (modules) of genes that have similar expression patterns across samples and explore biological networks, identifying candidate biomarkers, and finding modules associated with clinical traits.

Mathematical theory:

​	1.Gene Co-expression as a Network

​	WGCNA treats gene expression data as a network. In this network, Nodes Represent genes,Edges Represent the relationships (correlations) between genes. The objective is to measure the similarity in gene expression profiles and group genes into **modules** (clusters) of highly correlated genes.

​	2.Measure of Gene-Gene Similarity

The similarity $S_{ij}$ between two genes $i$ and $j$ is computed using correlation coefficients:
$$
r_{ij} = \frac{\text{Cov}(X_i,Y_i)}{\sigma(X_i)\sigma(Y_i)}
$$
where $X_i$ and $X_j$ are the expression levels of genes $i$ and $j$ across samples.

The similarity measure is absolute value of pearson correlation coefficients $S_{ij} = |r_{ij}|$.(The absolute value ensures the network captures positive and negative correlations equally)

​	3.Adjacency Matrix and Soft-Thresholding

The adjacency matrix $A_{ij}$ encodes the connection strength between gene $i$ and gene $j$.To emphasize strong connections and suppress weak ones, WGCNA applies **soft-thresholding**:
$$
A_{ij} = S_{ij}^\beta
$$
where the $S_{ij}$ is the similarity measure, and $\beta$ is a parameter chosen to ensure the network follows a **scale-free topology**.

Notation: In a scale-free network, most nodes have few connections, and a few nodes (hubs) have many connections. This property is checked by fitting the degree distribution $p(k) \sim k^{-\gamma}$, where $k$ is the node degree.

​	4.Topological Overlap Matrix (TOM)

The **Topological Overlap Matrix (TOM)** <u>refines the adjacency matrix by considering shared neighbors between genes</u>. It measures the interconnectedness of two nodes in the network.

For two gene $i$ and $j$:
$$
TOM_{ij} = \frac{\sum_kA_{ik}A_{jk} + A_{ij}}{\text{min}(K_i,K_j) + 1 - A_{ij}} \in [0,1]
$$
where $K_i=\sum_kA_{ik}$ is the connectivity of gene $i$ and $K_j=\sum_kA_{jk}$ is the connectivity of gene $j$. The numerator captures the shared neighbors between $i$ and $j$. TOM values range from 0 to 1, where 1 indicates strong topological overlap.

Why should we use TOM? **Limitations of Correlation or Adjacency Matrices**: simple correlation or adjacency matrices only measure direct pairwise relationships between genes; They fail to capture the context of how genes are connected within the network (e.g., shared neighbors). **Advantages of TOM**: TOM accounts for **both direct and indirect relationships**; It creates a more biologically meaningful and robust measure of interconnectedness; TOM helps cluster genes into modules (groups of highly interconnected genes).

​	5.Module Detection via Clustering

Modules are groups of genes with high topological overlap. WGCNA uses hierarchical clustering on the TOM-based dissimilarity measure:
$$
\text{Dissimilarity}_{ij} = 1 - TOM_{ij}
$$
Then, perform hierarchical clustering algorithem on $1 - TOM_{ij}$. Finally, using a **dynamic tree cut** algorithm to identify modules as branches of the clustering dendrogram.

6.Module Eigengenes

Each module is summarized by a single representative value called the **module eigengene (ME)**. Compute the **first principal component (PC1)** of the expression data for all genes in the module:
$$
ME_k=\text{PC}_1(\text{Expression Matrix of module}\ k)
$$
$ME_k$ represents the overall expression trend of the module.

7.Correlation with External Traits

To relate modules to phenotypic traits, we need to compute the corrlationship between module eigengenes and external traits:
$$
\text{Cor}(ME_k, \text{traits}) = \frac{\text{Cov}(ME_k, \text{traits})}{\sigma(ME_k)\sigma(\text{traits})}
$$
and **Assess significance using p-values**. Modules with strong correlations to traits may contain biologically relevant genes.

8.Identifying Key Genes (Hub Genes)

**Module Membership (MM)**: Measures the correlation between a gene's expression and the module eigengene:
$$
MM_{i,k} = \text{Cor}(X_i,ME_k)
$$
where $X_i$ is the $i$-th gene in the module eigengene $ME_k$. The higher score represents stronger connection the gene and other gene in this module eigengene $ME_k$.

**Gene Significance (GS)**: Measures the correlation between a gene’s expression and an external trait:
$$
\text{GS}_i = \text{Cor}(X_i, \text{Traits})
$$
The Hub gene have both higher MM scores and GS scores.

9.Statistical Validation

Checking if the identified modules are robust using permutation tests and validating the biological relevance of hub genes via external databases or experimental studies.

具体的WGCNA pepline（R语言）见2024.09.09。简化实现代码：

```R
# 模拟基因表达数据
set.seed(123)
data <- matrix(rnorm(1000), nrow = 100, ncol = 10) # 100个基因，10个样本
rownames(data) <- paste0("Gene", 1:100) # 基因名称
colnames(data) <- paste0("Sample", 1:10) # 样本名称

# 数据标准化
data <- scale(data) # 对基因表达数据进行标准化


# 计算相关性矩阵
correlation_matrix <- cor(data, method = "pearson")

# 定义软阈值化函数
soft_threshold <- function(cor_matrix, beta) {
  adjacency_matrix <- abs(cor_matrix)^beta
  return(adjacency_matrix)
}

# 应用软阈值
beta <- 6 # 通常通过pickSoftThreshold函数选择合适的beta值
adjacency_matrix <- soft_threshold(correlation_matrix, beta)

# 计算节点的连接度数
node_degree <- rowSums(adjacency_matrix)

# 计算共享邻居数
shared_neighbors <- adjacency_matrix %*% adjacency_matrix

# 计算TOM
tom_matrix <- (shared_neighbors + adjacency_matrix) / 
              (pmin(node_degree, t(node_degree)) + 1 - adjacency_matrix)

# 计算dissimilarity
dissimilairy <- 1 - tom_matrix

# 使用层次聚类
hclust_tree <- hclust(as.dist(dissimilarity), method = "average")

# 动态剪切树（简单实现）
dynamic_modules <- cutree(hclust_tree, k = 5) # 假设分成5个模块
table(dynamic_modules)

# 可视化
# 绘制聚类树和模块颜色
plot(hclust_tree, labels = FALSE, main = "Gene Clustering Dendrogram")
rect.hclust(hclust_tree, k = 5, border = 2:6) # 添加模块边框
```

修改Typora以修改代码块的高度以及滚动查看方式：打开偏好设置->外观->打开主题文件夹->选取与目前主题一致的.css文件->ctrl+F搜索.mid-fences->向代码块里添加.`mid-fences {max-height: 400px; overflow-y: auto;}`->保存修改并重启Typora【缺点：代码块右下角选择语言的列表会固定在代码块内】。

然后去基法实验室给小鼠近端肿瘤进行照光。回家吃饭、休息，空闲时思考后续的技能树应该点什么。

------





## 2024.12.22 周日

今日上午国重会议室开会，开会的内容主要开始讲一些思政、奋斗、内驱相关的内容，毫无新意。

中午学习Transformer的代码，地址链接：https://www.cnblogs.com/nickchen121/p/16518613.html：

```python
#!/usr/bin/python3.9
# -*- coding: utf-8 -*-
# @Time    : 2021/10/29 10:48
# @Author  : nickchen121
# @Email   : nickchen121@163.com
# Cnblogs : https://www.cnblogs.com/nickchen121
# @File    : abd_transformer_cyd.py
# @Software: PyCharm




import math
import torch
import collections
import numpy as np
import torch.nn as nn
from copy import deepcopy
import torch.nn.functional as F
from torch.autograd import Variable

# 让Hypothesis拥有可访问的属性，即Hypothesis.value
Hypothesis = collections.namedtuple('Hypothesis', ['value', 'score'])


def clone_module_to_modulelist(module, module_num):
    """
    克隆n个Module类放入ModuleList中，并返回ModuleList，这个ModuleList中的每个Module都是一模一样的
    nn.ModuleList，它是一个储存不同 module，并自动将每个 module 的 parameters 添加到网络之中的容器。
    你可以把任意 nn.Module 的子类 (比如 nn.Conv2d, nn.Linear 之类的) 加到这个 list 里面，
    加入到 nn.ModuleList 里面的 module 是会自动注册到整个网络上的，
    同时 module 的 parameters 也会自动添加到整个网络中。
    :param module: 被克隆的module
    :param module_num: 被克隆的module数
    :return: 装有module_num个相同module的ModuleList
    """
    return nn.ModuleList([deepcopy(module) for _ in range(module_num)])


class LayerNorm(nn.Module):
    """
    构建一个LayerNorm Module
    LayerNorm的作用：对x归一化，使x的均值为0，方差为1
    LayerNorm计算公式：x-mean(x)/\sqrt{var(x)+\epsilon} = x-mean(x)/std(x)+\epsilon
    """

    def __init__(self, x_size, eps=1e-6):
        """
        :param x_size: 特征的维度
        :param eps: eps是一个平滑的过程，取值通常在（10^-4~10^-8 之间）
        其含义是，对于每个参数，随着其更新的总距离增多，其学习速率也随之变慢。
        防止出现除以0的情况。

        nn.Parameter将一个不可训练的类型Tensor转换成可以训练的类型parameter，
        并将这个parameter绑定到这个module里面。
        使用这个函数的目的也是想让某些变量在学习的过程中不断的修改其值以达到最优化。
        """
        super(LayerNorm, self).__init__()
        self.ones_tensor = nn.Parameter(torch.ones(x_size))  # 按照特征向量大小返回一个全1的张量，并且转换成可训练的parameter类型
        self.zeros_tensor = nn.Parameter(torch.zeros(x_size))
        self.eps = eps

    def forward(self, x):
        mean = x.mean(-1, keepdim=True)
        std = x.std(-1, keepdim=True)  # 求标准差
        return self.ones_tensor * (x - mean) / (std + self.eps) + self.zeros_tensor  # LayerNorm的计算公式


class FeatEmbedding(nn.Module):
    """
    视频特征向量生成器
    """

    def __init__(self, d_feat, d_model, dropout):
        """
        FeatEmbedding的初始化
        :param d_feat: per frame dimension（每帧的维度），作为Linear层输入的维度
        :param d_model: 作为Linear层输出的维度
        :param dropout: Dropout层的比率

        nn.Sequential：这是一个有顺序的容器，将特定神经网络模块按照在传入构造器的顺序依次被添加到计算图中
        在这里构造的容器是：LayerNorm --> Dropout --> Linear
        """
        super(FeatEmbedding, self).__init__()
        self.video_embeddings = nn.Sequential(
            # TODO:为什么这里对视频做处理，即图片做处理，不使用BatchNorm
            # nn.BatchNorm2d(d_feat)
            # nn.LayerNorm(d_feat),
            LayerNorm(d_feat),
            nn.Dropout(p=dropout),
            nn.Linear(d_feat, d_model)
        )

    def forward(self, x):
        return self.video_embeddings(x)  # 返回被处理后的视频特征向量


class WordEmbedding(nn.Module):
    """
    把向量构造成d_model维度的词向量，以便后续送入编码器
    """

    def __init__(self, vocab_size, d_model):
        """
        :param vocab_size: 字典长度
        :param d_model: 词向量维度
        """
        super(WordEmbedding, self).__init__()
        self.d_model = d_model
        # 字典中有vocab_size个词，词向量维度是d_model，每个词将会被映射成d_model维度的向量
        self.embedding = nn.Embedding(vocab_size, d_model)
        self.embed = self.embedding

    def forward(self, x):
        # TODO：为什么要乘以一个sqrt，Transformer中的？
        return self.embed(x) * math.sqrt(self.d_model)


class PositionalEncoding(nn.Module):
    """
    正弦位置编码，即通过三角函数构建位置编码

    Implementation based on "Attention Is All You Need"
    :cite:`DBLP:journals/corr/VaswaniSPUJGKP17`
    """

    def __init__(self, dim: int, dropout: float, max_len=5000):
        """
        :param dim: 位置向量的向量维度，一般与词向量维度相同，即d_model
        :param dropout: Dropout层的比率
        :param max_len: 句子的最大长度
        """
        # 判断能够构建位置向量
        if dim % 2 != 0:
            raise ValueError(f"不能使用 sin/cos 位置编码，得到了奇数的维度{dim:d}，应该使用偶数维度")

        """
        构建位置编码pe
        pe公式为：
        PE(pos,2i/2i+1) = sin/cos(pos/10000^{2i/d_{model}})
        """
        pe = torch.zeros(max_len, dim)  # 初始化pe
        position = torch.arange(0, max_len).unsqueeze(1)  # 构建pos，为句子的长度，相当于pos
        div_term = torch.exp((torch.arange(0, dim, 2, dtype=torch.float) * torch.tensor(
            -(math.log(10000.0) / dim))))  # 复现位置编码sin/cos中的公式
        pe[:, 0::2] = torch.sin(position.float() * div_term)  # 偶数使用sin函数
        pe[:, 1::2] = torch.cos(position.float() * div_term)  # 奇数使用cos函数
        pe = pe.unsqueeze(1)  # 扁平化成一维向量

        super(PositionalEncoding, self).__init__()
        self.register_buffer('pe', pe)  # pe不是模型的一个参数，通过register_buffer把pe写入内存缓冲区，当做一个内存中的常量
        self.drop_out = nn.Dropout(p=dropout)
        self.dim = dim

    def forward(self, emb, step=None):
        """
        词向量和位置编码拼接并输出
        :param emb: 词向量序列（FloatTensor），``(seq_len, batch_size, self.dim)``
        :param step: 如果 stepwise("seq_len=1")，则用此位置的编码
        :return: 词向量和位置编码的拼接
        """
        emb = emb * math.sqrt(self.dim)
        if step is None:
            emb = emb + self.pe[:emb.size(0)]  # 拼接词向量和位置编码
        else:
            emb = emb + self.pe[step]
        emb = self.drop_out(emb)
        return emb


def self_attention(query, key, value, dropout=None, mask=None):
    """
    自注意力计算
    :param query: Q
    :param key: K
    :param value: V
    :param dropout: drop比率
    :param mask: 是否mask
    :return: 经自注意力机制计算后的值
    """
    d_k = query.size(-1)  # 防止softmax未来求梯度消失时的d_k
    # Q,K相似度计算公式：\frac{Q^TK}{\sqrt{d_k}}
    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)  # Q,K相似度计算
    # 判断是否要mask，注：mask的操作在QK之后，softmax之前
    if mask is not None:
        """
        scores.masked_fill默认是按照传入的mask中为1的元素所在的索引，
        在scores中相同的的索引处替换为value，替换值为-1e9，即-(10^9)
        """
        # mask.cuda()
        # 进行mask操作，由于参数mask==0，因此替换上述mask中为0的元素所在的索引

    scores = scores.masked_fill(mask == 0, -1e9)

    self_attn_softmax = F.softmax(scores, dim=-1)  # 进行softmax
    # 判断是否要对相似概率分布进行dropout操作
    if dropout is not None:
        self_attn_softmax = dropout(self_attn_softmax)

    # 注意：返回经自注意力计算后的值，以及进行softmax后的相似度（即相似概率分布）
    return torch.matmul(self_attn_softmax, value), self_attn_softmax


class MultiHeadAttention(nn.Module):
    """
    多头注意力计算
    """

    def __init__(self, head, d_model, dropout=0.1):
        """
        :param head: 头数
        :param d_model: 词向量的维度，必须是head的整数倍
        :param dropout: drop比率
        """
        super(MultiHeadAttention, self).__init__()
        assert (d_model % head == 0)  # 确保词向量维度是头数的整数倍
        self.d_k = d_model // head  # 被拆分为多头后的某一头词向量的维度
        self.head = head
        self.d_model = d_model

        """
        由于多头注意力机制是针对多组Q、K、V，因此有了下面这四行代码，具体作用是，
        针对未来每一次输入的Q、K、V，都给予参数进行构建
        其中linear_out是针对多头汇总时给予的参数
        """
        self.linear_query = nn.Linear(d_model, d_model)  # 进行一个普通的全连接层变化，但不修改维度
        self.linear_key = nn.Linear(d_model, d_model)
        self.linear_value = nn.Linear(d_model, d_model)
        self.linear_out = nn.Linear(d_model, d_model)

        self.dropout = nn.Dropout(p=dropout)
        self.attn_softmax = None  # attn_softmax是能量分数, 即句子中某一个词与所有词的相关性分数， softmax(QK^T)

    def forward(self, query, key, value, mask=None):
        if mask is not None:
            """
            多头注意力机制的线性变换层是4维，是把query[batch, frame_num, d_model]变成[batch, -1, head, d_k]
            再1，2维交换变成[batch, head, -1, d_k], 所以mask要在第二维（head维）添加一维，与后面的self_attention计算维度一样
            具体点将，就是：
            因为mask的作用是未来传入self_attention这个函数的时候，作为masked_fill需要mask哪些信息的依据
            针对多head的数据，Q、K、V的形状维度中，只有head是通过view计算出来的，是多余的，为了保证mask和
            view变换之后的Q、K、V的形状一直，mask就得在head这个维度添加一个维度出来，进而做到对正确信息的mask
            """
            mask = mask.unsqueeze(1)

        n_batch = query.size(0)  # batch_size大小，假设query的维度是：[10, 32, 512]，其中10是batch_size的大小

        """
        下列三行代码都在做类似的事情，对Q、K、V三个矩阵做处理
        其中view函数是对Linear层的输出做一个形状的重构，其中-1是自适应（自主计算）
        从这种重构中，可以看出，虽然增加了头数，但是数据的总维度是没有变化的，也就是说多头是对数据内部进行了一次拆分
        transopose(1,2)是对前形状的两个维度(索引从0开始)做一个交换，例如(2,3,4,5)会变成(2,4,3,5)
        因此通过transpose可以让view的第二维度参数变成n_head
        假设Linear成的输出维度是：[10, 32, 512]，其中10是batch_size的大小
        注：这里解释了为什么d_model // head == d_k，如若不是，则view函数做形状重构的时候会出现异常
        """
        query = self.linear_query(query).view(n_batch, -1, self.head, self.d_k).transpose(1, 2)  # [b, 8, 32, 64]，head=8
        key = self.linear_key(key).view(n_batch, -1, self.head, self.d_k).transpose(1, 2)  # [b, 8, 28, 64]
        value = self.linear_value(value).view(n_batch, -1, self.head, self.d_k).transpose(1, 2)  # [b, 8, 28, 64]

        # x是通过自注意力机制计算出来的值， self.attn_softmax是相似概率分布
        x, self.attn_softmax = self_attention(query, key, value, dropout=self.dropout, mask=mask)

        """
        下面的代码是汇总各个头的信息，拼接后形成一个新的x
        其中self.head * self.d_k，可以看出x的形状是按照head数拼接成了一个大矩阵，然后输入到linear_out层添加参数
        contiguous()是重新开辟一块内存后存储x，然后才可以使用.view方法，否则直接使用.view方法会报错
        """
        x = x.transpose(1, 2).contiguous().view(n_batch, -1, self.head * self.d_k)
        return self.linear_out(x)


class FeedForward(nn.Module):
    """
    两层具有残差网络的前馈神经网络，FNN网络
    """

    def __init__(self, d_model: int, d_ff: int, dropout=0.1):
        """
        :param d_model: FFN第一层输入的维度
        :param d_ff: FNN第二层隐藏层输入的维度
        :param dropout: drop比率
        """
        super(FeedForward, self).__init__()
        self.w_1 = nn.Linear(d_model, d_ff)
        self.w_2 = nn.Linear(d_ff, d_model)
        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)
        self.dropout_1 = nn.Dropout(dropout)
        self.relu = nn.ReLU()
        self.dropout_2 = nn.Dropout(dropout)

    def forward(self, x):
        """
        :param x: 输入数据，形状为(batch_size, input_len, model_dim)
        :return: 输出数据（FloatTensor），形状为(batch_size, input_len, model_dim)
        """
        inter = self.dropout_1(self.relu(self.w_1(self.layer_norm(x))))
        output = self.dropout_2(self.w_2(inter))
        # return output + x，即为残差网络
        return output  # + x


class SublayerConnection(nn.Module):
    """
    子层的连接: layer_norm(x + sublayer(x))
    上述可以理解为一个残差网络加上一个LayerNorm归一化
    """

    def __init__(self, size, dropout=0.1):
        """
        :param size: d_model
        :param dropout: drop比率
        """
        super(SublayerConnection, self).__init__()
        self.layer_norm = LayerNorm(size)
        # TODO：在SublayerConnection中LayerNorm可以换成nn.BatchNorm2d
        # self.layer_norm = nn.BatchNorm2d()
        self.dropout = nn.Dropout(p=dropout)

    def forward(self, x, sublayer):
        return self.dropout(self.layer_norm(x + sublayer(x)))


class EncoderLayer(nn.Module):
    """
    一层编码Encoder层
    MultiHeadAttention -> Add & Norm -> Feed Forward -> Add & Norm
    """

    def __init__(self, size, attn, feed_forward, dropout=0.1):
        """
        :param size: d_model
        :param attn: 已经初始化的Multi-Head Attention层
        :param feed_forward: 已经初始化的Feed Forward层
        :param dropout: drop比率
        """
        super(EncoderLayer, self).__init__()
        self.attn = attn
        self.feed_forward = feed_forward

        """
        下面一行的作用是因为一个Encoder层具有两个残差结构的网络
        因此构建一个ModuleList存储两个SublayerConnection，以便未来对数据进行残差处理
        """
        self.sublayer_connection_list = clone_module_to_modulelist(SublayerConnection(size, dropout), 2)

    def forward(self, x, mask):
        """
        :param x: Encoder层的输入
        :param mask: mask标志
        :return: 经过一个Encoder层处理后的输出
        """
        """
        编码层第一层子层
        self.attn 应该是一个已经初始化的Multi-Head Attention层
        把Encoder的输入数据x和经过一个Multi-Head Attention处理后的x_attn送入第一个残差网络进行处理得到first_x
        """
        first_x = self.sublayer_connection_list[0](x, lambda x_attn: self.attn(x, x, x, mask))

        """
        编码层第二层子层
        把经过第一层子层处理后的数据first_x与前馈神经网络送入第二个残差网络进行处理得到Encoder层的输出
        """
        return self.sublayer_connection_list[1](first_x, self.feed_forward)


class DecoderLayer(nn.Module):
    """
    一层解码Decoder层
    Mask MultiHeadAttention -> Add & Norm -> Multi-Head Attention -> Add & Norm
    -> Feed Forward -> Add & Norm
    """

    def __init__(self, d_model, attn, feed_forward, sublayer_num, dropout=0.1):
        """
        :param d_model: d_model
        :param attn: 已经初始化的Multi-Head Attention层
        :param feed_forward: 已经初始化的Feed Forward层
        :param sublayer_num: 解码器内部子层数，如果未来r2l_memory传入有值，则为4层，否则为普通的3层
        :param dropout: drop比率
        """
        super(DecoderLayer, self).__init__()
        self.attn = attn
        self.feed_forward = feed_forward
        self.sublayer_connection_list = clone_module_to_modulelist(SublayerConnection(d_model, dropout), sublayer_num)

    def forward(self, x, l2r_memory, src_mask, trg_mask, r2l_memory=None, r2l_trg_mask=None):
        """
        :param x: Decoder的输入(captioning)
        :param l2r_memory: Encoder的输出，作为Multi-Head Attention的K，V值，为从左到右的Encoder的输出
        :param src_mask: 编码器输入的填充掩码
        :param trg_mask: 解码器输入的填充掩码和序列掩码，即对后面单词的掩码
        :param r2l_memory: 从右到左解码器的输出
        :param r2l_trg_mask: 从右到左解码器的输出的填充掩码和序列掩码
        :return: Encoder的输出
        """
        """
        解码器第一层子层
        把Decoder的输入数据x和经过一个Masked Multi-Head Attention处理后的first_x_attn送入第一个残差网络进行处理得到first_x
        """
        first_x = self.sublayer_connection_list[0](x, lambda first_x_attn: self.attn(x, x, x, trg_mask))

        """
        解码器第二层子层
        把第一层子层得到的first_x和
        经过一个Multi-Head Attention处理后的second_x_attn（由first_x和Encoder的输出进行自注意力计算）
        送入第二个残差网络进行处理
        """
        second_x = self.sublayer_connection_list[1](first_x,
                                                    lambda second_x_attn: self.attn(first_x, l2r_memory, l2r_memory,
                                                                                    src_mask))

        """
        解码器第三层子层
        把经过第二层子层处理后的数据second_x与前馈神经网络送入第三个残差网络进行处理得到Decoder层的输出
        
        如果有r2l_memory数据，则还需要经过一层多头注意力计算，也就是说会有四个残差网络
        r2l_memory是让Decoder层多了一层双向编码中从右到左的编码层
        而只要三个残差网络的Decoder层只有从左到右的编码
        """
        if not r2l_memory:
            # 进行从右到左的编码，增加语义信息
            third_x = self.sublayer_connection_list[-2](second_x,
                                                        lambda third_x_attn: self.attn(second_x, r2l_memory, r2l_memory,
                                                                                       r2l_trg_mask))
            return self.sublayer_connection_list[-1](third_x, self.feed_forward)
        else:
            return self.sublayer_connection_list[-1](second_x, self.feed_forward)


class Encoder(nn.Module):
    """
    构建n层编码层
    """

    def __init__(self, n, encoder_layer):
        """
        :param n: Encoder层的层数
        :param encoder_layer: 初始化的Encoder层
        """
        super(Encoder, self).__init__()
        self.encoder_layer_list = clone_module_to_modulelist(encoder_layer, n)

    def forward(self, x, src_mask):
        """
        :param x: 输入数据
        :param src_mask: mask标志
        :return: 经过n层Encoder处理后的数据
        """
        for encoder_layer in self.encoder_layer_list:
            x = encoder_layer(x, src_mask)
        return x


class R2LDecoder(nn.Module):
    """
    n个含有R2L自注意计算的解码层，该解码层只有3个残差网络
    """

    def __init__(self, n_layers, decoder_layer):
        """
        :param n_layers: Decoder层的层数
        :param decoder_layer: 初始化的Decoder层
        """
        super(R2LDecoder, self).__init__()
        self.decoder_layer_list = clone_module_to_modulelist(decoder_layer, n_layers)

    def forward(self, x, memory, src_mask, trg_mask):
        for decoder_layer in self.decoder_layer_list:
            # 没有传入r2l_memory和r2l_trg_mask，默认值为None，即该Decoder只有3个残差网络
            x = decoder_layer(x, memory, src_mask, trg_mask)
        return x


class L2RDecoder(nn.Module):
    """
    n个含有L2R自注意计算的解码层，该解码层有4个残差网络
    """

    def __init__(self, n_layers, decoder_layer):
        """
        :param n_layers: Decoder层的层数
        :param decoder_layer: 初始化的Decoder层
        """
        super(L2RDecoder, self).__init__()
        self.decoder_layer_list = clone_module_to_modulelist(decoder_layer, n_layers)

    def forward(self, x, memory, src_mask, trg_mask, r2l_memory, r2l_trg_mask):
        for decoder_layer in self.decoder_layer_list:
            # 传入r2l_memory和r2l_trg_mask，即修改默认值，Decoder将具有4个残差网络
            x = decoder_layer(x, memory, src_mask, trg_mask, r2l_memory, r2l_trg_mask)
        return x


def sequence_mask(size):
    """
    序列掩码，解码器输入数据时掩盖后续词的位置
    :param size: 生成词个数
    :return: 右上角为False，主对角线及左下角为True的bool矩阵
    """
    attn_shape = (1, size, size)
    """
    np.triu：返回函数的上三角矩阵A，k=1得到主对角线向上平移一个距离的对角线，
    即保留右上对角线及其以上的数据，其余置为0，即a_11=0
    """
    mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')
    return (torch.from_numpy(mask) == 0).cuda()  # 通过==0返回的是bool矩阵，即矩阵元素为bool值


def src_trg_mask(src, r2l_trg, trg, pad_idx):
    """
    :param src: 编码器的输入
    :param r2l_trg: r2l方向解码器的输入
    :param trg: l2r方向解码器的输入
    :param pad_idx: pad的索引
    :return: trg为None，返回编码器输入的掩码；trg存在，返回编码器和解码器输入的掩码
    """

    # TODO: enc_src_mask是元组，是否可以改成list，然后修改这种冗余代码
    # 通过src的长短，即视频特征向量提取的模式，判断有多少种特征向量需要进行mask
    if isinstance(src, tuple) and len(src) == 4:
        # 不同模式的视频特征向量的mask
        src_image_mask = (src[0][:, :, 0] != pad_idx).unsqueeze(1)  # 二维特征向量
        src_motion_mask = (src[1][:, :, 0] != pad_idx).unsqueeze(1)  # 三维特征向量
        src_object_mask = (src[2][:, :, 0] != pad_idx).unsqueeze(1)  # 目标检测特征向量
        src_rel_mask = (src[3][:, :, 0] != pad_idx).unsqueeze(1)  # 目标关系特征向量

        # 视频所有特征向量mask的拼接
        enc_src_mask = (src_image_mask, src_motion_mask, src_object_mask, src_rel_mask)
        dec_src_mask = src_image_mask & src_motion_mask  # 视频二维和三维特征向量mask的拼接
        src_mask = (enc_src_mask, dec_src_mask)  # 视频最终的mask
    elif isinstance(src, tuple) and len(src) == 3:
        src_image_mask = (src[0][:, :, 0] != pad_idx).unsqueeze(1)
        src_motion_mask = (src[1][:, :, 0] != pad_idx).unsqueeze(1)
        src_object_mask = (src[2][:, :, 0] != pad_idx).unsqueeze(1)

        enc_src_mask = (src_image_mask, src_motion_mask, src_object_mask)
        dec_src_mask = src_image_mask & src_motion_mask
        src_mask = (enc_src_mask, dec_src_mask)
    elif isinstance(src, tuple) and len(src) == 2:
        src_image_mask = (src[0][:, :, 0] != pad_idx).unsqueeze(1)
        src_motion_mask = (src[1][:, :, 0] != pad_idx).unsqueeze(1)

        enc_src_mask = (src_image_mask, src_motion_mask)
        dec_src_mask = src_image_mask & src_motion_mask
        src_mask = (enc_src_mask, dec_src_mask)
    else:
        # 即只有src_image_mask，即二维特征的mask
        src_mask = src_image_mask = (src[:, :, 0] != pad_idx).unsqueeze(1)

    # 判断是否需要对trg，也就是解码器的输入进行掩码
    if trg and r2l_trg:
        """
        trg_mask是填充掩码和序列掩码，&前是填充掩码，&后是通过subsequent_mask函数得到的序列掩码
        其中type_as，是为了让序列掩码和填充掩码的维度一致
        """
        trg_mask = (trg != pad_idx).unsqueeze(1) & sequence_mask(trg.size(1)).type_as(src_image_mask.data)
        # r2l_trg的填充掩码
        r2l_pad_mask = (r2l_trg != pad_idx).unsqueeze(1).type_as(src_image_mask.data)
        # r2l_trg的填充掩码和序列掩码
        r2l_trg_mask = r2l_pad_mask & sequence_mask(r2l_trg.size(1)).type_as(src_image_mask.data)
        # src_mask[batch, 1, lens]  trg_mask[batch, 1, lens]
        return src_mask, r2l_pad_mask, r2l_trg_mask, trg_mask
    else:
        return src_mask


class WordProbGenerator(nn.Module):
    """
    文本生成器，即把Decoder层的输出通过最后一层softmax层变化为词概率
    """

    def __init__(self, d_model, vocab_size):
        """
        :param d_model: 词向量维度
        :param vocab_size: 词典大小
        """
        super(WordProbGenerator, self).__init__()
        # 通过线性层的映射，映射成词典大小的维度
        self.linear = nn.Linear(d_model, vocab_size)

    def forward(self, x):
        # 通过softmax函数对词概率做出估计
        return F.log_softmax(self.linear(x), dim=-1)


class ABDTransformer(nn.Module):
    """
    拼凑出Transformer
    """

    def __init__(self, vocab, d_feat, d_model, d_ff, n_heads, n_layers, dropout, feature_mode, device='cuda'):
        """
        :param vocab: 字典长度
        :param d_feat: per frame dimension（每帧的维度）
        :param d_model: 词向量的长度
        :param d_ff: FNN（FeedForward）第二层隐藏层输入的维度
        :param n_heads: 多头注意力时的头数
        :param n_layers: 编码器和解码器的层数
        :param dropout: drop的比率
        :param feature_mode: 提取视频特征的模式
        :param device: 是否使用gpu
        """
        super(ABDTransformer, self).__init__()
        self.vocab = vocab
        self.device = device
        self.feature_mode = feature_mode
        attn = MultiHeadAttention(n_heads, d_model, dropout)  # 多头注意力计算
        feed_forward = FeedForward(d_model, d_ff)  # 前馈神经网络

        """
        提取视频特征向量
        通过feature_mode判断d_feat提取出的维度，也就是提取了多少种信息
        共有四种特征向量信息，四种特征向量依次为：
        image_mask：二维特征向量
        motion_mask：三维特征向量
        object_mask：目标检测，分为两部分，第一部分是目标检测框的坐标，第二部分是被检测目标的特征向量
        rel_mask：是目标之间的关系特征向量
        """
        if feature_mode == 'one':
            # 使用unknown_src_embed命名的目的：提取视频一个特征向量的时候，不一定会提取什么种类的特征向量
            self.unknown_src_embed = FeatEmbedding(d_feat, d_model, dropout)
        elif feature_mode == 'two':
            self.image_src_embed = FeatEmbedding(d_feat[0], d_model, dropout)
            self.motion_src_embed = FeatEmbedding(d_feat[1], d_model, dropout)
        elif feature_mode == 'three':
            self.image_src_embed = FeatEmbedding(d_feat[0], d_model, dropout)
            self.motion_src_embed = FeatEmbedding(d_feat[1], d_model, dropout)
            self.object_src_embed = FeatEmbedding(d_feat[2], d_model, dropout)
        elif feature_mode == 'four':
            self.image_src_embed = FeatEmbedding(d_feat[0], d_model, dropout)
            self.motion_src_embed = FeatEmbedding(d_feat[1], d_model, dropout)
            self.object_src_embed = FeatEmbedding(d_feat[2], d_model, dropout)
            self.rel_src_embed = FeatEmbedding(d_feat[3], d_model, dropout)
        else:
            raise "feature_mode没有该模式，只有['one','two','three','four']四种模式"

        # 把特征向量提取成d_model维度的词向量
        self.trg_embed = WordEmbedding(vocab.n_vocabs, d_model)
        # 提取位置向量
        self.pos_embed = PositionalEncoding(d_model, dropout)
        # 编码层
        self.encoder = Encoder(n_layers, EncoderLayer(d_model, deepcopy(attn), deepcopy(feed_forward), dropout))
        """
        单向解码层
        使用deepcopy的原因：因为每个层的参数是不同的，因此通过deepcopy拷贝一份到新的内存里，避免共享参数
        """
        self.r2l_decoder = R2LDecoder(n_layers, DecoderLayer(d_model, deepcopy(attn), deepcopy(feed_forward),
                                                             sublayer_num=3, dropout=dropout))
        # 双向解码层
        self.l2r_decoder = L2RDecoder(n_layers, DecoderLayer(d_model, deepcopy(attn), deepcopy(feed_forward),
                                                             sublayer_num=4, dropout=dropout))
        # 生成单词概率分布
        self.word_prob_generator = WordProbGenerator(d_model, vocab.n_vocabs)

    def _encoder_feature_concat(self, src, feature_type, src_mask):
        """
        为接下来的encoder函数做准备，主要目的是对视频的特征向量做处理
        :param src: 特征向量
        :param feature_type: 根据视频的类别不同，使用不同的特征向量生成函数， ['image', 'motion', 'object', 'rel']
        :param src_mask: 特征向量掩码的标志
        :return: 经过处理后的视频特征向量
        """
        if feature_type == 'rel':
            # 视频的关系特征向量不需要进行位置向量
            x = self.rel_src_embed(src)  # 提取目标关系特征向量
            return self.encoder(x, src_mask)  # 送入编码器进行编码

        # 例：对于'image'，下面的调用为 self.image_src_embed(src)
        x = self.__getattribute__(f'{feature_type}_src_embed')(src)
        x = self.pos_embed(x)  # 提取视频位置特征向量
        return self.encoder(x, src_mask)  # 送入编码器进行编码

    def encode(self, src, src_mask):
        """
        对数据进行编码，此处主要目的是对不同类型的视频特征向量进行编码
        :param src: 视频的特征向量
        :param src_mask: 视频特征向量的掩码标志
        :return: 成功被编码器编码的视频特征向量
        """
        x_list = []  # 存储不同类型的视频特征向量被编码后的向量
        feature_type_list = ['image', 'motion', 'object', 'rel']  # 视频特征向量的类型
        feature_mode_dict = {'two': 2, 'three': 3, 'four': 4}  # 输入视频特征向量的种类

        if self.feature_mode == 'one':
            return self._encoder_feature_concat[src, 'unknown', src_mask]

        for i, feature_type in enumerate(feature_type_list):
            # 对于不同的feature_mode，拥有的encode的种类也不同
            if i == feature_mode_dict[self.feature_mode]:
                break
            x_list.append(self._encoder_feature_concat[src[i], feature_type, src_mask[i]])

        # TODO（灵感）：这里是否能添加一个线性变化，找出对于视频词向量更为有作用的模式和权重，这样也具有一定的解释性
        return sum(x_list)  # 对于不同feature_type提取的向量进行叠加

    def r2l_decode(self, trg, memory, src_mask, trg_mask):
        """
        对于单向编码，把视频向量转为文本向量，并且添加位置向量
        :param trg: 解码器的输入
        :param memory: 编码器的输出，也就是传给解码器的K、V
        :param src_mask: 编码器输出的掩码标志
        :param trg_mask: 解码器的掩码和单词掩码序列（看不见后面的词）
        :return:
        """
        x = self.trg_embed(trg)  # 把视频向量转为单向编码的词向量
        x = self.pos_embed(x)
        return self.r2l_decoder(x, memory, src_mask, trg_mask)

    def l2r_decode(self, trg, memory, src_mask, trg_mask, r2l_memory, r2l_trg_mask):
        """
        对于双向编码，把视频向量转为文本向量，并且添加位置向量
        :param trg: 解码器的输入
        :param memory: 编码器的输出，也就是传给解码器的K、V
        :param src_mask: 编码器输出的掩码标志
        :param trg_mask: 解码器的掩码和单词掩码序列（看不见后面的词）
        :param r2l_memory: 从右到左解码器的输出
        :param r2l_trg_mask: 从右到左解码器的输出的填充掩码和序列掩码
        :return:
        """
        x = self.trg_embed(trg)  # 把视频向量转为双向编码的词向量
        x = self.pos_embed(x)
        return self.l2r_decoder(x, memory, src_mask, trg_mask, r2l_memory, r2l_trg_mask)

    def forward(self, src, r2l_trg, trg, mask):
        """
        :param src: 编码器的输入
        :param r2l_trg: 从右到左解码器的输入
        :param trg: 从左到右解码器的输入
        :param mask: mask标志
        :return: 从右到左解码器和从左到右解码器的输出词概率分布
        """
        # mask应该是个元组，其中src_mask是包括了不同特征模式的mask的元组
        if len(mask) == 4:
            src_mask, r2l_pad_mask, r2l_trg_mask, trg_mask = mask
        else:
            raise "mask返回的是不带有解码器输入掩码的掩码元组，确认src_trg_mask()函数的参数"

        if self.feature_mode == 'one':
            # 得到视频encode后的输出
            encoding_output = self.encode(src, src_mask)
            # 视频特征单向编码后送入三层残差网络的解码器后得到的输出
            r2l_output = self.r2l_decode(r2l_trg, encoding_output, src_mask, r2l_trg_mask)
            # 视频特征双向编码后送入四层残差网络的解码器后得到的输出
            l2r_output = self.l2r_decode(trg, encoding_output, src_mask, trg_mask, r2l_output, r2l_pad_mask)
        elif self.feature_mode == 'two' or 'three' or 'four':
            # enc_src_mask是视频所有类型的特征掩码；dec_src_mask是二维和三维类型的特征的掩码
            enc_src_mask, dec_src_mask = src_mask
            # 视频特征向量模式的不同，对应不同的掩码方式
            encoding_output = self.encode(src, enc_src_mask)
            r2l_output = self.r2l_decode(r2l_trg, encoding_output, dec_src_mask, r2l_trg_mask)
            l2r_output = self.l2r_decode(trg, encoding_output, dec_src_mask, trg_mask, r2l_output, r2l_pad_mask)
        else:
            raise "没有这种feature_mode，只有['one','two','three','four']"

        # 预测解码词概率分布
        r2l_pred = self.word_prob_generator(r2l_output)
        l2r_pred = self.word_prob_generator(l2r_output)

        return r2l_pred, l2r_pred

    def greedy_decode(self, batch_size, src_mask, memory, max_len):
        """
        针对r2l的解码单词生成，贪婪解码，每次按照最大概率的词作为候选词
        :param batch_size: 每次送入的数据的数量
        :param src_mask: 编码器输入数据的掩码标志
        :param memory: 编码器的输出
        :param max_len: 最大的迭代次数，即生成单词数
        :return: 返回的r2l_hidden，即未来送入l2r中的r2l_memory；output是r2l层的预测输出
        """
        eos_idx = self.vocab.word2idx['<S>']  # <S>符号，表示结束输出的标志
        with torch.no_grad():
            # 构建一个batch_size大小的向量存储eos标志，作为初始化的output
            output = torch.ones(batch_size, 1).fill_(eos_idx).long().cuda()
            # 迭代生成最终输出
            for i in range(max_len + 2 - 1):
                # 构建解码器输入的序列掩码，掩盖后续的词
                trg_mask = sequence_mask(output.size(1))
                # 把初始化的输出和编码器的输出进行解码输出
                dec_out = self.r2l_decode(output, memory, src_mask, trg_mask)  # batch, len, d_model
                r2l_hidden = dec_out
                # 按照最大概率的词作为候选词
                pred = self.word_prob_generator(dec_out)  # batch, len, n_vocabs
                next_word = pred[:, -1].max(dim=-1)[1].unsqueeze(1)  # pred[:, -1]([batch, n_vocabs])
                output = torch.cat([output, next_word], dim=-1)  # 拼接预测单词送入解码器解码

        # 返回的r2l_hidden，即未来送入l2r中的r2l_memory；output是r2l层的预测输出
        return r2l_hidden, output

    def r2l_beam_search_decode(self, batch_size, src, src_mask, model_encodings, beam_size, max_len):
        """
        Beam Search算法可以参考：https://www.cnblogs.com/nickchen121/p/15499576.html
        在每生成一个单词的时间步上，不是只保留当前分数最高的1个输出，而是保留num_beams个。
        当num_beams=1时集束搜索就退化成了贪心搜索，也就是上述的greedy_decode。
        :param batch_size: 一次送入数据的大小
        :param src: 编码器的输入
        :param src_mask: 编码器输入的掩码
        :param model_encodings:
        :param beam_size:
        :param max_len: 最大迭代数，即生成单词数
        :return:
        """
        # batch_size = src.shape[0]
        end_symbol = self.vocab.word2idx['<S>']  # 结束符号
        start_symbol = self.vocab.word2idx['<S>']  # 开始符号
        r2l_output = None  # r2l解码器的输出

        r2l_outputs = None

        # 1.1 Setup Src
        # src has shape (batch_size, sent_len)
        # src_mask has shape (batch_size, 1, sent_len)
        # src_mask = (src[:, :, 0] != self.vocab.word2idx['<PAD>']).unsqueeze(-2)  # TODO Untested
        # model_encodings has shape (batch_size, sentence_len, d_model)
        # model_encodings = self.encode(src, src_mask)

        # 1.2 Setup Tgt Hypothesis Tracking
        # hypothesis is List(4 bt)[(cur beam_sz, dec_sent_len)], init: List(4 bt)[(1 init_beam_sz, dec_sent_len)]
        # hypotheses[i] is shape (cur beam_sz, dec_sent_len)
        hypotheses = [copy.deepcopy(torch.full((1, 1), start_symbol, dtype=torch.long,
                                               device=self.device)) for _ in range(batch_size)]
        # List after init: List 4 bt of List of len max_len_completed, init: List of len 4 bt of []
        completed_hypotheses = [copy.deepcopy([]) for _ in range(batch_size)]
        # List len batch_sz of shape (cur beam_sz), init: List(4 bt)[(1 init_beam_sz)]
        # hyp_scores[i] is shape (cur beam_sz)
        hyp_scores = [copy.deepcopy(torch.full((1,), 0, dtype=torch.float, device=self.device))
                      for _ in range(batch_size)]  # probs are log_probs must be init at 0.

        # 2. Iterate: Generate one char at a time until maxlen
        for _ in range(max_len + 1):
            if all([len(completed_hypotheses[i]) == beam_size for i in range(batch_size)]):
                break

            """
            2.1 Setup the batch. Since we use beam search, each batch has a variable number (called cur_beam_size)
            between 0 and beam_size of hypotheses live at any moment. We decode all hypotheses for all batches at
            the same time, so we must copy the src_encodings, src_mask, etc the appropriate number fo times for
            the number of hypotheses for each example. We keep track of the number of live hypotheses for each example.
            We run all hypotheses for all examples together through the decoder and log-softmax,
            and then use `torch.split` to get the appropriate number of hypotheses for each example in the end.
            """
            cur_beam_sizes, last_tokens, model_encodings_l, src_mask_l = [], [], [], []
            for i in range(batch_size):
                if hypotheses[i] is None:
                    cur_beam_sizes += [0]
                    continue
                cur_beam_size, decoded_len = hypotheses[i].shape
                cur_beam_sizes += [cur_beam_size]
                last_tokens += [hypotheses[i]]
                model_encodings_l += [model_encodings[i:i + 1]] * cur_beam_size
                src_mask_l += [src_mask[i:i + 1]] * cur_beam_size
            # shape (sum(4 bt * cur_beam_sz_i), 1 dec_sent_len, 128 d_model)
            model_encodings_cur = torch.cat(model_encodings_l, dim=0)
            src_mask_cur = torch.cat(src_mask_l, dim=0)
            y_tm1 = torch.cat(last_tokens, dim=0)
            # shape (sum(4 bt * cur_beam_sz_i), 1 dec_sent_len, 128 d_model)
            if self.feature_mode == 'one':
                out = self.r2l_decode(Variable(y_tm1).to(self.device), model_encodings_cur, src_mask_cur,
                                      Variable(sequence_mask(y_tm1.size(-1)).type_as(src.data)).to(self.device))
            elif self.feature_mode == 'two' or 'three' or 'four':
                out = self.r2l_decode(Variable(y_tm1).to(self.device), model_encodings_cur, src_mask_cur,
                                      Variable(sequence_mask(y_tm1.size(-1)).type_as(src[0].data)).to(self.device))
            else:
                raise "out为None"

            r2l_output = out

            # shape (sum(4 bt * cur_beam_sz_i), 1 dec_sent_len, 50002 vocab_sz)
            log_prob = self.word_prob_generator(out[:, -1, :]).unsqueeze(1)
            # shape (sum(4 bt * cur_beam_sz_i), 1 dec_sent_len, 50002 vocab_sz)
            _, decoded_len, vocab_sz = log_prob.shape
            # log_prob = log_prob.reshape(batch_size, cur_beam_size, decoded_len, vocab_sz)
            # shape List(4 bt)[(cur_beam_sz_i, dec_sent_len, 50002 vocab_sz)]
            # log_prob[i] is (cur_beam_sz_i, dec_sent_len, 50002 vocab_sz)
            log_prob = torch.split(log_prob, cur_beam_sizes, dim=0)

            """
            2.2 Now we process each example in the batch. 
            Note that the example may have already finished processing before
            other examples (no more hypotheses to try), in which case we continue
            """
            new_hypotheses, new_hyp_scores = [], []
            for i in range(batch_size):
                if hypotheses[i] is None or len(completed_hypotheses[i]) >= beam_size:
                    new_hypotheses += [None]
                    new_hyp_scores += [None]
                    continue

                """
                2.2.1 We compute the cumulative scores for each live hypotheses for the example
                hyp_scores is the old scores for the previous stage, and `log_prob` are the new probs for
                this stage. Since they are log probs, we sum them instead of multiplying them.
                The .view(-1) forces all the hypotheses into one dimension. The shape of this dimension is
                cur_beam_sz * vocab_sz (ex: 5 * 50002).
                So after getting the topk from it, 
                we can recover the generating sentence and the next word using: ix // vocab_sz, ix % vocab_sz.
                """
                cur_beam_sz_i, dec_sent_len, vocab_sz = log_prob[i].shape
                # shape (vocab_sz,)
                cumulative_hyp_scores_i = (hyp_scores[i].unsqueeze(-1).unsqueeze(-1)
                                           .expand((cur_beam_sz_i, 1, vocab_sz)) + log_prob[i]).view(-1)

                """
                2.2.2 We get the topk values in cumulative_hyp_scores_i and compute the current (generating) sentence
                and the next word using: ix // vocab_sz, ix % vocab_sz.
                """

                # shape (cur_beam_sz,)
                live_hyp_num_i = beam_size - len(completed_hypotheses[i])
                # shape (cur_beam_sz,). Vals are between 0 and 50002 vocab_sz
                top_cand_hyp_scores, top_cand_hyp_pos = torch.topk(cumulative_hyp_scores_i, k=live_hyp_num_i)
                """
                shape (cur_beam_sz,). prev_hyp_ids vals are 0 <= val < cur_beam_sz. 
                hyp_word_ids vals are 0 <= val < vocab_len
                """
                prev_hyp_ids = top_cand_hyp_pos // self.vocab.n_vocabs
                hyp_word_ids = top_cand_hyp_pos % self.vocab.n_vocabs

                """
                2.2.3 For each of the topk words, we append the new word to the current (generating) sentence
                We add this to new_hypotheses_i and add its corresponding total score to new_hyp_scores_i
                """

                # Removed live_hyp_ids_i, which is used in the LSTM decoder to track live hypothesis ids
                new_hypotheses_i, new_hyp_scores_i = [], []
                for prev_hyp_id, hyp_word_id, cand_new_hyp_score in zip(prev_hyp_ids, hyp_word_ids,
                                                                        top_cand_hyp_scores):
                    prev_hyp_id, hyp_word_id, cand_new_hyp_score = \
                        prev_hyp_id.item(), hyp_word_id.item(), cand_new_hyp_score.item()

                    new_hyp_sent = torch.cat(
                        (hypotheses[i][prev_hyp_id], torch.tensor([hyp_word_id], device=self.device)))
                    if hyp_word_id == end_symbol:
                        completed_hypotheses[i].append(Hypothesis(
                            value=[self.vocab.idx2word[a.item()] for a in new_hyp_sent[1:-1]],
                            score=cand_new_hyp_score))
                    else:
                        new_hypotheses_i.append(new_hyp_sent.unsqueeze(-1))
                        new_hyp_scores_i.append(cand_new_hyp_score)

                """
                2.2.4 We may find that the hypotheses_i for some example in the batch
                is empty - we have fully processed that example. We use None as a sentinel in this case.
                Above, the loops gracefully handle None examples.
                """
                if len(new_hypotheses_i) > 0:
                    hypotheses_i = torch.cat(new_hypotheses_i, dim=-1).transpose(0, -1).to(self.device)
                    hyp_scores_i = torch.tensor(new_hyp_scores_i, dtype=torch.float, device=self.device)
                else:
                    hypotheses_i, hyp_scores_i = None, None
                new_hypotheses += [hypotheses_i]
                new_hyp_scores += [hyp_scores_i]
            # print(new_hypotheses, new_hyp_scores)
            hypotheses, hyp_scores = new_hypotheses, new_hyp_scores

        """
        2.3 Finally, we do some postprocessing to get our final generated candidate sentences.
        Sometimes, we may get to max_len of a sentence and still not generate the </s> end token.
        In this case, the partial sentence we have generated will not be added to the completed_hypotheses
        automatically, and we have to manually add it in. We add in as many as necessary so that there are
        `beam_size` completed hypotheses for each example.
        Finally, we sort each completed hypothesis by score.
        """
        for i in range(batch_size):
            hyps_to_add = beam_size - len(completed_hypotheses[i])
            if hyps_to_add > 0:
                scores, ix = torch.topk(hyp_scores[i], k=hyps_to_add)
                for score, id_ in zip(scores, ix):
                    completed_hypotheses[i].append(Hypothesis(
                        value=[self.vocab.idx2word[a.item()] for a in hypotheses[i][id_][1:]],
                        score=score))
            completed_hypotheses[i].sort(key=lambda hyp: hyp.score, reverse=True)
        return r2l_output, completed_hypotheses

    def beam_search_decode(self, src, beam_size, max_len):
        """
        An Implementation of Beam Search for the Transformer Model.
        Beam search is performed in a batched manner. Each example in a batch generates `beam_size` hypotheses.
        We return a list (len: batch_size) of list (len: beam_size) of Hypothesis,
        which contain our output decoded sentence sand their scores.
        :param src: shape (sent_len, batch_size). Each val is 0 < val < len(vocab_dec). The input tokens to the decoder.
        :param max_len: the maximum length to decode
        :param beam_size: the beam size to use
        :return completed_hypotheses: A List of length batch_size,
        each containing a List of beam_size Hypothesis objects.Hypothesis is a named Tuple,
        its first entry is "value" and is a List of strings which contains the translated word
        (one string is one word token).
        The second entry is "score" and it is the log-prob score for this translated sentence.
        Note: Below I note "4 bt", "5 beam_size" as the shapes of objects. 4, 5 are default values.
         Actual values may differ.
        """

        # 1. Setup
        start_symbol = self.vocab.word2idx['<S>']
        end_symbol = self.vocab.word2idx['<S>']

        # 1.1 Setup Src
        # src has shape (batch_size, sent_len)
        # src_mask has shape (batch_size, 1, sent_len)
        # src_mask = (src[:, :, 0] != self.vocab.word2idx['<PAD>']).unsqueeze(-2)  # TODO Untested
        src_mask = src_trg_mask(src, r2l_trg=None, trg=None, pad_idx=self.vocab.word2idx['<PAD>'])
        # model_encodings has shape (batch_size, sentence_len, d_model)
        if self.feature_mode == 'one':
            batch_size = src.shape[0]
            dec_src_mask = None
            model_encodings = self.encode(src, src_mask)
            r2l_memory, r2l_completed_hypotheses = self.r2l_beam_search_decode(batch_size, src, src_mask,
                                                                               model_encodings=model_encodings,
                                                                               beam_size=1, max_len=max_len)
        elif self.feature_mode == 'two' or 'three' or 'four':
            batch_size = src[0].shape[0]
            enc_src_mask = src_mask[0]
            dec_src_mask = src_mask[1]
            model_encodings = self.encode(src, enc_src_mask)
            r2l_memory, r2l_completed_hypotheses = self.r2l_beam_search_decode(batch_size, src, dec_src_mask,
                                                                               model_encodings=model_encodings,
                                                                               beam_size=1, max_len=max_len)
        else:
            raise "batch_size为None"

        """
        1.2 Setup r2l target output
        r2l_memory, r2l_completed_hypotheses = self.r2l_beam_search_decode(batch_size, src, src_mask,
                                                                           model_encodings=model_encodings,
                                                                           beam_size=1, max_len=max_len)
        r2l_memory, r2l_completed_hypotheses = self.greedy_decode(batch_size, src_mask, model_encodings, max_len)
        beam_r2l_memory = [copy.deepcopy(r2l_memory) for _ in range(beam_size)]
        
        1.3 Setup Tgt Hypothesis Tracking
        """

        # hypothesis is List(4 bt)[(cur beam_sz, dec_sent_len)], init: List(4 bt)[(1 init_beam_sz, dec_sent_len)]
        # hypotheses[i] is shape (cur beam_sz, dec_sent_len)
        hypotheses = [copy.deepcopy(torch.full((1, 1), start_symbol, dtype=torch.long,
                                               device=self.device)) for _ in range(batch_size)]
        # List after init: List 4 bt of List of len max_len_completed, init: List of len 4 bt of []
        completed_hypotheses = [copy.deepcopy([]) for _ in range(batch_size)]
        # List len batch_sz of shape (cur beam_sz), init: List(4 bt)[(1 init_beam_sz)]
        # hyp_scores[i] is shape (cur beam_sz)
        hyp_scores = [copy.deepcopy(torch.full((1,), 0, dtype=torch.float, device=self.device))
                      for _ in range(batch_size)]  # probs are log_probs must be init at 0.

        # 2. Iterate: Generate one char at a time until maxlen
        for _ in range(max_len + 1):
            if all([len(completed_hypotheses[i]) == beam_size for i in range(batch_size)]):
                break

            """
            2.1 Setup the batch. Since we use beam search, each batch has a variable number (called cur_beam_size)
            between 0 and beam_size of hypotheses live at any moment. We decode all hypotheses for all batches at
            the same time, so we must copy the src_encodings, src_mask, etc the appropriate number fo times for
            the number of hypotheses for each example. We keep track of the number of live hypotheses for each example.
            We run all hypotheses for all examples together through the decoder and log-softmax,
            and then use `torch.split` to get the appropriate number of hypotheses for each example in the end.
            """

            cur_beam_sizes, last_tokens, model_encodings_l, src_mask_l, r2l_memory_l = [], [], [], [], []
            for i in range(batch_size):
                if hypotheses[i] is None:
                    cur_beam_sizes += [0]
                    continue
                cur_beam_size, decoded_len = hypotheses[i].shape
                cur_beam_sizes += [cur_beam_size]
                last_tokens += [hypotheses[i]]
                model_encodings_l += [model_encodings[i:i + 1]] * cur_beam_size
                if self.feature_mode == 'one':
                    src_mask_l += [src_mask[i:i + 1]] * cur_beam_size
                elif dec_src_mask and (self.feature_mode == 'two' or 'three' or 'four'):
                    src_mask_l += [dec_src_mask[i:i + 1]] * cur_beam_size
                r2l_memory_l += [r2l_memory[i: i + 1]] * cur_beam_size
            # shape (sum(4 bt * cur_beam_sz_i), 1 dec_sent_len, 128 d_model)
            model_encodings_cur = torch.cat(model_encodings_l, dim=0)
            src_mask_cur = torch.cat(src_mask_l, dim=0)
            y_tm1 = torch.cat(last_tokens, dim=0)
            r2l_memory_cur = torch.cat(r2l_memory_l, dim=0)
            # shape (sum(4 bt * cur_beam_sz_i), 1 dec_sent_len, 128 d_model)
            if self.feature_mode == 'one':
                out = self.l2r_decode(Variable(y_tm1).to(self.device), model_encodings_cur, src_mask_cur,
                                      Variable(sequence_mask(y_tm1.size(-1)).type_as(src.data)).to(self.device),
                                      r2l_memory_cur, r2l_trg_mask=None)
            elif self.feature_mode == 'two' or 'three' or 'four':
                out = self.l2r_decode(Variable(y_tm1).to(self.device), model_encodings_cur, src_mask_cur,
                                      Variable(sequence_mask(y_tm1.size(-1)).type_as(src[0].data)).to(self.device),
                                      r2l_memory_cur, r2l_trg_mask=None)
            else:
                raise "out为None"

            # shape (sum(4 bt * cur_beam_sz_i), 1 dec_sent_len, 50002 vocab_sz)
            log_prob = self.word_prob_generator(out[:, -1, :]).unsqueeze(1)
            # shape (sum(4 bt * cur_beam_sz_i), 1 dec_sent_len, 50002 vocab_sz)
            _, decoded_len, vocab_sz = log_prob.shape
            # log_prob = log_prob.reshape(batch_size, cur_beam_size, decoded_len, vocab_sz)
            # shape List(4 bt)[(cur_beam_sz_i, dec_sent_len, 50002 vocab_sz)]
            # log_prob[i] is (cur_beam_sz_i, dec_sent_len, 50002 vocab_sz)
            log_prob = torch.split(log_prob, cur_beam_sizes, dim=0)

            """
            2.2 Now we process each example in the batch.
            Note that the example may have already finished processing before.
            other examples (no more hypotheses to try), in which case we continue
            """
            new_hypotheses, new_hyp_scores = [], []
            for i in range(batch_size):
                if hypotheses[i] is None or len(completed_hypotheses[i]) >= beam_size:
                    new_hypotheses += [None]
                    new_hyp_scores += [None]
                    continue

                # 2.2.1 We compute the cumulative scores for each live hypotheses for the example
                # hyp_scores is the old scores for the previous stage, and `log_prob` are the new probs for
                # this stage. Since they are log probs, we sum them instead of multiplying them.
                # The .view(-1) forces all the hypotheses into one dimension. The shape of this dimension is
                # cur_beam_sz * vocab_sz (ex: 5 * 50002). So after getting the topk from it, we can recover the
                # generating sentence and the next word using: ix // vocab_sz, ix % vocab_sz.
                cur_beam_sz_i, dec_sent_len, vocab_sz = log_prob[i].shape
                "shape (vocab_sz,)"
                cumulative_hyp_scores_i = (hyp_scores[i].unsqueeze(-1).unsqueeze(-1)
                                           .expand((cur_beam_sz_i, 1, vocab_sz)) + log_prob[i]).view(-1)

                """
                2.2.2 We get the topk values in cumulative_hyp_scores_i and compute the current (generating) sentence
                and the next word using: ix // vocab_sz, ix % vocab_sz.
                """
                # shape (cur_beam_sz,)
                live_hyp_num_i = beam_size - len(completed_hypotheses[i])
                # shape (cur_beam_sz,). Vals are between 0 and 50002 vocab_sz
                top_cand_hyp_scores, top_cand_hyp_pos = torch.topk(cumulative_hyp_scores_i, k=live_hyp_num_i)
                """
                shape (cur_beam_sz,). prev_hyp_ids vals are 0 <= val < cur_beam_sz. 
                hyp_word_ids vals are 0 <= val < vocab_len
                """
                prev_hyp_ids = top_cand_hyp_pos // self.vocab.n_vocabs
                hyp_word_ids = top_cand_hyp_pos % self.vocab.n_vocabs

                """
                2.2.3 For each of the topk words, we append the new word to the current (generating) sentence
                We add this to new_hypotheses_i and add its corresponding total score to new_hyp_scores_i
                """
                # Removed live_hyp_ids_i, which is used in the LSTM decoder to track live hypothesis ids
                new_hypotheses_i, new_hyp_scores_i = [], []
                for prev_hyp_id, hyp_word_id, cand_new_hyp_score in zip(prev_hyp_ids, hyp_word_ids,
                                                                        top_cand_hyp_scores):
                    prev_hyp_id, hyp_word_id, cand_new_hyp_score = \
                        prev_hyp_id.item(), hyp_word_id.item(), cand_new_hyp_score.item()

                    new_hyp_sent = torch.cat(
                        (hypotheses[i][prev_hyp_id], torch.tensor([hyp_word_id], device=self.device)))
                    if hyp_word_id == end_symbol:
                        completed_hypotheses[i].append(Hypothesis(
                            value=[self.vocab.idx2word[a.item()] for a in new_hyp_sent[1:-1]],
                            score=cand_new_hyp_score))
                    else:
                        new_hypotheses_i.append(new_hyp_sent.unsqueeze(-1))
                        new_hyp_scores_i.append(cand_new_hyp_score)

                # 2.2.4 We may find that the hypotheses_i for some example in the batch
                # is empty - we have fully processed that example. We use None as a sentinel in this case.
                # Above, the loops gracefully handle None examples.
                if len(new_hypotheses_i) > 0:
                    hypotheses_i = torch.cat(new_hypotheses_i, dim=-1).transpose(0, -1).to(self.device)
                    hyp_scores_i = torch.tensor(new_hyp_scores_i, dtype=torch.float, device=self.device)
                else:
                    hypotheses_i, hyp_scores_i = None, None
                new_hypotheses += [hypotheses_i]
                new_hyp_scores += [hyp_scores_i]
            # print(new_hypotheses, new_hyp_scores)
            hypotheses, hyp_scores = new_hypotheses, new_hyp_scores

        """
        2.3 Finally, we do some postprocessing to get our final generated candidate sentences.
        Sometimes, we may get to max_len of a sentence and still not generate the </s> end token.
        In this case, the partial sentence we have generated will not be added to the completed_hypotheses
        automatically, and we have to manually add it in. We add in as many as necessary so that there are
        `beam_size` completed hypotheses for each example.
        Finally, we sort each completed hypothesis by score.
        """
        for i in range(batch_size):
            hyps_to_add = beam_size - len(completed_hypotheses[i])
            if hyps_to_add > 0:
                scores, ix = torch.topk(hyp_scores[i], k=hyps_to_add)
                for score, id_ in zip(scores, ix):
                    completed_hypotheses[i].append(Hypothesis(
                        value=[self.vocab.idx2word[a.item()] for a in hypotheses[i][id_][1:]],
                        score=score))
            completed_hypotheses[i].sort(key=lambda hyp: hyp.score, reverse=True)
        # print('completed_hypotheses', completed_hypotheses)
        return r2l_completed_hypotheses, completed_hypotheses
```

发现Pytorch之前有点搞忘，故直接在该博主的博客中补习Pytorch的基础，地址链接：https://www.cnblogs.com/nickchen121/p/14662511.html

今日剩余时间整理数据、无其他事项，休息。

------





## 2024.12.23 周一

今日上午在图书馆学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture10: Depth-First Search（Instructor: Justin Solomon）：

​	This class builds on the previous lecture of breadth-first search (BFS) by introducing depth-first search (DFS) and full-BFS and full-DFS. The lecture continues with topological sorts and cycle detection.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-10-depth-first-search/

Connectivity on undirected graph:

​	An undirected graph is connected if there is a path connecting every pair of vetices.

​	In a directed graph, the vertice $u$ may be reachable from vertice $v$, but $v$ may not be reachable from $u$.

​	Connectivity is much more complicated in directed graph than undirected graph.

​	`Connectivity(G)`: is undirected graph connected?

​	`Connected_components(G)`: given undirected graph $G=(V,E)$, return partittion of $V$ into subsets $V_i \subseteq V$ (Connected compoenents) where each $V_i$ is connected in G and there are no edges between vertices from different connected components.

MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture11: Weighted Shortest Paths（Instructor: Jason Ku）：

​	This lecture discusses weighted graphs and weighted paths. This prepares for the next four lectures, which are on algorithms to find shortest-path weights in weighted graphs.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-11-weighted-shortest-paths/

补充最短路径算法资料：https://zhuanlan.zhihu.com/p/33162490

下午学习MLCB2024-Lecture04-Sequence Alignment，地址链接：https://www.youtube.com/watch?v=3Fz1wNpFFnw。主要的重点就是Needleman-Wunsch Algorithm【Global Alignment】、Simth-Waterman Algorithm【Local Alignment】、Karp-Rabin Algorithm【Semi-global Alignment】、BLAST Algorithm。

Note: The step of the BLAST algorithm:

​	Recive Query: Split query into overlapping word of length W; Find neighborhood words for each word until threshold T; Look in table where these neighbor words occurs: seeds S; Extends seed S until score drops off under X.

​	Report significance and alignment of each match.

<img src="./assets/BLASTAlgorithmOverview.png" alt="BLASTAlgorithmOverview" style="zoom:25%;" />

复习DSA（Data Structure and Algorithm）的资料：https://www.wscubetech.com/resources/dsa

晚上配合视频学习PyTorch：地址链接：https://www.bilibili.com/video/BV1RiDJYmEEU/

梯度下降法：



线性回归：

实现损失函数（loss of function）即$loss= L = \sum_{i = 1}^n (y_i - (w \cdot x_i + b))^2$：

```python
def compute_average_error_for_given_points(w, b, points):
  totalError = 0
	for i in range(0, len(points)):
    x = points[i, 0]
    y = points[i, 1]
    totalError = (y - w * x - b)**2
 	return totalError / float(len(points))
```

实现梯度下降（grad_decent）即$w' = w - lr \frac{\partial L}{\partial x} = 2 * L$ 和$b' = b - lr \frac{\partial L}{\partial y}$：

```python
def step_gradient(w_current, b_current, points, learningRate):
  b_current = 0
  w_current = 0
  N = float(len(points))
  for i in range(0, len(points)):
    x = points[i, 0];
    y = points[i ,1];
    b_average_gradient += -(2 / N) * (y - ((w_current * x) + b_current))
    w_average_gradient += -(2 / N) * x * (y - ((w_current * x) + b_current))
  new_b = b_current - (learningRate * b_average_gradient)
  new_w = w_current - (learningRate * w_average_gradient)  
  return [new_w, new_b]
```

```python
import numpy as np

def gradient_descent(points, start_w, start_b, learningRate, iter):
  w = start_w
  b = start_b
  for i in range(iter):
    w, b = step_gradient(w, b, np.array(points), learningRate)
  return [w, b] 
```

实战：MNIST集（手写数字识别）：

```python
import torch
from torch import nn
from torch.nn import functional as F
from torch import optim

import torchvision
from matplotlib import pyplot as plt
import utils import image, plot_curve, one_hot

batch_size = 512

# step1.load dataset
train_loader
test_loader

class Net(nn.Module):
  def __init__(self):
    super(Net, self).__init__()
    
    # x * w + b
    self.fc1 = nn.Linear(28 * 28, 256)
    self.fc1 = nn.Linear(256, 64)
    self.fc1 = nn.Linear(64, 10)
  
  def forward(self, x):
    # x: [b, 1, 28, 28]
    # h1 = w1 * x + b1
    x = F.relu(self.fc1(x))
    # h2 = w2 * h1 + b2    
    x = F.relu(self.fc2(x))    
    # h3 = w3 * h2 + b1    
		x = self.fc3(x)
    
    return x
  
net = Net()  
# [w1, b1, w2, b2, w3, b3]
optimizer = optim.SGD(net.parameters(), lr = 0.01, momentum = 0.9)
train_loss = []  
  
for epoch in range(3):
  for batch_idx, (x, y) in enumerate(train_loader):
    # x: [b, 1, 28, 28], y: [512]
    # [b, 1, 28, 28] ---> [b, feature]
		x = x.view(x.size(0), 28 * 28)
    # [b, feature] ---> [b, 10]
    out = net(x)
   	# [b, 10]
    y_onehot = one_hot(y)
    # loss = mse(out, y_onehot)
    loss = F.mse_loss(out, y_onehot)
    
    optimizer.zero_grad()
    loss.backward()
    # w' = w - lr * grad
    optimizer.step()
    train_loss.append(loss.item())
    
    if batch_idx % 10 == 0:
      print(epoch, batch_idx, loss.item())

plot_curve(train_loss)
# we get optimal [w1, b1, w2, b2, w3, b3] 
total_correct = 0
for x, y in test_loader:
  x = x.view(x.size(0), 28 * 28)
  out = net(x)
  # out: [b, 10] => pred: [b]
  pred = out.argmax(dim = 1)
  corret = pred.eq(y).sum().float().item()
  total_correct += correct
total_num = len(test_loader)
acc = total_correct / total_num 
print("test acc: %d", acc)

# visulization
x, y = next(iter(test_loader))
out = net(x.view(x.size(0), 28 * 28))
pred = out.argmax(dim = 1)
plot_image(x, pred, 'test:')
```

然后回基法实验室给小鼠照光，测量肿瘤及体重大小。

------





## 2024.12.24 周二

今日上午稍微休息晚起，然后去图书馆学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture12: Bellman-Ford（Instructor: Jason Ku）：

​	This lecture introduces a single source shortest path algorithm that works for general graphs. The process, correctness, and running time of the Bellman-Ford algorithm is discussed.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-12-bellman-ford/

Exercise1: given an undirected graph $G$, return $G$ whether contains negative weight cycle. 

Exercise2: design a algorithm to solve SSSP in $O(|V|(|V|+|E|))$, and show how to solve SSSP in $O(|V|\cdot |E|)$

Note: SSSP——Simple Shortest Single Path

For Simple Shortest Path problem, we have such claims:

- claim1: If $\delta(s,v)$ is finite, $\exist$ a shortest path $s \rightarrow v$ that is simple. **[simple path have $\le$ $|V|-1$ edges]**

Definition: $k$ edge Distance $\delta_k(s,v)$: weight of a shortest $s \rightarrow v$ using $\le k$ edges.

We can infer that if $\delta_{|V|}(s,v) \lt \delta_{|V|-1}(s,v)$, then $\delta(s,v) = -\infty$, $v$ is witness.

- claim2: if $\delta(s,v) = - \infty$, then $v$ is reachable from a witness.

Bellman-Ford Algorithm: 

```

```

中午抽空去国重会议室参加读书报告，饭后稍微作息继续学图书馆学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture13: Dijkstra（Instructor: Jason Ku）：

​	This class discusses a fourth weighted single-source shortest path algorithm: Dijkstra’s algorithms. **Non-negative** edge weights are introduced. There is a worked example of applying Dijkstra’s algorithm.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-13-dijkstra/

Observation(1). If weights $\ge$ 0, then distance increases along SPs.

Observation(2). Solve SSSP if given order of vertices in increasing distance

Dijkstra's algorithem:

Ideal1: Relax edges from vertices in increasing distance from $s$.

Ideal2: Find next vertex efficiently use a DS (Changable Priority Queue）

然后学习MLCB2024-Lecture05-Epigenome, HMMs，地址链接：https://www.youtube.com/watch?v=U6HPrUJex8I，主要重点：

Burrows-Wheeler Transform（BWT）：

<img src="./assets/BWT.png" alt="BWT" style="zoom:25%;" />

Sequencing of Quality Control:

​	1.Use of input DNA as control dataset.

​	2.Read-level sequencing quality score $\ge$ 10.

​	3.Fraction of short read map $\gt$ 50%.

​	4.Library complexity: non-redundant fraction【non-redundant fraction, NRF = $\frac{\text{No. of distinct unique-mapping reads}}{\text{No.of unique-mapping reads}}$, NRF should be $\gt$ 0.8 when 10M < #reads < 80M unique-mapping reads】（If your sample does not contain enough DNA or RNA sequence or you over-sequence, you will simply be repeatedly sequencing PCR duplicated of a restrict pool of a distinct DNA fragments, which is **Low-complexity library** and is not desired）.

​	5.Exploit ChIP forward vs. reverse reads ---> Strand cross-correlation (CC) analysis. 

<img src="./assets/StrandCCAnalysis.png" alt="StrandCCAnalysis" style="zoom:25%;" />

<img src="./assets/StrandCCAnalysis1.png" alt="StrandCCAnalysis1" style="zoom:25%;" />

<img src="./assets/StrandCCAnalysis2.png" alt="StrandCCAnalysis2" style="zoom:25%;" />

HMMs models:

<img src="./assets/HMMs2.png" alt="HMMs2" style="zoom:25%;" />

​	After sequcing, we have big unlabeled region of DNA. So modeling biological sequence with HMMs is ability to emit DNA sequences of a certain type, to recognize DNA sequences of a certain type, and to learn distinguishing charateristics of each state.

<img src="./assets/HMMs.png" alt="HMMs" style="zoom:25%;" />

<img src="./assets/HMMs1.png" alt="HMMs1" style="zoom:25%;" />

Viterbi Algorithm:

​	The key is to calculate the maximum $\text{P}(x, \pi)$: 

<img src="./assets/ViterbiAlgorithm.png" alt="ViterbiAlgorithm" style="zoom:25%;" />

傍晚学累了看一篇文献休息：

[4] Fu, M., Zhao, J., Zhang, L., Sheng, Z., Li, X., Qiu, F., Feng, Y., You, M., Xu, H., Zhang, J., Zeng, R., Huang, Y., Li, C., Chen, W., Chen, Z., Peng, H., Li, L., Wu, Y., Ye, D., Chi, Y., … Mao, Y. (2024). Overcoming tyrosine kinase inhibitor resistance in lung cancer brain metastasis with CTLA4 blockade. *Cancer cell*, *42*(11), 1882–1897.e7. https://doi.org/10.1016/j.ccell.2024.09.012

主要的几个复习点：

- 复习EpCAM：EpCAM (epithelial cell adhesion molecule) is a cell surface glycoprotein that plays a crucial role in cell-cell adhesion, maintaining epithelial integrity, and regulating various signaling pathways. It is also known as CD326. EpCAM is expressed on the surface of many epithelial cells, and its function is critical in tissue organization and maintaining the structure of epithelial layers. EpCAM is overexpressed in various types of epithelial cancers, such as colon cancer, breast cancer, and prostate cancer. As a result, EpCAM is a target for cancer diagnosis and therapeutic intervention. EpCAM expression on tumor cells is often used as a marker for circulating tumor cells (CTCs) in blood, which are important for early cancer detection and monitoring metastatic spread. EpCAM is also considered a marker for cancer stem cells (CSCs), which are a subpopulation of cells within a tumor that are responsible for tumor initiation, growth, and resistance to treatment. Targeting EpCAM-positive cells may help in eliminating CSCs and preventing tumor recurrence.

- 几个常用的分子marker





------





## 2024.12.25 周三

今日上午去图书馆学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture14: APSP and Johnson Algorithm（Instructor: Jason Ku）：

​	This lecture focuses on solving any all-pairs shortest paths (APSP) in weighted graphs. Johnson’s algorithm is introduced.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-14-apsp-and-johnson/

Summary of algorithm in previous four lectures:

| Graph   | Weights      | Name           | Running Time $O(\cdot)$  |
| ------- | ------------ | -------------- | ------------------------ |
| General | Unweighted   | BFS            | $|V|+|E|$                |
| DAG     | Any          | DAG relaxation | $|V|+|E|$                |
| General | Non-negative | Dijkstra       | $|V|\text{log}|V| + |E|$ |
| General | Any          | Bellman-Ford   | $|V| \cdot |E|$          |

Johnson's Algorithm:



MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture15: Dynamic Programming, Part 1: SRTBOT, Fib, DAGs, Bowling（Instructor: Erik Demaine）：

​	This is the first of four lectures on dynamic programing. This begins with how to solve a problem recursively and continues with three examples: Fibonacci, DAG shortest paths, and bowling.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-15-dynamic-programming-part-1-srtbot-fib-dags-bowling/

Key: **Dynamic Programming = recursion(recursive function returns stored solution or if doesn't exist, compute and restore it) + memorization(remeber &re-use solutions to subproblems -> maintain a dictionay mapping subproblems)**

PseudoCode:

```
memo = {}

def f(subprobs):

	if subprobs in memo:

		return memo[subprobs];

	else:

		compute the subprobs based on the recursive relation and store it as memo[subprobs]
```

Running Time Analysis: $T(n) = T(\frac{n}{2}) + O(n) = \Theta(n\log n) \le O(n^3)$.

然后继续学习MLCB2024-Lecture06-Regulatory Circuitry，地址链接：https://www.youtube.com/watch?v=PJFRz1vrGEI

Viterbi Traning:

​	Initiation: Pick the best (abitrary) guess for model parameters. 

​	Iteration: Perform the Viterbi Algorithm to find $\pi^*$ -> Calculate the $A_{kl}, E_k(b)$ according to $\pi^*$ + pseudocounts -> Calculate the new parameters $a_{kl}, e_k(b)$. Repeat these steps until convergence.

中午学习读书报告会：汪源教授——《肿瘤早期演进可视化和靶向干预》

下午整理MIT 18.05 | Spring 2022 | Undergraduate —— 《Introduction To Probability And Statistics》的课程资料，然后复习Python: https://www.youtube.com/watch?v=EHi0RDZ31VA，然后学习Advanced Python Tutorials，地址链接：https://www.youtube.com/watch?v=KSiRzuSx120

1.Magic Methods & Dunder

```python
class Vector:
  def __init__(self, x, y):
    self.x = x
    self.y = y
  
  def __add__(self, other):
    return Vector(self.x + other.x, self.y + other.y)
  
  def __repr__(self,):
    return f"X: {self.x}, Y: {self.y}"
  
  def __len__(self):
    return 10
  
  def __call__(self):
    return "Hello, I am called!"
  
v1 = Vector(10, 20)
v2 = Vector(10, 20)

v = v1 + v2 # Error if we doesn't define the __add__ function
print(v.x) # 20
print(v.y) # 40
print(len(v)) # 10
v() # "Hello, I am called!"
```

2.Decorators

```python
def mydecorator(function):
  
  def wrapper():
    print("I am decorating your function")
    function()
    
  return wrapper  

def hello_world():
  print("Hello, World!")
  
mydecorator(hello_word)() # I am decorating your function\n Hello, World!
```

```python
def mydecorator(function):
  
  def wrapper():
    print("I am decorating your function")
    function()
    
  return wrapper  

@mydecorator
def hello_world():
  print("Hello, World!")
  
hello_world() # I am decorating your function\n Hello, World!
```

```python
def mydecorator(function):
  
  def wrapper(*args, **kwargs):
    print("I am decorating your function")
    function(*args, **kwargs)
    
  return wrapper  

@mydecorator
def hello_world(person):
  print(f"Hello, World!, {person}")
  
hello_world("Baimiaomiao") # I am decorating your function\n Hello, World!, Baimiaomiao
```

```python
def mydecorator(function):
  
  def wrapper(*args, **kwargs):
    return_value = function(*args, **kwargs)
    print("I am decorating your function")
    return return_value
    
  return wrapper  

@mydecorator
def hello_world(person):
  print(f"Hello, World!, {person}")
  return f"Hello, World!, {person}"
  
print(hello_world("Baimiaomiao")) #  Hello, World!, Baimiaomiao\nI am decorating your function\n Hello, World!, Baimiaomiao
```

Example1:

```python
def logged(function):
  def wrapper(*args, **kwargs):
    value = function(*args, **kwargs)
    with open('log.txt', 'w') as f:
      fname = function.__name__
      printf(f"{fname} returned value {value}")
    f.close()  
    return value
  
  return wrapper  

@logged
def add(x, y):
  printf("Add Operation")
  return x + y

print(add(10, 20)) # Add Operation \n add returned value 30 \n 30
```

Example2:

```python
import time

def timed(function):
  def wrapper(*args, **kwargs):
    before = time.time()
	  value = function(*args, **kwargs)
  	after = time.time()
  	fname = function.__name__
		print(f"{fname} took {after - before} seconds after the program excutes")
  	return value
  
  return wrapper

@timed
def myfunction(n):
  ret = 0;
  for i in range(n):
    ret += i
  return ret

print(myfunction(100))
```

3.Generators

```python
def mygenerator(n):
  for i in range(n)
  	yield i**3
    
values = mygenerator(100)
print(next(values)) # 0 
print(next(values)) # 1
print(next(values)) # 8
print(next(values)) # 27
```

4.Argument Parsing

```python
def myfunction(*args, **kwargs):
  print(args[0])
  print(args[1])
  print(args[2])
  print(args[3])  
  print(kwargs["key_one"]) 
  print(kwargs["key_two"])

myfunction('hey', 19, True, 'wow', key_one = "one", key_two = "two") # hey \n 19 \n True \n wow \n one \n two
```

```python
import sys

# Usage: main.py FILENAME MESSAGE
filename = sys.argv[0]
message = sys.argv[1]

with open(filename, 'w') as f:
  f.write(message)
```

```python
import sys
import getopt

opts, args = getopt.getopt(sys.argv[1:], "f:m:", ['filename', 'message'])

print(opts)
print(args)

# main.py -f log.txt -m "Hello, world!" xixi #[('-f', 'log.txt'), ('-m', 'Hello, world!')] ['xixi']
```

5.Encapsulation

```python
class Person:
  def __init__(self, name, age, gender):
    # private attributes
    self.__name = name
    self.__age = age
    self.gender = gender
    
  @property  
  def Name(self):
    return self.__name;
  
  @Name.setter
  def Name(self, name):
    return self.__name = name
  
  @staticmethod
  def mymethod():
    print("Hello, World!")  
```

6.Type Hinting （与mypy包配合使用）

```python
def myfunction(myparameter: int) -> str:
  return f"{myparameter + 10}"
 
def myfunction1(myparameter: list[int], index: int) -> int:
  return myparameter[index]
```

以下是简要介绍几种设计模式：**Factory Design Pattern、Proxy Design Pattern、Singleton Design Pattern、Composite Design Pattern**

7.Factory Design Pattern：a **creational design pattern** that provides an interface for creating objects in a super class, but allows subclasses to alter the type of objects that will be created. It is used to achieve **loose coupling** by delegating the instantiation logic to child classes. The pattern encapsulates the object creation logic and promotes the **open/closed principle**, meaning new types of objects can be added without modifying the existing code.

```python
from abc import ABCMeta, abstractstaticmethod

class IPerson(metaclass = ABCMeta):
  @abstractstaticmethod
  def person_method():
    """Interface method"""
    
class Student(IPerson):
  def __init__(self, name):
    self.name = name
  def person_method(self):
    print("I am a student")
    
class Teacher(IPerson):
  def __init__(self, name):
    self.name = name
  def person_method(self):
    print("I am a teacher")    
    
class PersonFactory:
  @staticmethod
  def create_person(person_type):
    if person_type == 'student':
      return Student()
    elif person_type == 'teacher':
      return Teacher()
    else:
      print("Error")
    return -1  
```

8.Proxy Design Pattern：a **structural design pattern** that provides a **surrogate or placeholder** for another object to control access to it. It acts as an intermediary, adding an extra level of control or functionality without modifying the original object. The Proxy pattern is useful in scenarios where direct access to an object is not desirable or possible, such as for **security**, **performance optimization**, or **lazy initialization**.

```python
from abc import ABCMeta, abstractstaticmethod

class IPerson(metaclass = ABCMeta):
  @abstractstaticmethod
  def person_method():
    """Interface method"""
    
class Person(IPerson):
  def person_method(self):
    print("I am a Person")    
    
class ProxyPerson(IPerson):
  def __init__(self):
    self.person = Person()
  def person_method(self):
    print("I am the proxy personality")
    self.person.person_method()
```

9.Singleton Design Pattern：a **creational design pattern** that ensures a class has only **one instance** and provides a global point of access to that instance. It is widely used to manage shared resources, such as **configuration settings**, **logging**, or **thread pools**, where it is essential to have only a single instance controlling the system's behavior.

```python
from abc import ABCMeta, abstractstaticmethod

class IPerson(metaclass = ABCMeta):
  @abstractstaticmethod
  def print_data():
    """Implement in child class"""
    
class PersonSingleton(IPerson):
  
  __instance == None
  
  @staticmethod
  def get_instance():
    if PersonSingleton.__instance == None:
      PersonSingleton("Default Name", 0)
    return __instance
  
  def __init__(self, name, age):
    if PersonSingleton.__instance != None:
      raise Exception("Singleton cannot be instantiated more than once!")
    else:    
    	self.name = name
    	self.age = age
    	Personsingleton.__instance = self
      
  def print_data():
    print(f"Name: {PersonSingleton.__instance.name}, age: {PersonSingleton.__instance.age}")
    
p = PersonSingleton('Mike', 30)
p
p.print_data() # Name: Mike, age: 30

p2 = PersonSingleton('Jason', 40) #Error 

p3 = PersonSingleton.get_instance()
p3.print_data() # Name: Mike, age: 30
```

10.Composite Design Pattern：a **structural design pattern** that is used to treat a group of objects in the same way as a single instance of an object. It allows you to build a **tree-like structure** to represent **part-whole hierarchies** and enables clients to interact with the individual objects and their compositions **uniformly**.

```python
from abc import ABCMeta, abstractmethod ,abstractstaticmethod

class IDepartment(metaclass = ABCMeta):
  
  @abstractmethod
  def __init__(self, employees):
		"""Implement in child class"""
    
  @abstractstaticmethod
  def print_department():
    "Implement in child class"
    
class Accounting(IDepartment):
  
  def __init__(self, employees):
    self.employess = employees
    
  def print_data():
    print(f"Accounting Department: {self.employees}")
    
class Development(IDepartment):
  
  def __init__(self, employees):
    self.employess = employees
    
  def print_data():
    print(f"Development Department: {self.employees}")    
    
class ParentDepartment(IDepartment):
  
  def __init__(self, employees):
    self.employees = employees
    self.base_employees = employees
    self.sub_depts = []
    
  def add(self, dept):
    self.sub_depts.append(dept)
    self.employees += dept.employees
    
   def print_department(self):
    print("Parent Department")
    print(f"Parent Department Base Employees: {self.base_employees}")
    for dept in self.sub_depts:
      dept.print_department()
    print(f"Total number of empolyess: {self.empolyees}")  
    
dept1 = Accounting(200)
dept2 = Development(170)

parent_dept = ParentDepartment(30)
parent_dept.add(dept1)
parent_dept.add(dept2)
```

晚上学习Pytorch的基础操作，然后去基法实验室给小鼠的近端肿瘤照光（2min/只）。



------





## 2024.12.26 周四

今日上午睡觉休息大脑，最近学习有点疯狂，需要足够的休息。

下午开始学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture16: Dynamic Programming, Part 2: LCS, LIS, Coins（Instructor: Erik Demaine）：

​	This is the second of four lectures on dynamic programming. This introduces multiple sequence, substring subproblems, and parent pointers. Three examples of subproblem constraints and expansion are given.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-16-dynamic-programming-part-2-lcs-lis-coins/

a.Longest Common Subsequence (LCS)

​	Given two strings A and B, ﬁnd a longest (not necessarily contiguous) subsequence of A that is also a subsequence of B. 

Python算法实现：

```python
def lcs(X, Y):
    m = len(X)
    n = len(Y)

    # Create a 2D table to store lengths of longest common subsequence.
    dp = [[0] * (n + 1) for _ in range(m + 1)]

    # Build the table dp[][] in bottom-up fashion.
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if X[i - 1] == Y[j - 1]:
                dp[i][j] = dp[i - 1][j - 1] + 1
            else:
                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])

    # The length of the LCS is in the bottom-right cell of the matrix.
    lcs_length = dp[m][n]

    # To print the LCS, we backtrack from dp[m][n]
    lcs_string = []
    i, j = m, n
    while i > 0 and j > 0:
        if X[i - 1] == Y[j - 1]:
            lcs_string.append(X[i - 1])
            i -= 1
            j -= 1
        elif dp[i - 1][j] >= dp[i][j - 1]:
            i -= 1
        else:
            j -= 1

    # The LCS is built in reverse order
    lcs_string.reverse()

    return lcs_length, ''.join(lcs_string)

# Example Usage
X = "AGGTAB"
Y = "GXTXAYB"

length, lcs_str = lcs(X, Y)
print(f"Length of LCS: {length}") # Length of LCS: 4
print(f"LCS: {lcs_str}") # LCS: GTAB
```

Java实现（LeecCode算法题1143.最长公共子序列：https://leetcode.cn/problems/longest-common-subsequence/ —— 给定两个字符串 `text1` 和 `text2`，返回这两个字符串的最长 **公共子序列** 的长度。如果不存在 **公共子序列** ，返回 `0` 。一个字符串的 **子序列** 是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。）：

```java
class Solution {
    public int longestCommonSubsequence(String text1, String text2){
        int m = text1.length();
        int n = text2.length();
        int[][] dp = new int[m+1][n+1];

        for (int i = 0; i < m; i++){
            for (int j = 0; j < n; j++){
                if (text1.charAt(i) == text2.charAt(j)){
                    dp[i+1][j+1] = dp[i][j] + 1;
                }else{
                    dp[i+1][j+1] = Math.max(dp[i+1][j], dp[i][j+1]);    
                }
            }
        }
        return dp[m][n];
    }
}
```



MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture17: Dynamic Programming, Part 3: APSP, Parens, Piano（Instructor: Erik Demaine）：

​	This is the third of four lectures on dynamic programming. This focusses on applying subproblem constraints and expansions to example problems including, Bellman-Ford SSSP, Floyd-Warshall APSP, arithmetic parenthesization, and piano/guitar fingering.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-17-dynamic-programming-part-3-apsp-parens-piano/

傍晚学习MLCB2024-Lecture08-Intro to protein structure，地址链接：https://www.youtube.com/watch?v=Hp3pjYaMsnU

Key Resource for structural biology: PyMol（molecular visualization）、RCSB（database of molecular struture）、AlphaFold（structural prediction DB and software）、ESMFlod（structural prediction DB and software）

Experimetal method for detecting protein struture:

- X-Ray Crystallography——Do not capture dynamic struture.
- NMR——capture dynamic structure and idenfity the protein-ligand interaction in solution, generally only for small proteins (< 50KDa)
- CryoEM——No need for crystallization of molecules, ideal for large complex of protein (ribosome, virus, et al.), large ensembles of molecules are imaged and these are fit together into 3D shape using algorithms, capture multiple conformation of a molecule in one sample.

Protein structure basis——conformation:

​	The 3D shape or conformation of a protein is deterimed by the dihedral angle of each of its rotatable bonds. The global structure of a protein is determined by the rotations of the backbone {$\phi,\psi,\omega$} for each residue. In practice, {$\phi,\psi$} are sufficient to describe the rotational state for most residues besides proline. Each rotatable bond has approximately 3 states.

The protein folding problem: 

- Anfinson(1950s) - thermodynamic hypothesis: proteins adopt conformation is a global energy minumum.
- Levinthal Paradox(1969) - proteins can't exhausitvely sample all possible conformations, yet fold very quickly (< ms to sec).
- Contact order predicts folding rates(1998) - more local interaction means faster folding. 

Levels of protein structure: Primay -> Secondary -> Tertiary -> Quartenary.

Predicting protein secondary structure: 

- Chou-Fasman(1974) - compute relative likelihood of observing AA in each secondary structure P(aa | helix) / P(aa), P(aa | sheet) / P(aa), P(aa | coil) / P(aa). And hoc rules for finding stretches of AAs compatible with secondary structure.
- PHD(1993) - 3 layer INN, first to use evolutionary data from MSAs.
- PSIPERD and other deep learning methods (~ 2000s).
- AlphaFold2 (2020) - 3D structure prediction implicity predicts high-quality secondary struture.

Tertiary structure prediction milestones:

- CASP (Critical Assessment of Protein Structure Prediction)catalyzed improvement in prediction methods by holding blind competitions.

- Rosetta(1990s) - combined fragments of proteins from PDB and scored them using a physics/stats-based energy function.
- AlphaFold2(2020) - utilized evolutionary information and deep learning.

然后晚上学习CS50x 2024_Lecture07_SQL课程，地址链接：https://www.youtube.com/watch?v=1RCMYG8RUSE，学习平面文件（Flat-File Database）和关系数据库（Relational Database），复习SQL查询语句（Query）、主键与外键（Primary/Foreign Key）、索引（Indexes）、关键字（Kewords），Python如何调用SQL（SQL in Python），竞态条件（Race Conditions）、SQL注入攻击（SQL injection attacks）。

竞态条件是指一个系统或者进程的输出结果，依赖于**多个**不受控制的事件（也可以称为两个信号），两个事件相互竞争，来影响最终输出的结果。竞态条件的典型场景：多个线程对同一共享资源进行读写操作、资源没有共享机制，解决竞态条件的方法：

1. **互斥锁（Mutex）**：确保同一时刻只有一个线程可以访问共享资源，其他线程必须等待。
2. **信号量（Semaphore）**：用于控制对资源的访问数量，避免过多线程同时访问共享资源。
3. **读写锁**：在允许多个线程并发读取共享资源的同时，确保写操作是独占的。
4. **原子操作**：某些操作（如增加、减少等）是原子性的，即操作不可分割，可以避免竞态条件。

------





## 2024.12.27 周五

今日上午先去基法实验室合成药物，然后给近端肿瘤局部注射药物，然后去图书馆学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture18: Dynamic Programming, Part 4: Rods, Subset Sum, Pseudopolynomial（Instructor: Erik Demaine）：

​	This is the fourth and final lecture on dynamic programming. This class focusses on integer subproblems and pseudopolynomial time. Two worked examples are given: rod cutting and subset sum.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-18-dynamic-programming-part-4-rods-subset-sum-pseudopolynomial/

a.Rob cutting

b.Subset sum

MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture18: Complexity（Instructor: Erik Demaine）：

​	This lecture discusses computational complexity and introduces terminology: P, NP, EXP, R. These terms are applied to the concepts of hardness and completeness. The lecture ends with discussion on reductions.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-19-complexity/

The relation among these terminology: $P \subset NP \subset EXP \subset R$

中午复习Machine Learning（Instructor: Andrew Ng），地址链接：https://www.bilibili.com/video/BV1Bq421A74G/:

1.Supervised learning vs Unsupervised learning

Supervised learning learn from data labeled with the "right answers", while unsupervised learning find something interested in unlabeled data.

Unsupervised learning data nonly comes with inputs x, but not output label y. The algorithm ias to find structure in the data or dataset. There are many types of unsupervised learning, such as clustering(group similar data points together), anomaly detection(find unsual data points), dimensional reduction(compress data using fewer numbers).

2.Linear regression with one variable

Terminlogy: Training set, input/feature, output/target/prediction,$(x^{(i)},y^{(i)}) = i^{th}$ training example(single training example), 

We assume that the relation $x$ and $y$ is linear, so we have the model function $f_{w,b} = wx +b$, where $w$ and $b$ are parameters

Cost function: To find the optimal parameters $w$ and $b$ to make $\hat{y}^{(i)}$ close to $y^{(i)}$ for $\forall x^{(i)},y^{(i)}$, we introduce the cost function to denote the bias of true value from prediction value (here is a squard error cost function) :
$$
\text{Cost function}= J(w,b) = \frac{1}{2m}\sum_{i = 0}^m (\hat{y}^{(i)} - y^{(i)})^2  \\
= \frac{1}{2m}\sum_{i = 0}^m(f_{w, b}(x^{(i)})- y^{(i)})^2
$$
where $m$ is the number of the traning examples.

The goal for this model is to find the parameters $w$ and $b$ under minimum cost function called $\text{minimize}_{w,b}J(w,b)$. 

3.Gradient descent

Problem: we have some function $J(w,b)$, we want $\text{min}_{w,b} J(w,b)$ 【more geneal, $J(w_1, w_2, w_3,...,b) \rightarrow \text{min}_{w,b}J(w_1, w_2, w_3,...,b)$】

Outline: we start with some $w$ and $b$ and keep changing $w,b$ to reduce $J(w,b)$ .

Gradient descent algorithm: 
$$
w = w - \alpha \cdot \frac{\partial}{\partial w} J(w,b) \\
b = b - \alpha \cdot \frac{\partial}{\partial b} J(w,b)
$$
where the $\alpha$ is called **learning rate**. If the $\alpha$ is too small, gradient descent may be slow, while too large may be over shoot and divergent, never reach minimum. With the change of $w,b$ derivative becomes smaller $\rightarrow$ update steps become smaller, it can reach minimum without decreasing learning rate.

For solution of partial derivative of $J(w,b)$ about $w,b$:
$$
\frac{\partial}{\partial w} J(w, b) = \frac{1}{m}\sum_{i = 0}^m(f_{w, b}(x^{(i)})- y^{(i)})x^{(i)} \\
\frac{\partial}{\partial w} J(w, b) = \frac{1}{m}\sum_{i = 0}^m(f_{w, b}(x^{(i)})- y^{(i)})
$$
so, take them into the gradient descent algorithm:
$$
w = w - \alpha \cdot \frac{1}{m}\sum_{i = 0}^m(f_{w, b}(x^{(i)})- y^{(i)})x^{(i)} \\
b = b - \alpha \cdot \frac{1}{m}\sum_{i = 0}^m(f_{w, b}(x^{(i)})- y^{(i)})
$$
4.Multiple features(variables), multiple linear regression, vectorization

Notations: $x_j = j^{th}$ feature, $n = $ number of features, $\vec{x}^{(i)} = $ features of $i^{th}$ training example, $x_{j}^{(i) } = $ value of feature $j$ in $i^{th}$ training example.

Model function: $f_{w,b} = w_1x_1 + w_2x_2 + w_3x_3 + ...+ w_nx_n + b = \sum_{j = 1}^{n}w_jx_j + b$, we can write it as matrix forms:
$$
f_{\vec{x},b} = \vec{w} \cdot \vec{x} + b
$$
where $\vec{w} = [w_1, w_2, w_3, ... ,w_n]$, $\vec{x} = [x_1, x_2, x_3, ... ,x_n]$ and $b$ is a number.

The cost funtion: $J(w_1,w_2,w_3, ... ,b)$

The partial derivative of multiple features:
$$
w_j = w_j - \alpha \cdot \frac{1}{m}\sum_{i = 0}^m(f_{w, b}(x^{(i)})- y^{(i)})x_j^{(i)} \\
b = b - \alpha \cdot \frac{1}{m}\sum_{i = 0}^m(f_{w, b}(x^{(i)})- y^{(i)})
$$
for $j = 1,2,3,...,n$.

5.Feature scaling、Gradient convergence、Choosing learning rate、Feature engineering、polynomial regression

Feature scaling aims for find suitable value range about $\text{min} \le x_j \le \text{max}$ for each feature $x_j$: Mean normalization、Z-score normalization.

Make sure gradient descent is working correctly: **$J(\vec{w}, b)$ should decrease after every iteration.** Automatic convergence test: let $\varepsilon$ be 0.001, if $J(\vec{w}, b)$ decreases by $\le$ $\varepsilon$ in one iteration, declare convergence.

With a small enough $\alpha$, $J(\vec{w},b)$ should decrease on every iteration. If $\alpha$ it too small, gradient descent takes a lot more iteration to converge.

Feature engineering: using intuition to design new features, by transforming or combining original features.

Polynomial regression: choosing the polynomial model function $f_{w,b}(x)=w_1x_1 + w_2x_2^2 + ...+b $ to do regression.

6.Motivation、Logistic regression、Decision boundary

binary classfication -> $y$ can only be one of two values `true` and `false`, `true` is positive class/category and `false` is negative class/category.

logistic function or sigmoid function -> outputs between 0 and 1:
$$
g(z) = \frac{1}{1+e^{-z}} \quad 0 \lt g(z) \lt 1
$$
if we use this function to the regression model function, we have:
$$
f_{\vec{w},b}(\vec{x}) =g(\vec{w} \cdot \vec{x} + b) = \frac{1}{1+e^{-(\vec{w} \cdot \vec{x} + b)}}
$$
That's called logistic regression.

E.g. $x$ is "tumor size", $y$ is $0$ (not malignant) and $1$ (malignant), $f_{\vec{w},b}(\vec{x})=0.7$ means 70% chance that $y$ is 1. And we have the uncertain relations: $P(y = 0) + P(y= 1) = 1$.  

Decision boundary: if we have the model $f_{\vec{w},b}(\vec{x}) = g(z) = g(\vec{x} \cdot \vec{w} + b)$, and if we think $g(z = \text{const}) \ge 0.5$ is positve and $g(z = \text{const}) \le 0.5$, then the decision boundary condition is $z = \text{const}$. 

7.Cost function for logistic regression、Simplified Cost Function、logistic regression gradient descent

The logistic loss function is: 

$L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)}) = -y^{(i)}\log(f_{\vec{w},b}(x^{(i)})) - (1 - y^{(i)})\log(1 - f_{\vec{w},b}(x^{(i)}))$ :
$$
L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)}) = \begin{Bmatrix}
 -\log(f_{\vec{w},b}(x^{(i)})) & \text{if}\ y^{(i)} = 1 \\
 -\log(1 - f_{\vec{w},b}(x^{(i)})) & \text{if}\ y^{(i)} = 0
\end{Bmatrix}
$$
we can see that loss is lowest when $f_{\vec{w},b}(\vec{x}^{(i)})$ predicts close to true label $y^{(i)}$, and further prediction $f_{\vec{w},b}(\vec{x}^{(i)})$ is from target $y^{(i)}$, the higher the loss.

<img src="./assets/CostFunctionForLogisticRegression.png" alt="CostFunctionForLogisticRegression" style="zoom:25%;" />

So, the cost function is:
$$
J(\vec{w},b) = \frac{1}{m}\sum_{i=1}^m[L(f_{\vec{w},v}(\vec{x^{(i)}}),y^{(i)})] \\
=-\frac{1}{m}\sum_{i=1}^m[y^{(i)}\log(f_{\vec{w},b}(x^{(i)})) + (1 - y^{(i)})\log(1 - f_{\vec{w},b}(x^{(i)}))]
$$
Ant then, we take them into the equations:
$$
w_j = w_j - \alpha \cdot \frac{1}{m}\sum_{i = 0}^m(f_{w, b}(x^{(i)})- y^{(i)})x_j^{(i)} \\
b = b - \alpha \cdot \frac{1}{m}\sum_{i = 0}^m(f_{w, b}(x^{(i)})- y^{(i)})
$$
to compute and renew the $w_j$ and $b$ for $j = 1,2,3,...,n$.

8.The problem of overfitting、Addressing overfitting、Cost function with regularization、Regularized logistic regression

Underfit -> does not fit the training set well -> high bias, Just night -> fits training set pretty well -> generalization, overfit -> fits the training set extremely well -> high variance. 

Addressing overfitting:

- Collect more training examples.
- Select features to include/exclude (superabundant features + insufficient data -> overfit).
- Reduce size of parameters -> Regularization.

<img src="./assets/Regularization.png" alt="Regularization" style="zoom:25%;" />

<img src="./assets/Regularization1.png" alt="Regularization1" style="zoom:25%;" />

For the regularization linear regression:
$$
J(\vec{w},b) = \frac{1}{2m}\sum_{i=1}^m(f_{\vec{w},b}(\vec{x}^{(i)})-y^{(i)})^2 +\frac{\lambda}{2m}\sum_{j=1}^m w_j^2
$$
The object is to find $\min_{\vec{w},b}J(\vec{w}, b)$. Implementing the gradient descent method:
$$
w_j = w_j - \alpha [\frac{1}{m}\sum_{i=1}^m[(f_{\vec{w}, b}(x^{(i)})-y^{(i)})x_j]+\frac{\lambda}{m}w_j] = w_j\underbrace{(1 - \alpha\frac{\lambda}{m})}_{\text{shrink}\ w_j} - \alpha\frac{1}{m}\sum_{i = 0}^m(f_{w, b}(x^{(i)})- y^{(i)})x_j^{(i)}\\
b = b - \alpha \frac{1}{m}\sum_{i=1}^m(f_{\vec{w}, b}(x^{(i)})-y^{(i)})
$$
For regularized logistic regression:
$$
J(\vec{w},b)=-\frac{1}{m}\sum_{i=1}^m[y^{(i)}\log(f_{\vec{w},b}(x^{(i)})) + (1 - y^{(i)})\log(1 - f_{\vec{w},b}(x^{(i)}))] + \frac{\lambda}{2m}\sum_{j=1}^mw_j^2
$$
we can also use the same rule act on them to get $w$ and $b$.

下午学习MLCB2024-Lecture09-Protein Folding Algorithm，地址链接：https://www.youtube.com/watch?v=ZSLzucWe424，笔记如下：

Ab initioprediction using energy functions: physical based methods make use of energy functions

Eletrostatics, Van der waals, Hydrogen bonds, Solvent interaction and the hydrophobic effect.

Some popular energy energy functions:

- AMBER
- CHARMM
- GROMOS
- OPLS

Can be used with explicit or implicit water models

How to interpret energies as probabilities: The Boltzmann distribution states that the energy of a state (eg, protein conformation) is related to the exponent of its energy. A more general form of the energy that has this property is referred to as the free energy.

Boltzmann distribution:
$$
p_i = \frac{1}{Q}\exp(-\frac{\varepsilon_i}{kT}) = \frac{\exp(-\frac{\varepsilon_i}{kT})}{\sum_{j=1}^M \exp(-\frac{\varepsilon_i}{kT})}
$$
where $\varepsilon_i = $ energy of state $i$, $kT = 2.5$ KJ/mol at 298K.

How AlphaFold2 works？Input -> MSA representation -> Pair representation -> Evoformer block -> Structure module -> Confidence measures.

<img src="./assets/AlphaFold2WorkFlow.png" alt="AlphaFold2WorkFlow" style="zoom:25%;" /> 

Both the MSA and pair representations embed amino acids (or pairs of AAs) as fixed dimensional vectors called embeddings(change the discrete data types into fixed dimensional contiunous data type). 

Actually, the AlphaFold is the transformer model(embedding, position, add&norm, multi-head attention, feedforward).

傍晚去基法实验室给小鼠照光（2min/只）并测量肿瘤大小，然后进行实验室大扫除。

晚上继续去图书馆学习Machine Learning（Instructor: Andrew Ng），整理笔记如上，然后阅读文献休息一下：

[5] Waibl Polania, J., Hoyt-Miggelbrink, A., Tomaszewski, W. H., Wachsmuth, L. P., Lorrey, S. J., Wilkinson, D. S., Lerner, E., Woroniecka, K., Finlay, J. B., Ayasoufi, K., & Fecci, P. E. (2024). Antigen presentation by tumor-associated macrophages drives T cells from a progenitor exhaustion state to terminal exhaustion. *Immunity*, S1074-7613(24)00541-7. Advance online publication. https://doi.org/10.1016/j.immuni.2024.11.026

记录笔记如下：



------





## 2024.12.28 周六

今日上午睡觉休息大脑，无其他事项。

中午及下午去图书馆学习MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture20: Course Review（Instructor: Jason Ku）：

​	This lecture reviews the main concepts and learning goals for the course. Students should be able to solve hard computational problems, argue an algorithm is correct, argue an algorithm is “good,” and effectively communicate the above.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-20-course-review/

The goals for this class: a.solve "hard" computational problems; b.argue corretcness; c.argue "good" <- model + assumption; d.communication.

Not always "good" algorithms to solve problems, but many problems we think about can be:

- check in polynomial time $NP$.
- solve by brute force in time $EXP$.

MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms——Lecture21: Algorithms—Next Steps（Instructor: Erik Demaine, Jason Ku, and Justin Solomon）：

​	In this lecture, Erik Demaine, Jason Ku, and Justin Solomon talk about their own research in algorithms. This includes origami, folding designs, and applied geometry.

地址链接：https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/resources/lecture-21-algorithms2014next-steps/

<u>至此MIT 6.006 | Spring 2020 | Undergraduate Introduction To Algorithms这门课程已经全部修完。</u>

然后继续学习MLCB2024-Lecture10-Protein Structure with Transformers，笔记如下：

Predicted LDDT: predicted local distance difference test(range from 0 - 100) ---> pLDDT <  50 are note reliable; pLDDT > 70 backbone accurate but maybe not sidechains; pLDDT > 90 suitable for docking, sidechains accurate.

AlphaFold3 architecture:

<img src="./assets/AlphaFold3Architecture.png" alt="AlphaFold3Architecture" style="zoom:25%;" />

MSA information is bottlenecked into pair representation. Diffusion model used to reconstruct 3D coords.

AlphaFold3 integrates molecular interactions such as nucleic acids, ligands, protein complexes modeled in a single framework.

Protein design: Generate new proteins that fit some design criteria ---> enzyme activity, protein-protein binding, molecular cage, biosensors. Protein design step: a.generate target backbone such as rational design, RFDiffusion(diffusion model); b.generate example sequences e.g.MPNN(using GNNs); c.build sequence -> structure using AlphaFold3; d.iterate at any step.

Diffusion model:

<img src="./assets/DiffusionModel.png" alt="DiffusionModel" style="zoom:25%;" />

RFDiffusion model:

<img src="./assets/RFDiffusion.png" alt="RFDiffusion" style="zoom:25%;" />

Protein MPNN:

<img src="./assets/MPNN.png" alt="MPNN" style="zoom:25%;" />

The left part of this lecture is to introduce the each layer of transformers.

再去看了看CS324的课程，发现assignments难度还是很大，先暂时不学这门课，先按照ChatGPT的建议学习CS224n这门课，地址链接：https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1246/（学习这门课之前，先学习CS229以及Machine Learning，等待CS224n 2025 Spring的课程）

简单学习了一下Word2Vec知识，借助ChatGPT学习Word2Vec的简单实现。

```python
import numpy as np
import random
from collections import Counter

class Word2Vec:
    def __init__(self, corpus, vector_size=100, window_size=5, min_count=1, negative_samples=5):
        self.vector_size = vector_size
        self.window_size = window_size
        self.min_count = min_count
        self.negative_samples = negative_samples
        self.corpus = corpus
        self.word_to_index = {}
        self.index_to_word = {}
        self.vocab = []
        
        # Step 1: Prepare data
        self._prepare_data()
        
        # Step 2: Initialize parameters (embedding matrix and context matrix)
        self._initialize_weights()
    
    def _prepare_data(self):
        """
        Prepare the vocabulary and word indices, ignore words with count lower than `min_count`
        """
        words = [word for sentence in self.corpus for word in sentence]
        word_count = Counter(words)
        self.vocab = [word for word, count in word_count.items() if count >= self.min_count]
        
        # Create word-to-index and index-to-word mappings
        self.word_to_index = {word: i for i, word in enumerate(self.vocab)}
        self.index_to_word = {i: word for i, word in enumerate(self.vocab)}
    
    def _initialize_weights(self):
        """
        Initialize word vectors randomly with small values
        """
        self.W_in = np.random.uniform(-0.1, 0.1, (len(self.vocab), self.vector_size))  # Input matrix
        self.W_out = np.random.uniform(-0.1, 0.1, (len(self.vocab), self.vector_size))  # Output matrix
    
    def _generate_context_pairs(self, sentence):
        """
        Generate (target, context) pairs for a given sentence.
        """
        for i, target in enumerate(sentence):
            target_idx = self.word_to_index.get(target, -1)
            if target_idx == -1:
                continue
            start = max(i - self.window_size, 0)
            end = min(i + self.window_size + 1, len(sentence))
            
            for j in range(start, end):
                if j != i:
                    context = sentence[j]
                    context_idx = self.word_to_index.get(context, -1)
                    if context_idx != -1:
                        yield target_idx, context_idx
    
    def _negative_sampling(self, target_idx):
        """
        Negative sampling: Select a few random words (not equal to target) to update weights.
        """
        negative_samples = []
        while len(negative_samples) < self.negative_samples:
            negative_idx = random.randint(0, len(self.vocab) - 1)
            if negative_idx != target_idx:
                negative_samples.append(negative_idx)
        return negative_samples
    
    def train(self, epochs=5, learning_rate=0.01):
        """
        Train the Word2Vec model.
        """
        for epoch in range(epochs):
            total_loss = 0
            for sentence in self.corpus:
                for target_idx, context_idx in self._generate_context_pairs(sentence):
                    # Positive sample
                    predicted = self.W_in[target_idx]
                    actual = self.W_out[context_idx]
                    score = np.dot(predicted, actual)
                    sigmoid_score = self.sigmoid(score)
                    error = sigmoid_score - 1
                    
                    # Gradient update (positive context)
                    self.W_in[target_idx] -= learning_rate * error * actual
                    self.W_out[context_idx] -= learning_rate * error * predicted
                    
                    # Negative sampling
                    negative_samples = self._negative_sampling(target_idx)
                    for negative_idx in negative_samples:
                        predicted_neg = self.W_in[target_idx]
                        actual_neg = self.W_out[negative_idx]
                        score_neg = np.dot(predicted_neg, actual_neg)
                        sigmoid_score_neg = self.sigmoid(score_neg)
                        error_neg = sigmoid_score_neg
                        
                        # Gradient update (negative samples)
                        self.W_in[target_idx] -= learning_rate * error_neg * actual_neg
                        self.W_out[negative_idx] -= learning_rate * error_neg * predicted_neg
                    
                    total_loss += -np.log(sigmoid_score)  # Add loss for this pair

            print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss}')
    
    @staticmethod
    def sigmoid(x):
        return 1 / (1 + np.exp(-x))
    
    def get_word_vector(self, word):
        """
        Retrieve the word vector for a given word.
        """
        word_idx = self.word_to_index.get(word)
        if word_idx is not None:
            return self.W_in[word_idx]
        else:
            return None
    
    def most_similar(self, word, top_n=5):
        """
        Find the top_n most similar words to the input word.
        """
        word_vector = self.get_word_vector(word)
        if word_vector is None:
            return []
        
        similarities = []
        for idx in range(len(self.vocab)):
            similarity = np.dot(word_vector, self.W_in[idx])
            similarities.append((self.index_to_word[idx], similarity))
        
        similarities = sorted(similarities, key=lambda x: -x[1])
        return similarities[:top_n]

# 示例文本数据
corpus = [
    ["i", "love", "machine", "learning"],
    ["machine", "learning", "is", "fun"],
    ["deep", "learning", "is", "a", "subfield", "of", "machine", "learning"]
]

# 创建并训练模型
model = Word2Vec(corpus, vector_size=10, window_size=2, negative_samples=5, min_count=1)
model.train(epochs=10, learning_rate=0.01)

# 获取某个词的词向量
print(model.get_word_vector('machine'))

# 获取与某个词相似的前 3 个词
print(model.most_similar('machine', top_n=3))
```

晚上继续学习Machine Learning（Instructor: Andrew Ng），整理笔记如下：

The history of Neural Networks: The origins of neural network is the thought of algorithm that try to mimc the brain, used in the 1980's and early 1990's, fell out of favor in the late 1990's. Then it resurgence from around 2005, further apply in the field of speech, image, video...

The structure of the NN: input layer+hidden layer+output layer.

For given layer $l$, the relationship between layer $l-1$ and layer $l$ is:
$$
\vec{a}_j^{[l]} = g(\vec{w}_j^{[l]} \cdot \vec{a}_j^{[l-1]} + b_j^{[l]}) 
$$
where the parameters $w$ and $b$ is in the unit $j$ of layer $l$. $g$ is the sigmoid function ("activation function"). 

forward propagation: the data flow is：input layer --> hidden layer --> output layer.

The code for loops versus vectorization :

loops:

```python
x = np.array([200, 17])

W = np.array([[1, -3, 5],
             	[-2, 4, -6]])

b = np.array([-1, 1, 2])

def dense(a_in = x, W, b):
  units = W.shape[1]
  a_out = np.zeros(units)
  for j in range(units):
    w = W[:, j]
    z = np.dot(w, a_in) + b[j]
    a_out[j] = g(z)
  return a_out   # [1, 0, 1] #1D vector
```

vector:

```python
X = np.array([[200, 17]]) # 1 X 2 2D matrix

W = np.array([[1, -3, 5],
             	[-2, 4, -6]]) # 2 X 3 2D matrix

B = np.array([[-1, 1, 2]]) # 1 X 3 2D matrix

def dense(a_in = X, W, b):
  return g(np.matmul(a_in, W) + b) # [[1, 0, 1]] # 1 X 3 2D matrix
```



------





## 2024.12.29 周日

今日休息一天。

------





## 2024.12.30 周一

今日上午继续学习Machine Learning（Instructor: Andrew Ng），整理笔记如下：

Traning a Neural Network in Tensorflow:

```python
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
  Dense(units = 25, activation = 'sigmoid'),
  Dense(units = 15, activation = 'sigmoid'),
  Dense(units = 1, activation = 'sigmoid'),  
])

from tensorflow.keras.loss import BinaryCrossentropy
model.compile(loss = BinaryCrossentropy()) # logistic loss also known as binary cross entropy.
model.fit(X, Y,epochs = 100) #  epochs is the number of steps in gradient descent.

```

Notation: if you use linear regression, you can use mean squared error:

```python
from tensorflow.keras.loss import MeanSquaredError
model.compile(loss = MeanSquaredError()) # Mean Squared Error
```

Model Traning Steps:

<img src="./assets/ModelTraningSteps.png" alt="ModelTraningSteps" style="zoom:25%;" />

Alternatives to sigmoid function:

ReLU(Rectified Linear Unit) function:
$$
g(z) = \max(0,z)
$$
Linear activation function:
$$
g(z) = z
$$
How to choose activation functions? —— According to object of each layer:

<img src="./assets/ChooseActivationFunctions.png" alt="ChooseActivationFunctions" style="zoom:25%;" />

<img src="./assets/ChooseActivationFunctions1.png" alt="ChooseActivationFunctions1" style="zoom:25%;" />

The softmax regression -> multiple classification problems (N possible outputs such as multi-label classification): 
$$
z_j = \vec{w}_j \cdot \vec{x} + b \quad  j = 1,2,...,N \\
a_j = \frac{e^{z_j}}{\sum_{k = 1}^Ne^{z_k}} = P(y = j|\vec{x}) \\
a_1 + a_2 + a_3 + ... + a_N = 1
$$
The cost and loss function:

<img src="./assets/SoftmaxCostAndLossFunction.png" alt="SoftmaxCostAndLossFunction" style="zoom:25%;" />

For softmax function in tensorflow:

```python
from tensorflow.keras.losses import SparseCategoricalCrossentropy
model.compile(loss = SparseCategoricalCrossentropy()) # But dont's use this version shown here
```

learning rate $\alpha$ optimalization —— "Adam" algorithm 【Adam: Adaptive Moment Estimation】:

​	If the gradient descent go faster (keep in the same direction), then increase $\alpha_j$. If the gradient descent go slower (keep oscillating), then decrease $\alpha_j$.

Code:

```python
model.compile(optimizer = tf.keras.optimizers.Adam(leanring_rate = 1e-3), loss = tf.keras.optimizers.SparseCategoricalCrossentroy)
```

Additional layer type:

​	Previously, we have constructed dense layer. There are exists some addtional layer type such as **Convolutionay Layer**(Faster computation, Need less training data) -> Convolutionary Neural Network(CNN).

Debugging a learning algorithm:

You've implemented regularized linear regression:
$$
J(\vec{w},b) = \frac{1}{2m}\sum_{i = 1}^m(f_{\vec{w},b}(\vec{x}^{(i)})-y^{(i)})^2 + \frac{\lambda}{2m}\sum_{j = 1}^nw_j
$$
But it makes unacceptably large errors in predictions. What do you try next?

- Get more training example
- Try samller sets of features
- Try getting additional features
- Try adding polynomial features ($x_1^2,x_2^2,x_1,x_2,etc$)
- Try decreasing $\lambda$ or increasing $\lambda$

Machine learning diagnositc: a test that you run to gain insight into what is/isn't working with a learning algorithm, to gain guidance into improving its performance. Diagnostics can take time to implement but doing so can be a very good use of your time.

Evaluating a model:

Divide the dataset into training set (70%) and test set (30%). Then fitting parameters by minimizing cost function $J(\vec{w},b)$ :

For **linear regression**:
$$
J(\vec{w}, b) = \min_{\vec{w}, b}[\frac{1}{2m_{train}}\sum_{i = 1}^{m_{train}}(f_{\vec{w},b}(\vec{x}^{(i)}) - y^{(i)})^2 + \frac{\lambda}{2m_{train}}\sum_{i=1}^nw_j]
$$
and compute test error:
$$
J_{test}(\vec{w},b) = \frac{1}{2m_{test}}[\sum_{i = 1}^{m_{test}}(f_{\vec{w},b}(\vec{x}_{test}^{(i)}) - y_{test}^{(i)})^2]
$$
compute train error:
$$
J_{train}(\vec{w},b) = \frac{1}{2m_{train}}[\sum_{i = 1}^{m_{train}}(f_{\vec{w},b}(\vec{x}_{train}^{(i)}) - y_{train}^{(i)})^2]
$$
$J_{test}(\vec{x},b)$ will be high, $J_{train}(\vec{x},b)$ will be low.

For **logistic regression**:
$$
J(\vec{w}, b) = \frac{1}{m}\sum_{i = 1}^{m}[y^{(i)}\log(f_{\vec{w},b}(\vec{x}^{(i)}))+(1-y^{(i)})\log(1-f_{\vec{w},b}(\vec{x}^{(i)}))] + \frac{\lambda}{2m}\sum_{i=1}^nw_j
$$
and compute test error:
$$
J_{test}(\vec{w},b) = -\frac{1}{m_{test}}\sum_{i = 1}^{m_{test}}[y_{test}^{(i)}\log(f_{\vec{w},b}(\vec{x}_{test}^{(i)}))+(1-y_{test}^{(i)})\log(1-f_{\vec{w},b}(\vec{x}_{test}^{(i)}))]
$$
compute train error:
$$
J_{train}(\vec{w},b) = -\frac{1}{m_{train}}\sum_{i = 1}^{m_{train}}[y_{train}^{(i)}\log(f_{\vec{w},b}(\vec{x}_{train}^{(i)}))+(1-y_{train}^{(i)})\log(1-f_{\vec{w},b}(\vec{x}_{train}^{(i)}))]
$$
Model selection: 

​	Once parameters $\vec{w},b$ are fit to training set, the training error $J_{train}(\vec{w},b)$ is likely lower than the actual generalization error. $J_{test}(\vec{w},b)$ is better estimate of how well the model will generalize to new data than $J_{train}(\vec{x},b)$:

<img src="./assets/ModelSelection.png" alt="ModelSelection" style="zoom:25%;" />

We also can divide the dataset into three parts: training set, cross validation set, test set. **How It Fits in the Dataset Splitting Process**:

- **Training set**: The portion of the data used to train the neural network. The model learns weights and biases using this data.
- **Validation set (cross-validation set)**: The portion of the data used to tune hyperparameters and evaluate the model during training, but it is not used to update the model's weights.
- **Test set**: A completely separate portion of the data used to evaluate the final model performance after all training and tuning is completed.

These errors are:
$$
\text{Training error}: \quad J_{train}(\vec{w},b) = \frac{1}{2m_{train}}[\sum_{i = 1}^{m_{train}}(f_{\vec{w},b}(\vec{x}_{train}^{(i)}) - y_{train}^{(i)})^2] \\
\text{Cross validation error}: \quad J_{cv}(\vec{w},b) = \frac{1}{2m_{cv}}[\sum_{i = 1}^{m_{cv}}(f_{\vec{w},b}(\vec{x}_{cv}^{(i)}) - y_{cv}^{(i)})^2] \\
\text{Test error}: \quad J_{test}(\vec{w},b) = \frac{1}{2m_{test}}[\sum_{i = 1}^{m_{test}}(f_{\vec{w},b}(\vec{x}_{test}^{(i)}) - y_{test}^{(i)})^2]
$$
<img src="./assets/ModelSelection1.png" alt="ModelSelection1" style="zoom:25%;" />

Note: The **cross-validation set** in neural networks (NNs) refers to a subset of the data that is used to **evaluate the model's performance during training.** It is part of the **validation process** in machine learning and helps assess how well the model generalizes to unseen data.

中午复习并整理了一下常用于machine learning的metrics：

|       Metric       |      Type      |                   Formual/Key Calculation                    |               Best Use Case                |                         Key Insights                         |
| :----------------: | :------------: | :----------------------------------------------------------: | :----------------------------------------: | :----------------------------------------------------------: |
|      **Loss**      |    General     |        Task-dependent (e.g., MSE, Cross-Entropy Loss)        |     Optimizing models during training      |     Measures prediction error, minimized during training     |
|    **Accuracy**    | Classification |             $\frac{TP+TN}{\text{Total sample}}$              |             Balanced datasets              |              Percentage of correct predictions               |
|   **Precision**    | Classification |                      $\frac{TP}{TP+FP}$                      |             High FP cost tasks             |           Focuses on reducing false positives(FP)            |
|     **Recall**     | Classification |                      $\frac{TP}{TP+FN}$                      |             High FN cost tasks             |           Focuses on reducing false negatives(FN)            |
|    **F1-Score**    | Classification | $2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision}+\text{Recall}}$ |            Imbalanced datasets             |       Balances precision and recall in a single metric       |
|    **Log Loss**    | Classification | $\frac{1}{n}\sum \hat{y}\log \hat{y} + (1-\hat{y})\log (1-\hat{y})$ |            Probabilistic models            |        Penalizes overconfident incorrect predictions         |
|    **ROC-AUC**     | Classification |                     Area under ROC curve                     | Binary classification, imbalanced datasets |   Evaluates model's ability to distinguish between classes   |
|     **PR-AUC**     | Classification |              Area under Precision-Recall curve               |            Imbalanced datasets             |            Focuses on positive class performance             |
| **MCC** (Matthews) | Classification | $\frac{TP \cdot TN - FP \cdot FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$ |          Binary/multiclass tasks           | Balanced evaluation for all classes, even for imbalanced datasets |
| **Cohen’s Kappa**  | Classification |             $\kappa = \frac{p_0 - p_e}{1 - p_e}$             |         Multiclass classification          |        Measures agreement adjusted for random chance.        |
|                    |                |                                                              |                                            |                                                              |
|                    |                |                                                              |                                            |                                                              |
|                    |                |                                                              |                                            |                                                              |
|                    |                |                                                              |                                            |                                                              |

下午继续学习MLCB2024-Lecture11-Protein Language Models，地址链接：https://www.youtube.com/watch?v=uPoFdCUqBWk，整理笔记如下：





Model evaluation:

- Different protein models better at predicting different function (stability, organismal fitness, binding, activity, expression). 

- Models do better with more relevant sequence. 

Model embedding: 

- Structure-aware tokens separate embeddings by structure type.
- Focusing on one class of proteins (i.e. antibody) leads to informative embeddings to that class.

Attention maps:

- Language mdel attention maps learn structural contacts

又找到一门适合学习的课程：MIT 7.91J | Spring 2014 | Graduate｜Foundations of Computational And System Biology.

晚上然后同步进行学习Stanford CS229，今日课程Stanford CS229: Machine Learning Course, Lecture 1 - Andrew Ng，地址链接：https://www.youtube.com/watch?v=jGwO_UgTS7I，以及Stanford CS229: Machine Learning - Linear Regression and Gradient Descent | Lecture 2 - Andrew Ng，地址链接：https://www.youtube.com/watch?v=4b4MUYve_U8，在学习这门课的过程中，发现对于线性代数甚至高等代数的部分知识已经遗忘，所以同时再修Linear Algebra。

选取MIT｜18.06 | Spring 2010 | Undergraduate —— Linear Algebra (Instructor: Prof. Gilbert Strang)这一门课程：These video lectures of Professor Gilbert Strang teaching 18.06 were recorded in Fall 1999 and do not correspond precisely to the current edition of the textbook. However, this book is still the best reference for more information on the topics covered in each lecture.

Reference: Strang, Gilbert. *Introduction to Linear Algebra*. 5th ed. [Wellesley-Cambridge Press](http://www.wellesleycambridge.com/), 2016. ISBN: 9780980232776. 

学习：MIT｜18.06 | Spring 2010 | Undergraduate —— Linear Algebra, Lecture1: The geometry of linear equations (Instructor: Prof. Gilbert Strang)

​	A major application of linear algebra is to solving systems of linear equations. This lecture presents three ways of thinking about these systems. The “row method” focuses on the individual equations, the “column method” focuses on combining the columns, and the “matrix method” is an even more compact and powerful way of describing systems of linear equations.

地址链接：https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/resources/lecture-1-the-geometry-of-linear-equations/

MIT｜18.06 | Spring 2010 | Undergraduate —— Linear Algebra, Lecture2: Elimination with matrices (Instructor: Gilbert Strang)

​	This session introduces the method of elimination, an essential tool for working with matrices. The method follows a simple algorithm. To help make sense of material presented later, we describe this algorithm in terms of matrix multiplication.

地址链接：https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/resources/lecture-2-elimination-with-matrices/

然后回家吃饭休息，身体稍有不适。

------





## 2024.12.31 周二

今日是今年的最后一天，上午在家睡觉休息，缓解身体不适。

中午去国重会议室听读书报告，然后去图书馆学习MLCB2024-Lecture12-DNA language models and Convolution，地址链接：https://www.youtube.com/watch?v=KyQKC34dCts，整理笔记如下：

1.RNA Splice Site Prediction:

- Definition: Predicting RNA splice sites to identify where splicing occurs in pre-mRNA.
- Importance: Crucial for understanding gene expression, alternative splicing, and genetic disorders.
- Splice sites: Donor(5' GT), Acceptor(3' AG).
- Challenges: Sequence variability and alternative splicing add complexity.
- Approaches: Machine Learning(SVM, Random Forest using sequence features), Deep Learning(CNNs, RNNs for raw sequence data)
- Applications: Gene annotation, disease research (e.g., cancer).
- Tools: SpliceAI, GeneSplicer, MaxEntScan.

2.Introduce to convolution neuron network:

- Definition: Convolution combines two functions to produce a third, showing how one modifies the other.
- Mathematical Form: $\int_{-\infty}^{+\infty}f(\tau)g(x - \tau) \mathrm{d}\tau$.
- Purpose in Deep Learning: Extracts features by applying filters (kernels) to data in CNN.
- Filter (Kernel): Slides across input, performing element-wise multiplication and summation.
- Advantages: Parameter Sharing: Fewer parameters, more efficient; Translation Invariance: Recognizes features regardless of position.
- Applications: Signal processing, images, spatial data.

3.For discrete convolution model: terminology: I**nput**——an image or sequence; **Kernel**——matrix of weights that slide across image; **Feature map**——output of a convolutional layer; **Width**——size of kernel matrix; **Stride**——step size over input data; **Padding**——additional data (zeros) added to edges around input data.

Convolution output size:
$$
L_{\text{out}} = \frac{L_\text{in} -K + 2P}{S + 1}
$$
where $L_{in}$ is size of input image or feature map, $K$ is kernel size, $S$ is stride, $P$ is padding, $L_{out}$ is size of output feature map.

1D convolution for DNA: key -> one-hot matrix for 1D DNA sequences.

<img src="./assets/1DDNACNN.png" alt="1DDNACNN" style="zoom:25%;" />

**The workflow of SpliceAI: RB(N, W, D)[input] -> Batch Normalization -> ReLU layer -> Conv(N, W, D) -> Batch normalization -> ReLU layer -> Conv(N, W, D) -> Add connection -> softmax activation -> output.**

DNA Foundation model: DNABERT, Nucleotide Transformer, SegmentNT, HyenaDNA, Borzoi

下午学习Stanford CS229: Machine Learning - Locally Weighted & Logistic Regression | Lecture 3 - Andrew Ng，地址链接：https://www.youtube.com/watch?v=het9HFqo1TQ，以及Stanford CS229: Machine Learning - Perceptron & Generalized Linear Model | Lecture 4 - Andrew Ng，地址链接：https://www.youtube.com/watch?v=iZTeva0WSTQ

傍晚及晚上学习MIT｜18.06 | Spring 2010 | Undergraduate —— Linear Algebra, Lecture3: Multiplication and inverse matrices (Insturctor: Gilbert Strang): 

​	This lecture looks at matrix multiplication from five different points of view. We then learn how to find the inverse of a matrix using elimination, and why the Gauss-Jordan method works.

地址链接：https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/resources/lecture-3-multiplication-and-inverse-matrices/

MIT｜18.06 | Spring 2010 | Undergraduate —— Linear Algebra, Lecture4: Factorization into A = LU (Insturctor: Gilbert Strang): 

​	This session explains inverses, transposes and permutation matrices. We also learn how elimination leads to a useful factorization *A* = *LU* and how hard a computer will work to invert a very large matrix.

地址链接：https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/resources/lecture-4-factorization-into-a-lu/

然后仔细阅读CS229和MIT18.06的textbook，完成Problem Set 1，总结今日所学的内容。

------





## 2024 年终总结







































